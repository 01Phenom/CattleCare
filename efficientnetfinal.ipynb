{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- import os<br>\n",
    "import pandas as pd<br>\n",
    "from PIL import Image<br>\n",
    "import torch<br>\n",
    "from torch.utils.data import Dataset, DataLoader<br>\n",
    "from torchvision import transforms, models<br>\n",
    "from ultralytics import YOLO -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1 - Dataset Preparation<br>\n",
    "class CattleDataset(Dataset):<br>\n",
    "    def __init__(self, annotations_file, img_dir, transform=None):<br>\n",
    "        self.annotations = pd.read_csv(annotations_file)<br>\n",
    "        self.img_dir = img_dir<br>\n",
    "        self.transform = transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "    def __len__(self):<br>\n",
    "        return len(self.annotations)\n",
    "    def __getitem__(self, idx):<br>\n",
    "        img_filename = self.annotations.iloc[idx, 0]<br>\n",
    "        img_path = os.path.join(self.img_dir, img_filename)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        # Fetch bounding boxes and class label<br>\n",
    "        boxes = self.annotations.iloc[idx, 4:8].values.astype(float)<br>\n",
    "        label = self.annotations.iloc[idx, 3]  # The class label\n",
    "        if self.transform:<br>\n",
    "            image = self.transform(image)\n",
    "        label_tensor = torch.tensor(self.get_class_id(label), dtype=torch.long)\n",
    "        return image, boxes, label_tensor\n",
    "    def get_class_id(self, class_name):<br>\n",
    "        class_map = {<br>\n",
    "            'Infected_Foot_Image': 0,<br>\n",
    "            'Mouth Disease Infected': 1,<br>\n",
    "            'Normal_Healthy_Cow': 2,<br>\n",
    "            'Normal_Mouth_Image': 3,<br>\n",
    "            'lumpy skin': 4<br>\n",
    "        }<br>\n",
    "        return class_map.get(class_name, -1)\n",
    "# Define transformations for the dataset<br>\n",
    "transform = transforms.Compose([<br>\n",
    "    transforms.Resize((224, 224)),  # Resize images for EfficientNet<br>\n",
    "    transforms.ToTensor(),  # Convert images to tensors<br>\n",
    "])\n",
    "# Function to create DataLoader for training, validation, or testing<br>\n",
    "def get_data_loader(annotations_file, img_dir, batch_size=32, shuffle=True, transform=None):<br>\n",
    "    dataset = CattleDataset(annotations_file, img_dir, transform=transform)<br>\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "# PART 2 - Hybrid Model Definition<br>\n",
    "class HybridYOLOEfficientNet(torch.nn.Module):<br>\n",
    "    def __init__(self, yolo_model, efficientnet_model):<br>\n",
    "        super(HybridYOLOEfficientNet, self).__init__()<br>\n",
    "        self.yolo_model = yolo_model.model  # YOLO detection model<br>\n",
    "        self.efficientnet = efficientnet_model.features  # EfficientNet feature extractor\n",
    "        \n",
    "         # Dynamically find the size of the feature output from EfficientNet\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.randn(1, 3, 224, 224)\n",
    "            features_size = self.efficientnet(dummy_input).view(1, -1).size(1)\n",
    "        self.fc = torch.nn.Linear(features_size, 256)  # Fully connected layer<br>\n",
    "        self.output = torch.nn.Linear(256, 5)  # For 5 classes\n",
    "    def forward(self, x):<br>\n",
    "        # YOLO forward pass (detect objects in the image)<br>\n",
    "        detection_results = self.yolo_model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        # EfficientNet forward pass (for classification)<br>\n",
    "        features = self.efficientnet(x)<br>\n",
    "        features = torch.flatten(features, 1)  # Flatten features from EfficientNet\n",
    "        # Fully connected and output layers for classification<br>\n",
    "        features = torch.relu(self.fc(features))  # Fully connected layer with ReLU<br>\n",
    "        class_outputs = self.output(features)  # Classify the features\n",
    "        return class_outputs, detection_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 3 - Training Function<br>\n",
    "def train_model(model, data_loader, criterion, optimizer, device, epochs=3):<br>\n",
    "    model.train()  # Set the model to training mode<br>\n",
    "    for epoch in range(epochs):<br>\n",
    "        running_loss = 0.0<br>\n",
    "        print(f\"Starting epoch {epoch+1}/{epochs}\")<br>\n",
    "        for batch_idx, (inputs, _, labels) in enumerate(data_loader):<br>\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "#             optimizer.zero_grad()  # Zero the parameter gradients\n",
    "#             outputs, _ = model(inputs)  # Forward pass\n",
    "            \n",
    "#             loss = criterion(outputs, labels)  # Compute loss\n",
    "#             loss.backward()  # Backpropagation\n",
    "#             optimizer.step()  # Optimize the model\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "#             if batch_idx % 10 == 0:\n",
    "#                 print(f\"Batch {batch_idx}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # PART 4 - Main Function to Initialize and Train the Model<br>\n",
    "if __name__ == \"__main__\":<br>\n",
    "    # Force the use of CPU<br>\n",
    "    device = torch.device(\"cpu\")<br>\n",
    "    print(f\"Using device: {device}\")\n",
    "    # Load pretrained YOLO model<br>\n",
    "    yolo_model = YOLO(\"yolo11n.pt\")<br>\n",
    "    print(f\"YOLO model loaded: {yolo_model}\")\n",
    "    # Load pretrained EfficientNet model<br>\n",
    "    efficientnet_model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)<br>\n",
    "    print(f\"EfficientNet model loaded: {efficientnet_model}\")\n",
    "    # Initialize the hybrid model combining YOLO and EfficientNet<br>\n",
    "    hybrid_model = HybridYOLOEfficientNet(yolo_model, efficientnet_model)<br>\n",
    "    hybrid_model = hybrid_model.to(device)  # Move model to device\n",
    "    print(f\"Hybrid model initialized on {device}\")\n",
    "    # Define loss function and optimizer<br>\n",
    "    criterion = torch.nn.CrossEntropyLoss()  # Use CrossEntropy for classification loss<br>\n",
    "    optimizer = torch.optim.Adam(hybrid_model.parameters(), lr=0.001)  # Adam optimizer\n",
    "    # Create DataLoader for training data<br>\n",
    "    train_loader = get_data_loader('train/_annotations.csv', 'train', transform=transform)\n",
    "    # Check DataLoader by fetching a single batch<br>\n",
    "    for images, boxes, labels in train_loader:<br>\n",
    "        print(f\"Batch loaded - Image shape: {images[0].shape}, Labels: {labels}\")<br>\n",
    "        break  # Stop after the first batch to ensure DataLoader is working\n",
    "    # Train the hybrid model<br>\n",
    "    train_model(hybrid_model, train_loader, criterion, optimizer, device, epochs=3) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # Should return True if CUDA is installed and PyTorch detects the GPU\n",
    "print(torch.cuda.current_device())  # Should print the current GPU device ID\n",
    "print(torch.cuda.get_device_name(torch.cuda.current_device()))  # Should print the GPU model name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART 1 - Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CattleDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None):\n",
    "        self.annotations = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    def __getitem__(self, idx):\n",
    "        img_filename = self.annotations.iloc[idx, 0]\n",
    "        img_path = os.path.join(self.img_dir, img_filename)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # Only fetch the class label for classification\n",
    "        label = self.annotations.iloc[idx, 3]  # The class label\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label_tensor = torch.tensor(self.get_class_id(label), dtype=torch.long)\n",
    "        return image, label_tensor\n",
    "    def get_class_id(self, class_name):\n",
    "        class_map = {\n",
    "            'Infected_Foot_Image': 0,\n",
    "            'Mouth Disease Infected': 1,\n",
    "            'Normal_Healthy_Cow': 2,\n",
    "            'Normal_Mouth_Image': 3,\n",
    "            'lumpy skin': 4\n",
    "        }\n",
    "        return class_map.get(class_name, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define transformations for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images for EfficientNet\n",
    "    transforms.ToTensor(),  # Convert images to tensors\n",
    "])\n",
    "\n",
    "def get_data_loader(annotations_file, img_dir, batch_size=32, shuffle=True, transform=None):\n",
    "    dataset = CattleDataset(annotations_file, img_dir, transform=transform)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to create DataLoader for training, validation, or testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART 2 - EfficientNet Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNetClassifier(torch.nn.Module):\n",
    "    def __init__(self, efficientnet_model):\n",
    "        super(EfficientNetClassifier, self).__init__()\n",
    "        self.efficientnet = efficientnet_model.features  # EfficientNet feature extractor\n",
    "        \n",
    "        # Dynamically find the size of the feature output from EfficientNet\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.randn(1, 3, 224, 224)\n",
    "            features_size = self.efficientnet(dummy_input).view(1, -1).size(1)\n",
    "        self.fc = torch.nn.Linear(features_size, 256)  # Fully connected layer\n",
    "        self.output = torch.nn.Linear(256, 5)  # For 5 classes\n",
    "    def forward(self, x):\n",
    "        # EfficientNet forward pass for classification\n",
    "        features = self.efficientnet(x)\n",
    "        features = torch.flatten(features, 1)  # Flatten features from EfficientNet\n",
    "\n",
    "        # Fully connected and output layers for classification\n",
    "        features = torch.relu(self.fc(features))  # Fully connected layer with ReLU\n",
    "        class_outputs = self.output(features)  # Classify the features\n",
    "        return class_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART 3 - Training and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Training Function\n",
    "def train_model(model, train_loader, criterion, optimizer, device, epochs=10, batch_interval=10):\n",
    "    model.train()\n",
    "    epoch_losses = []\n",
    "    epoch_accuracies = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        batch_losses = []\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "\n",
    "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Track loss and accuracy\n",
    "            batch_losses.append(loss.item())\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            total_predictions += labels.size(0)\n",
    "\n",
    "            # Display progress for every 10 batches\n",
    "            if (batch_idx + 1) % batch_interval == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "        # Calculate epoch loss and accuracy\n",
    "        epoch_loss = sum(batch_losses) / len(batch_losses)\n",
    "        epoch_accuracy = correct_predictions / total_predictions\n",
    "        epoch_losses.append(epoch_loss)\n",
    "        epoch_accuracies.append(epoch_accuracy)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] - Average Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}\")\n",
    "\n",
    "    # Plot training loss and accuracy\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, epochs + 1), epoch_losses, label=\"Loss\", color='red')\n",
    "    plt.title(\"Training Loss per Epoch\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, epochs + 1), epoch_accuracies, label=\"Accuracy\", color='blue')\n",
    "    plt.title(\"Training Accuracy per Epoch\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            # Collect labels and predictions\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    precision = precision_score(all_labels, all_predictions, average='weighted')\n",
    "    recall = recall_score(all_labels, all_predictions, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision (Weighted): {precision:.4f}\")\n",
    "    print(f\"Recall (Weighted): {recall:.4f}\")\n",
    "    print(f\"F1-Score (Weighted): {f1:.4f}\")\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(all_labels, all_predictions)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART 4 - Main Function to Initialize, Train, and Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "Starting Training...\n",
      "\n",
      "Epoch [1/30], Batch [10/1045], Loss: 2.2037\n",
      "Epoch [1/30], Batch [20/1045], Loss: 1.0482\n",
      "Epoch [1/30], Batch [30/1045], Loss: 0.9608\n",
      "Epoch [1/30], Batch [40/1045], Loss: 0.5265\n",
      "Epoch [1/30], Batch [50/1045], Loss: 0.8103\n",
      "Epoch [1/30], Batch [60/1045], Loss: 1.5564\n",
      "Epoch [1/30], Batch [70/1045], Loss: 1.0247\n",
      "Epoch [1/30], Batch [80/1045], Loss: 0.6737\n",
      "Epoch [1/30], Batch [90/1045], Loss: 0.7322\n",
      "Epoch [1/30], Batch [100/1045], Loss: 0.9456\n",
      "Epoch [1/30], Batch [110/1045], Loss: 0.7243\n",
      "Epoch [1/30], Batch [120/1045], Loss: 1.0279\n",
      "Epoch [1/30], Batch [130/1045], Loss: 0.8892\n",
      "Epoch [1/30], Batch [140/1045], Loss: 0.9371\n",
      "Epoch [1/30], Batch [150/1045], Loss: 0.8489\n",
      "Epoch [1/30], Batch [160/1045], Loss: 0.8017\n",
      "Epoch [1/30], Batch [170/1045], Loss: 0.7032\n",
      "Epoch [1/30], Batch [180/1045], Loss: 0.8375\n",
      "Epoch [1/30], Batch [190/1045], Loss: 0.4971\n",
      "Epoch [1/30], Batch [200/1045], Loss: 1.2568\n",
      "Epoch [1/30], Batch [210/1045], Loss: 0.7865\n",
      "Epoch [1/30], Batch [220/1045], Loss: 1.0231\n",
      "Epoch [1/30], Batch [230/1045], Loss: 0.8301\n",
      "Epoch [1/30], Batch [240/1045], Loss: 1.0180\n",
      "Epoch [1/30], Batch [250/1045], Loss: 0.9055\n",
      "Epoch [1/30], Batch [260/1045], Loss: 1.0249\n",
      "Epoch [1/30], Batch [270/1045], Loss: 1.0820\n",
      "Epoch [1/30], Batch [280/1045], Loss: 1.0573\n",
      "Epoch [1/30], Batch [290/1045], Loss: 1.2603\n",
      "Epoch [1/30], Batch [300/1045], Loss: 0.6891\n",
      "Epoch [1/30], Batch [310/1045], Loss: 0.7844\n",
      "Epoch [1/30], Batch [320/1045], Loss: 0.5683\n",
      "Epoch [1/30], Batch [330/1045], Loss: 0.7297\n",
      "Epoch [1/30], Batch [340/1045], Loss: 1.0232\n",
      "Epoch [1/30], Batch [350/1045], Loss: 0.7117\n",
      "Epoch [1/30], Batch [360/1045], Loss: 0.9571\n",
      "Epoch [1/30], Batch [370/1045], Loss: 1.0624\n",
      "Epoch [1/30], Batch [380/1045], Loss: 0.8245\n",
      "Epoch [1/30], Batch [390/1045], Loss: 0.8038\n",
      "Epoch [1/30], Batch [400/1045], Loss: 0.6456\n",
      "Epoch [1/30], Batch [410/1045], Loss: 0.6802\n",
      "Epoch [1/30], Batch [420/1045], Loss: 0.6265\n",
      "Epoch [1/30], Batch [430/1045], Loss: 1.0421\n",
      "Epoch [1/30], Batch [440/1045], Loss: 0.8767\n",
      "Epoch [1/30], Batch [450/1045], Loss: 0.7090\n",
      "Epoch [1/30], Batch [460/1045], Loss: 0.6809\n",
      "Epoch [1/30], Batch [470/1045], Loss: 1.1146\n",
      "Epoch [1/30], Batch [480/1045], Loss: 0.5310\n",
      "Epoch [1/30], Batch [490/1045], Loss: 0.6836\n",
      "Epoch [1/30], Batch [500/1045], Loss: 0.9170\n",
      "Epoch [1/30], Batch [510/1045], Loss: 0.8100\n",
      "Epoch [1/30], Batch [520/1045], Loss: 0.7255\n",
      "Epoch [1/30], Batch [530/1045], Loss: 1.0963\n",
      "Epoch [1/30], Batch [540/1045], Loss: 0.5422\n",
      "Epoch [1/30], Batch [550/1045], Loss: 0.9022\n",
      "Epoch [1/30], Batch [560/1045], Loss: 0.7005\n",
      "Epoch [1/30], Batch [570/1045], Loss: 0.7890\n",
      "Epoch [1/30], Batch [580/1045], Loss: 0.8622\n",
      "Epoch [1/30], Batch [590/1045], Loss: 0.7943\n",
      "Epoch [1/30], Batch [600/1045], Loss: 0.8520\n",
      "Epoch [1/30], Batch [610/1045], Loss: 0.8184\n",
      "Epoch [1/30], Batch [620/1045], Loss: 0.8706\n",
      "Epoch [1/30], Batch [630/1045], Loss: 0.9785\n",
      "Epoch [1/30], Batch [640/1045], Loss: 0.8050\n",
      "Epoch [1/30], Batch [650/1045], Loss: 0.8224\n",
      "Epoch [1/30], Batch [660/1045], Loss: 0.6230\n",
      "Epoch [1/30], Batch [670/1045], Loss: 0.8335\n",
      "Epoch [1/30], Batch [680/1045], Loss: 0.7405\n",
      "Epoch [1/30], Batch [690/1045], Loss: 0.7859\n",
      "Epoch [1/30], Batch [700/1045], Loss: 0.9685\n",
      "Epoch [1/30], Batch [710/1045], Loss: 1.0452\n",
      "Epoch [1/30], Batch [720/1045], Loss: 1.0030\n",
      "Epoch [1/30], Batch [730/1045], Loss: 0.8517\n",
      "Epoch [1/30], Batch [740/1045], Loss: 0.6458\n",
      "Epoch [1/30], Batch [750/1045], Loss: 0.6412\n",
      "Epoch [1/30], Batch [760/1045], Loss: 0.9243\n",
      "Epoch [1/30], Batch [770/1045], Loss: 0.8210\n",
      "Epoch [1/30], Batch [780/1045], Loss: 0.8655\n",
      "Epoch [1/30], Batch [790/1045], Loss: 0.8855\n",
      "Epoch [1/30], Batch [800/1045], Loss: 0.5112\n",
      "Epoch [1/30], Batch [810/1045], Loss: 0.7483\n",
      "Epoch [1/30], Batch [820/1045], Loss: 0.7251\n",
      "Epoch [1/30], Batch [830/1045], Loss: 0.7783\n",
      "Epoch [1/30], Batch [840/1045], Loss: 0.9424\n",
      "Epoch [1/30], Batch [850/1045], Loss: 0.7762\n",
      "Epoch [1/30], Batch [860/1045], Loss: 1.0907\n",
      "Epoch [1/30], Batch [870/1045], Loss: 1.0713\n",
      "Epoch [1/30], Batch [880/1045], Loss: 0.6647\n",
      "Epoch [1/30], Batch [890/1045], Loss: 0.8182\n",
      "Epoch [1/30], Batch [900/1045], Loss: 0.7617\n",
      "Epoch [1/30], Batch [910/1045], Loss: 0.7784\n",
      "Epoch [1/30], Batch [920/1045], Loss: 0.6399\n",
      "Epoch [1/30], Batch [930/1045], Loss: 1.0309\n",
      "Epoch [1/30], Batch [940/1045], Loss: 0.5566\n",
      "Epoch [1/30], Batch [950/1045], Loss: 0.7630\n",
      "Epoch [1/30], Batch [960/1045], Loss: 0.7983\n",
      "Epoch [1/30], Batch [970/1045], Loss: 0.9167\n",
      "Epoch [1/30], Batch [980/1045], Loss: 0.7865\n",
      "Epoch [1/30], Batch [990/1045], Loss: 0.4800\n",
      "Epoch [1/30], Batch [1000/1045], Loss: 0.7278\n",
      "Epoch [1/30], Batch [1010/1045], Loss: 0.7056\n",
      "Epoch [1/30], Batch [1020/1045], Loss: 0.7307\n",
      "Epoch [1/30], Batch [1030/1045], Loss: 0.9543\n",
      "Epoch [1/30], Batch [1040/1045], Loss: 0.8363\n",
      "Epoch [1/30] - Average Loss: 0.8276, Accuracy: 0.7042\n",
      "Epoch [2/30], Batch [10/1045], Loss: 0.4736\n",
      "Epoch [2/30], Batch [20/1045], Loss: 0.6936\n",
      "Epoch [2/30], Batch [30/1045], Loss: 0.5820\n",
      "Epoch [2/30], Batch [40/1045], Loss: 0.5387\n",
      "Epoch [2/30], Batch [50/1045], Loss: 0.3747\n",
      "Epoch [2/30], Batch [60/1045], Loss: 0.4459\n",
      "Epoch [2/30], Batch [70/1045], Loss: 0.6967\n",
      "Epoch [2/30], Batch [80/1045], Loss: 0.8295\n",
      "Epoch [2/30], Batch [90/1045], Loss: 0.6065\n",
      "Epoch [2/30], Batch [100/1045], Loss: 0.6952\n",
      "Epoch [2/30], Batch [110/1045], Loss: 0.7218\n",
      "Epoch [2/30], Batch [120/1045], Loss: 0.5379\n",
      "Epoch [2/30], Batch [130/1045], Loss: 0.6069\n",
      "Epoch [2/30], Batch [140/1045], Loss: 1.1740\n",
      "Epoch [2/30], Batch [150/1045], Loss: 0.6204\n",
      "Epoch [2/30], Batch [160/1045], Loss: 0.6797\n",
      "Epoch [2/30], Batch [170/1045], Loss: 0.8143\n",
      "Epoch [2/30], Batch [180/1045], Loss: 0.5816\n",
      "Epoch [2/30], Batch [190/1045], Loss: 0.5897\n",
      "Epoch [2/30], Batch [200/1045], Loss: 0.7041\n",
      "Epoch [2/30], Batch [210/1045], Loss: 0.4518\n",
      "Epoch [2/30], Batch [220/1045], Loss: 0.6518\n",
      "Epoch [2/30], Batch [230/1045], Loss: 0.7032\n",
      "Epoch [2/30], Batch [240/1045], Loss: 0.5737\n",
      "Epoch [2/30], Batch [250/1045], Loss: 0.9388\n",
      "Epoch [2/30], Batch [260/1045], Loss: 0.6462\n",
      "Epoch [2/30], Batch [270/1045], Loss: 1.1770\n",
      "Epoch [2/30], Batch [280/1045], Loss: 0.8421\n",
      "Epoch [2/30], Batch [290/1045], Loss: 0.9013\n",
      "Epoch [2/30], Batch [300/1045], Loss: 0.5588\n",
      "Epoch [2/30], Batch [310/1045], Loss: 0.7176\n",
      "Epoch [2/30], Batch [320/1045], Loss: 0.4960\n",
      "Epoch [2/30], Batch [330/1045], Loss: 0.8002\n",
      "Epoch [2/30], Batch [340/1045], Loss: 0.6655\n",
      "Epoch [2/30], Batch [350/1045], Loss: 0.2872\n",
      "Epoch [2/30], Batch [360/1045], Loss: 1.2653\n",
      "Epoch [2/30], Batch [370/1045], Loss: 0.7800\n",
      "Epoch [2/30], Batch [380/1045], Loss: 0.8077\n",
      "Epoch [2/30], Batch [390/1045], Loss: 0.5348\n",
      "Epoch [2/30], Batch [400/1045], Loss: 0.7334\n",
      "Epoch [2/30], Batch [410/1045], Loss: 1.0485\n",
      "Epoch [2/30], Batch [420/1045], Loss: 0.5998\n",
      "Epoch [2/30], Batch [430/1045], Loss: 0.5622\n",
      "Epoch [2/30], Batch [440/1045], Loss: 0.8990\n",
      "Epoch [2/30], Batch [450/1045], Loss: 0.6962\n",
      "Epoch [2/30], Batch [460/1045], Loss: 0.5899\n",
      "Epoch [2/30], Batch [470/1045], Loss: 0.9273\n",
      "Epoch [2/30], Batch [480/1045], Loss: 0.5825\n",
      "Epoch [2/30], Batch [490/1045], Loss: 0.7510\n",
      "Epoch [2/30], Batch [500/1045], Loss: 0.6991\n",
      "Epoch [2/30], Batch [510/1045], Loss: 0.6919\n",
      "Epoch [2/30], Batch [520/1045], Loss: 0.7636\n",
      "Epoch [2/30], Batch [530/1045], Loss: 0.5857\n",
      "Epoch [2/30], Batch [540/1045], Loss: 0.8230\n",
      "Epoch [2/30], Batch [550/1045], Loss: 0.7475\n",
      "Epoch [2/30], Batch [560/1045], Loss: 0.8045\n",
      "Epoch [2/30], Batch [570/1045], Loss: 0.6391\n",
      "Epoch [2/30], Batch [580/1045], Loss: 0.6455\n",
      "Epoch [2/30], Batch [590/1045], Loss: 0.5986\n",
      "Epoch [2/30], Batch [600/1045], Loss: 0.6137\n",
      "Epoch [2/30], Batch [610/1045], Loss: 0.6235\n",
      "Epoch [2/30], Batch [620/1045], Loss: 0.7304\n",
      "Epoch [2/30], Batch [630/1045], Loss: 0.6559\n",
      "Epoch [2/30], Batch [640/1045], Loss: 1.2153\n",
      "Epoch [2/30], Batch [650/1045], Loss: 0.5994\n",
      "Epoch [2/30], Batch [660/1045], Loss: 0.8725\n",
      "Epoch [2/30], Batch [670/1045], Loss: 0.9356\n",
      "Epoch [2/30], Batch [680/1045], Loss: 0.9851\n",
      "Epoch [2/30], Batch [690/1045], Loss: 0.6228\n",
      "Epoch [2/30], Batch [700/1045], Loss: 0.8591\n",
      "Epoch [2/30], Batch [710/1045], Loss: 0.7007\n",
      "Epoch [2/30], Batch [720/1045], Loss: 0.8071\n",
      "Epoch [2/30], Batch [730/1045], Loss: 0.9981\n",
      "Epoch [2/30], Batch [740/1045], Loss: 0.7625\n",
      "Epoch [2/30], Batch [750/1045], Loss: 0.7897\n",
      "Epoch [2/30], Batch [760/1045], Loss: 0.8557\n",
      "Epoch [2/30], Batch [770/1045], Loss: 0.6660\n",
      "Epoch [2/30], Batch [780/1045], Loss: 0.7619\n",
      "Epoch [2/30], Batch [790/1045], Loss: 0.5065\n",
      "Epoch [2/30], Batch [800/1045], Loss: 0.6934\n",
      "Epoch [2/30], Batch [810/1045], Loss: 0.6792\n",
      "Epoch [2/30], Batch [820/1045], Loss: 0.5826\n",
      "Epoch [2/30], Batch [830/1045], Loss: 1.3541\n",
      "Epoch [2/30], Batch [840/1045], Loss: 0.6045\n",
      "Epoch [2/30], Batch [850/1045], Loss: 0.6897\n",
      "Epoch [2/30], Batch [860/1045], Loss: 0.7663\n",
      "Epoch [2/30], Batch [870/1045], Loss: 0.8488\n",
      "Epoch [2/30], Batch [880/1045], Loss: 0.6270\n",
      "Epoch [2/30], Batch [890/1045], Loss: 1.2453\n",
      "Epoch [2/30], Batch [900/1045], Loss: 0.5046\n",
      "Epoch [2/30], Batch [910/1045], Loss: 0.7808\n",
      "Epoch [2/30], Batch [920/1045], Loss: 0.5353\n",
      "Epoch [2/30], Batch [930/1045], Loss: 0.8061\n",
      "Epoch [2/30], Batch [940/1045], Loss: 0.5390\n",
      "Epoch [2/30], Batch [950/1045], Loss: 0.5146\n",
      "Epoch [2/30], Batch [960/1045], Loss: 0.7871\n",
      "Epoch [2/30], Batch [970/1045], Loss: 0.5431\n",
      "Epoch [2/30], Batch [980/1045], Loss: 0.7881\n",
      "Epoch [2/30], Batch [990/1045], Loss: 0.5285\n",
      "Epoch [2/30], Batch [1000/1045], Loss: 0.7042\n",
      "Epoch [2/30], Batch [1010/1045], Loss: 0.5876\n",
      "Epoch [2/30], Batch [1020/1045], Loss: 0.7034\n",
      "Epoch [2/30], Batch [1030/1045], Loss: 1.0444\n",
      "Epoch [2/30], Batch [1040/1045], Loss: 1.0211\n",
      "Epoch [2/30] - Average Loss: 0.7322, Accuracy: 0.7308\n",
      "Epoch [3/30], Batch [10/1045], Loss: 0.5300\n",
      "Epoch [3/30], Batch [20/1045], Loss: 0.5767\n",
      "Epoch [3/30], Batch [30/1045], Loss: 0.5852\n",
      "Epoch [3/30], Batch [40/1045], Loss: 0.4649\n",
      "Epoch [3/30], Batch [50/1045], Loss: 0.9935\n",
      "Epoch [3/30], Batch [60/1045], Loss: 0.7236\n",
      "Epoch [3/30], Batch [70/1045], Loss: 0.5061\n",
      "Epoch [3/30], Batch [80/1045], Loss: 0.6037\n",
      "Epoch [3/30], Batch [90/1045], Loss: 0.6482\n",
      "Epoch [3/30], Batch [100/1045], Loss: 0.8825\n",
      "Epoch [3/30], Batch [110/1045], Loss: 0.5051\n",
      "Epoch [3/30], Batch [120/1045], Loss: 0.7130\n",
      "Epoch [3/30], Batch [130/1045], Loss: 0.3320\n",
      "Epoch [3/30], Batch [140/1045], Loss: 0.7086\n",
      "Epoch [3/30], Batch [150/1045], Loss: 0.8435\n",
      "Epoch [3/30], Batch [160/1045], Loss: 0.4982\n",
      "Epoch [3/30], Batch [170/1045], Loss: 0.4866\n",
      "Epoch [3/30], Batch [180/1045], Loss: 0.7087\n",
      "Epoch [3/30], Batch [190/1045], Loss: 0.6271\n",
      "Epoch [3/30], Batch [200/1045], Loss: 0.6612\n",
      "Epoch [3/30], Batch [210/1045], Loss: 0.7664\n",
      "Epoch [3/30], Batch [220/1045], Loss: 1.1629\n",
      "Epoch [3/30], Batch [230/1045], Loss: 0.6940\n",
      "Epoch [3/30], Batch [240/1045], Loss: 0.6379\n",
      "Epoch [3/30], Batch [250/1045], Loss: 0.4699\n",
      "Epoch [3/30], Batch [260/1045], Loss: 0.7388\n",
      "Epoch [3/30], Batch [270/1045], Loss: 0.5704\n",
      "Epoch [3/30], Batch [280/1045], Loss: 0.5413\n",
      "Epoch [3/30], Batch [290/1045], Loss: 0.6724\n",
      "Epoch [3/30], Batch [300/1045], Loss: 0.5950\n",
      "Epoch [3/30], Batch [310/1045], Loss: 0.4096\n",
      "Epoch [3/30], Batch [320/1045], Loss: 0.9823\n",
      "Epoch [3/30], Batch [330/1045], Loss: 0.7234\n",
      "Epoch [3/30], Batch [340/1045], Loss: 0.5802\n",
      "Epoch [3/30], Batch [350/1045], Loss: 0.5658\n",
      "Epoch [3/30], Batch [360/1045], Loss: 0.7851\n",
      "Epoch [3/30], Batch [370/1045], Loss: 0.4843\n",
      "Epoch [3/30], Batch [380/1045], Loss: 0.5722\n",
      "Epoch [3/30], Batch [390/1045], Loss: 0.4902\n",
      "Epoch [3/30], Batch [400/1045], Loss: 0.7744\n",
      "Epoch [3/30], Batch [410/1045], Loss: 0.9125\n",
      "Epoch [3/30], Batch [420/1045], Loss: 0.7062\n",
      "Epoch [3/30], Batch [430/1045], Loss: 0.4133\n",
      "Epoch [3/30], Batch [440/1045], Loss: 0.7577\n",
      "Epoch [3/30], Batch [450/1045], Loss: 0.6386\n",
      "Epoch [3/30], Batch [460/1045], Loss: 0.6913\n",
      "Epoch [3/30], Batch [470/1045], Loss: 0.6835\n",
      "Epoch [3/30], Batch [480/1045], Loss: 0.6393\n",
      "Epoch [3/30], Batch [490/1045], Loss: 0.7257\n",
      "Epoch [3/30], Batch [500/1045], Loss: 0.5354\n",
      "Epoch [3/30], Batch [510/1045], Loss: 0.6531\n",
      "Epoch [3/30], Batch [520/1045], Loss: 0.4988\n",
      "Epoch [3/30], Batch [530/1045], Loss: 0.6448\n",
      "Epoch [3/30], Batch [540/1045], Loss: 0.7027\n",
      "Epoch [3/30], Batch [550/1045], Loss: 0.6612\n",
      "Epoch [3/30], Batch [560/1045], Loss: 0.6217\n",
      "Epoch [3/30], Batch [570/1045], Loss: 0.5798\n",
      "Epoch [3/30], Batch [580/1045], Loss: 0.3353\n",
      "Epoch [3/30], Batch [590/1045], Loss: 0.6323\n",
      "Epoch [3/30], Batch [600/1045], Loss: 0.6155\n",
      "Epoch [3/30], Batch [610/1045], Loss: 0.8024\n",
      "Epoch [3/30], Batch [620/1045], Loss: 0.7642\n",
      "Epoch [3/30], Batch [630/1045], Loss: 0.3909\n",
      "Epoch [3/30], Batch [640/1045], Loss: 0.9221\n",
      "Epoch [3/30], Batch [650/1045], Loss: 0.5817\n",
      "Epoch [3/30], Batch [660/1045], Loss: 0.6253\n",
      "Epoch [3/30], Batch [670/1045], Loss: 1.0153\n",
      "Epoch [3/30], Batch [680/1045], Loss: 0.5399\n",
      "Epoch [3/30], Batch [690/1045], Loss: 0.7717\n",
      "Epoch [3/30], Batch [700/1045], Loss: 0.5958\n",
      "Epoch [3/30], Batch [710/1045], Loss: 0.7547\n",
      "Epoch [3/30], Batch [720/1045], Loss: 0.9532\n",
      "Epoch [3/30], Batch [730/1045], Loss: 0.6069\n",
      "Epoch [3/30], Batch [740/1045], Loss: 0.8878\n",
      "Epoch [3/30], Batch [750/1045], Loss: 0.8134\n",
      "Epoch [3/30], Batch [760/1045], Loss: 0.6725\n",
      "Epoch [3/30], Batch [770/1045], Loss: 0.8136\n",
      "Epoch [3/30], Batch [780/1045], Loss: 1.0380\n",
      "Epoch [3/30], Batch [790/1045], Loss: 0.5965\n",
      "Epoch [3/30], Batch [800/1045], Loss: 0.5749\n",
      "Epoch [3/30], Batch [810/1045], Loss: 0.7400\n",
      "Epoch [3/30], Batch [820/1045], Loss: 0.6871\n",
      "Epoch [3/30], Batch [830/1045], Loss: 0.7144\n",
      "Epoch [3/30], Batch [840/1045], Loss: 0.7532\n",
      "Epoch [3/30], Batch [850/1045], Loss: 0.4331\n",
      "Epoch [3/30], Batch [860/1045], Loss: 0.9687\n",
      "Epoch [3/30], Batch [870/1045], Loss: 0.4643\n",
      "Epoch [3/30], Batch [880/1045], Loss: 0.8311\n",
      "Epoch [3/30], Batch [890/1045], Loss: 0.5456\n",
      "Epoch [3/30], Batch [900/1045], Loss: 0.9267\n",
      "Epoch [3/30], Batch [910/1045], Loss: 0.6518\n",
      "Epoch [3/30], Batch [920/1045], Loss: 0.5917\n",
      "Epoch [3/30], Batch [930/1045], Loss: 0.4650\n",
      "Epoch [3/30], Batch [940/1045], Loss: 0.8763\n",
      "Epoch [3/30], Batch [950/1045], Loss: 0.4660\n",
      "Epoch [3/30], Batch [960/1045], Loss: 0.9788\n",
      "Epoch [3/30], Batch [970/1045], Loss: 0.3703\n",
      "Epoch [3/30], Batch [980/1045], Loss: 0.6767\n",
      "Epoch [3/30], Batch [990/1045], Loss: 1.1187\n",
      "Epoch [3/30], Batch [1000/1045], Loss: 0.6724\n",
      "Epoch [3/30], Batch [1010/1045], Loss: 0.5372\n",
      "Epoch [3/30], Batch [1020/1045], Loss: 0.5576\n",
      "Epoch [3/30], Batch [1030/1045], Loss: 0.8078\n",
      "Epoch [3/30], Batch [1040/1045], Loss: 0.6278\n",
      "Epoch [3/30] - Average Loss: 0.6954, Accuracy: 0.7383\n",
      "Epoch [4/30], Batch [10/1045], Loss: 0.7306\n",
      "Epoch [4/30], Batch [20/1045], Loss: 0.7582\n",
      "Epoch [4/30], Batch [30/1045], Loss: 0.6729\n",
      "Epoch [4/30], Batch [40/1045], Loss: 0.6155\n",
      "Epoch [4/30], Batch [50/1045], Loss: 0.7701\n",
      "Epoch [4/30], Batch [60/1045], Loss: 0.6235\n",
      "Epoch [4/30], Batch [70/1045], Loss: 0.5668\n",
      "Epoch [4/30], Batch [80/1045], Loss: 0.9972\n",
      "Epoch [4/30], Batch [90/1045], Loss: 0.7918\n",
      "Epoch [4/30], Batch [100/1045], Loss: 0.3880\n",
      "Epoch [4/30], Batch [110/1045], Loss: 0.5853\n",
      "Epoch [4/30], Batch [120/1045], Loss: 0.5536\n",
      "Epoch [4/30], Batch [130/1045], Loss: 0.9592\n",
      "Epoch [4/30], Batch [140/1045], Loss: 0.6302\n",
      "Epoch [4/30], Batch [150/1045], Loss: 1.3771\n",
      "Epoch [4/30], Batch [160/1045], Loss: 0.5442\n",
      "Epoch [4/30], Batch [170/1045], Loss: 0.5153\n",
      "Epoch [4/30], Batch [180/1045], Loss: 0.9002\n",
      "Epoch [4/30], Batch [190/1045], Loss: 0.6214\n",
      "Epoch [4/30], Batch [200/1045], Loss: 0.7133\n",
      "Epoch [4/30], Batch [210/1045], Loss: 0.6505\n",
      "Epoch [4/30], Batch [220/1045], Loss: 0.4294\n",
      "Epoch [4/30], Batch [230/1045], Loss: 0.6586\n",
      "Epoch [4/30], Batch [240/1045], Loss: 0.6848\n",
      "Epoch [4/30], Batch [250/1045], Loss: 0.5007\n",
      "Epoch [4/30], Batch [260/1045], Loss: 0.8716\n",
      "Epoch [4/30], Batch [270/1045], Loss: 0.5891\n",
      "Epoch [4/30], Batch [280/1045], Loss: 0.7870\n",
      "Epoch [4/30], Batch [290/1045], Loss: 0.9259\n",
      "Epoch [4/30], Batch [300/1045], Loss: 0.7068\n",
      "Epoch [4/30], Batch [310/1045], Loss: 0.7821\n",
      "Epoch [4/30], Batch [320/1045], Loss: 0.6656\n",
      "Epoch [4/30], Batch [330/1045], Loss: 0.6371\n",
      "Epoch [4/30], Batch [340/1045], Loss: 0.7922\n",
      "Epoch [4/30], Batch [350/1045], Loss: 0.4156\n",
      "Epoch [4/30], Batch [360/1045], Loss: 0.5346\n",
      "Epoch [4/30], Batch [370/1045], Loss: 0.7336\n",
      "Epoch [4/30], Batch [380/1045], Loss: 0.8752\n",
      "Epoch [4/30], Batch [390/1045], Loss: 0.4121\n",
      "Epoch [4/30], Batch [400/1045], Loss: 0.5942\n",
      "Epoch [4/30], Batch [410/1045], Loss: 0.6993\n",
      "Epoch [4/30], Batch [420/1045], Loss: 0.5422\n",
      "Epoch [4/30], Batch [430/1045], Loss: 0.7937\n",
      "Epoch [4/30], Batch [440/1045], Loss: 0.8843\n",
      "Epoch [4/30], Batch [450/1045], Loss: 0.5739\n",
      "Epoch [4/30], Batch [460/1045], Loss: 0.6787\n",
      "Epoch [4/30], Batch [470/1045], Loss: 1.0819\n",
      "Epoch [4/30], Batch [480/1045], Loss: 0.6651\n",
      "Epoch [4/30], Batch [490/1045], Loss: 0.5692\n",
      "Epoch [4/30], Batch [500/1045], Loss: 0.9423\n",
      "Epoch [4/30], Batch [510/1045], Loss: 0.7906\n",
      "Epoch [4/30], Batch [520/1045], Loss: 0.7871\n",
      "Epoch [4/30], Batch [530/1045], Loss: 0.6818\n",
      "Epoch [4/30], Batch [540/1045], Loss: 1.0612\n",
      "Epoch [4/30], Batch [550/1045], Loss: 0.8587\n",
      "Epoch [4/30], Batch [560/1045], Loss: 0.4882\n",
      "Epoch [4/30], Batch [570/1045], Loss: 0.5475\n",
      "Epoch [4/30], Batch [580/1045], Loss: 0.5163\n",
      "Epoch [4/30], Batch [590/1045], Loss: 0.8494\n",
      "Epoch [4/30], Batch [600/1045], Loss: 0.8067\n",
      "Epoch [4/30], Batch [610/1045], Loss: 0.7303\n",
      "Epoch [4/30], Batch [620/1045], Loss: 0.8683\n",
      "Epoch [4/30], Batch [630/1045], Loss: 0.5704\n",
      "Epoch [4/30], Batch [640/1045], Loss: 0.6132\n",
      "Epoch [4/30], Batch [650/1045], Loss: 0.9757\n",
      "Epoch [4/30], Batch [660/1045], Loss: 0.6192\n",
      "Epoch [4/30], Batch [670/1045], Loss: 0.5682\n",
      "Epoch [4/30], Batch [680/1045], Loss: 0.7296\n",
      "Epoch [4/30], Batch [690/1045], Loss: 0.7672\n",
      "Epoch [4/30], Batch [700/1045], Loss: 0.5892\n",
      "Epoch [4/30], Batch [710/1045], Loss: 0.8028\n",
      "Epoch [4/30], Batch [720/1045], Loss: 0.8785\n",
      "Epoch [4/30], Batch [730/1045], Loss: 0.6747\n",
      "Epoch [4/30], Batch [740/1045], Loss: 0.7255\n",
      "Epoch [4/30], Batch [750/1045], Loss: 0.5825\n",
      "Epoch [4/30], Batch [760/1045], Loss: 0.8731\n",
      "Epoch [4/30], Batch [770/1045], Loss: 0.5117\n",
      "Epoch [4/30], Batch [780/1045], Loss: 0.7343\n",
      "Epoch [4/30], Batch [790/1045], Loss: 0.5549\n",
      "Epoch [4/30], Batch [800/1045], Loss: 0.7747\n",
      "Epoch [4/30], Batch [810/1045], Loss: 0.5301\n",
      "Epoch [4/30], Batch [820/1045], Loss: 0.6199\n",
      "Epoch [4/30], Batch [830/1045], Loss: 0.4996\n",
      "Epoch [4/30], Batch [840/1045], Loss: 0.7395\n",
      "Epoch [4/30], Batch [850/1045], Loss: 0.8505\n",
      "Epoch [4/30], Batch [860/1045], Loss: 0.5848\n",
      "Epoch [4/30], Batch [870/1045], Loss: 0.6317\n",
      "Epoch [4/30], Batch [880/1045], Loss: 0.6420\n",
      "Epoch [4/30], Batch [890/1045], Loss: 0.4817\n",
      "Epoch [4/30], Batch [900/1045], Loss: 0.6785\n",
      "Epoch [4/30], Batch [910/1045], Loss: 0.5011\n",
      "Epoch [4/30], Batch [920/1045], Loss: 0.5648\n",
      "Epoch [4/30], Batch [930/1045], Loss: 0.4521\n",
      "Epoch [4/30], Batch [940/1045], Loss: 0.4479\n",
      "Epoch [4/30], Batch [950/1045], Loss: 0.7332\n",
      "Epoch [4/30], Batch [960/1045], Loss: 0.6121\n",
      "Epoch [4/30], Batch [970/1045], Loss: 0.4610\n",
      "Epoch [4/30], Batch [980/1045], Loss: 0.7987\n",
      "Epoch [4/30], Batch [990/1045], Loss: 0.4885\n",
      "Epoch [4/30], Batch [1000/1045], Loss: 0.7495\n",
      "Epoch [4/30], Batch [1010/1045], Loss: 0.7284\n",
      "Epoch [4/30], Batch [1020/1045], Loss: 0.5011\n",
      "Epoch [4/30], Batch [1030/1045], Loss: 0.8828\n",
      "Epoch [4/30], Batch [1040/1045], Loss: 0.4412\n",
      "Epoch [4/30] - Average Loss: 0.6779, Accuracy: 0.7397\n",
      "Epoch [5/30], Batch [10/1045], Loss: 0.4767\n",
      "Epoch [5/30], Batch [20/1045], Loss: 1.0246\n",
      "Epoch [5/30], Batch [30/1045], Loss: 0.5439\n",
      "Epoch [5/30], Batch [40/1045], Loss: 0.5290\n",
      "Epoch [5/30], Batch [50/1045], Loss: 0.5947\n",
      "Epoch [5/30], Batch [60/1045], Loss: 0.6606\n",
      "Epoch [5/30], Batch [70/1045], Loss: 0.4013\n",
      "Epoch [5/30], Batch [80/1045], Loss: 0.7406\n",
      "Epoch [5/30], Batch [90/1045], Loss: 0.4810\n",
      "Epoch [5/30], Batch [100/1045], Loss: 0.6561\n",
      "Epoch [5/30], Batch [110/1045], Loss: 0.6514\n",
      "Epoch [5/30], Batch [120/1045], Loss: 0.6706\n",
      "Epoch [5/30], Batch [130/1045], Loss: 0.6979\n",
      "Epoch [5/30], Batch [140/1045], Loss: 0.6372\n",
      "Epoch [5/30], Batch [150/1045], Loss: 0.5984\n",
      "Epoch [5/30], Batch [160/1045], Loss: 0.7766\n",
      "Epoch [5/30], Batch [170/1045], Loss: 0.6381\n",
      "Epoch [5/30], Batch [180/1045], Loss: 0.8486\n",
      "Epoch [5/30], Batch [190/1045], Loss: 0.6622\n",
      "Epoch [5/30], Batch [200/1045], Loss: 0.6735\n",
      "Epoch [5/30], Batch [210/1045], Loss: 0.5476\n",
      "Epoch [5/30], Batch [220/1045], Loss: 1.1682\n",
      "Epoch [5/30], Batch [230/1045], Loss: 0.3217\n",
      "Epoch [5/30], Batch [240/1045], Loss: 0.6651\n",
      "Epoch [5/30], Batch [250/1045], Loss: 0.7974\n",
      "Epoch [5/30], Batch [260/1045], Loss: 0.6300\n",
      "Epoch [5/30], Batch [270/1045], Loss: 0.9289\n",
      "Epoch [5/30], Batch [280/1045], Loss: 0.5435\n",
      "Epoch [5/30], Batch [290/1045], Loss: 0.6376\n",
      "Epoch [5/30], Batch [300/1045], Loss: 0.9243\n",
      "Epoch [5/30], Batch [310/1045], Loss: 0.6350\n",
      "Epoch [5/30], Batch [320/1045], Loss: 0.7995\n",
      "Epoch [5/30], Batch [330/1045], Loss: 0.9027\n",
      "Epoch [5/30], Batch [340/1045], Loss: 0.9195\n",
      "Epoch [5/30], Batch [350/1045], Loss: 0.5976\n",
      "Epoch [5/30], Batch [360/1045], Loss: 0.3588\n",
      "Epoch [5/30], Batch [370/1045], Loss: 0.8731\n",
      "Epoch [5/30], Batch [380/1045], Loss: 0.6004\n",
      "Epoch [5/30], Batch [390/1045], Loss: 0.4910\n",
      "Epoch [5/30], Batch [400/1045], Loss: 0.7203\n",
      "Epoch [5/30], Batch [410/1045], Loss: 0.4289\n",
      "Epoch [5/30], Batch [420/1045], Loss: 0.6738\n",
      "Epoch [5/30], Batch [430/1045], Loss: 0.4386\n",
      "Epoch [5/30], Batch [440/1045], Loss: 0.7357\n",
      "Epoch [5/30], Batch [450/1045], Loss: 0.8868\n",
      "Epoch [5/30], Batch [460/1045], Loss: 0.5133\n",
      "Epoch [5/30], Batch [470/1045], Loss: 0.7731\n",
      "Epoch [5/30], Batch [480/1045], Loss: 0.7765\n",
      "Epoch [5/30], Batch [490/1045], Loss: 0.4649\n",
      "Epoch [5/30], Batch [500/1045], Loss: 1.1768\n",
      "Epoch [5/30], Batch [510/1045], Loss: 0.7884\n",
      "Epoch [5/30], Batch [520/1045], Loss: 0.7352\n",
      "Epoch [5/30], Batch [530/1045], Loss: 0.6960\n",
      "Epoch [5/30], Batch [540/1045], Loss: 0.8239\n",
      "Epoch [5/30], Batch [550/1045], Loss: 0.9218\n",
      "Epoch [5/30], Batch [560/1045], Loss: 0.9741\n",
      "Epoch [5/30], Batch [570/1045], Loss: 0.7007\n",
      "Epoch [5/30], Batch [580/1045], Loss: 0.6084\n",
      "Epoch [5/30], Batch [590/1045], Loss: 0.6636\n",
      "Epoch [5/30], Batch [600/1045], Loss: 0.7780\n",
      "Epoch [5/30], Batch [610/1045], Loss: 1.1070\n",
      "Epoch [5/30], Batch [620/1045], Loss: 0.7384\n",
      "Epoch [5/30], Batch [630/1045], Loss: 0.3920\n",
      "Epoch [5/30], Batch [640/1045], Loss: 0.6682\n",
      "Epoch [5/30], Batch [650/1045], Loss: 0.5350\n",
      "Epoch [5/30], Batch [660/1045], Loss: 0.7472\n",
      "Epoch [5/30], Batch [670/1045], Loss: 0.6533\n",
      "Epoch [5/30], Batch [680/1045], Loss: 0.9660\n",
      "Epoch [5/30], Batch [690/1045], Loss: 0.5993\n",
      "Epoch [5/30], Batch [700/1045], Loss: 0.5225\n",
      "Epoch [5/30], Batch [710/1045], Loss: 0.6799\n",
      "Epoch [5/30], Batch [720/1045], Loss: 0.8272\n",
      "Epoch [5/30], Batch [730/1045], Loss: 0.6979\n",
      "Epoch [5/30], Batch [740/1045], Loss: 0.6716\n",
      "Epoch [5/30], Batch [750/1045], Loss: 0.4416\n",
      "Epoch [5/30], Batch [760/1045], Loss: 0.4260\n",
      "Epoch [5/30], Batch [770/1045], Loss: 0.8405\n",
      "Epoch [5/30], Batch [780/1045], Loss: 0.5232\n",
      "Epoch [5/30], Batch [790/1045], Loss: 0.7141\n",
      "Epoch [5/30], Batch [800/1045], Loss: 0.5692\n",
      "Epoch [5/30], Batch [810/1045], Loss: 0.4695\n",
      "Epoch [5/30], Batch [820/1045], Loss: 0.6848\n",
      "Epoch [5/30], Batch [830/1045], Loss: 0.7739\n",
      "Epoch [5/30], Batch [840/1045], Loss: 0.7886\n",
      "Epoch [5/30], Batch [850/1045], Loss: 0.9864\n",
      "Epoch [5/30], Batch [860/1045], Loss: 0.6742\n",
      "Epoch [5/30], Batch [870/1045], Loss: 0.6940\n",
      "Epoch [5/30], Batch [880/1045], Loss: 0.6621\n",
      "Epoch [5/30], Batch [890/1045], Loss: 0.5289\n",
      "Epoch [5/30], Batch [900/1045], Loss: 1.0690\n",
      "Epoch [5/30], Batch [910/1045], Loss: 0.5953\n",
      "Epoch [5/30], Batch [920/1045], Loss: 0.6050\n",
      "Epoch [5/30], Batch [930/1045], Loss: 0.6812\n",
      "Epoch [5/30], Batch [940/1045], Loss: 0.8695\n",
      "Epoch [5/30], Batch [950/1045], Loss: 0.7345\n",
      "Epoch [5/30], Batch [960/1045], Loss: 0.9263\n",
      "Epoch [5/30], Batch [970/1045], Loss: 0.6099\n",
      "Epoch [5/30], Batch [980/1045], Loss: 0.7697\n",
      "Epoch [5/30], Batch [990/1045], Loss: 0.9692\n",
      "Epoch [5/30], Batch [1000/1045], Loss: 0.8547\n",
      "Epoch [5/30], Batch [1010/1045], Loss: 0.6110\n",
      "Epoch [5/30], Batch [1020/1045], Loss: 0.7382\n",
      "Epoch [5/30], Batch [1030/1045], Loss: 0.8334\n",
      "Epoch [5/30], Batch [1040/1045], Loss: 0.9840\n",
      "Epoch [5/30] - Average Loss: 0.6689, Accuracy: 0.7427\n",
      "Epoch [6/30], Batch [10/1045], Loss: 0.7994\n",
      "Epoch [6/30], Batch [20/1045], Loss: 0.4519\n",
      "Epoch [6/30], Batch [30/1045], Loss: 0.7399\n",
      "Epoch [6/30], Batch [40/1045], Loss: 0.4393\n",
      "Epoch [6/30], Batch [50/1045], Loss: 0.5885\n",
      "Epoch [6/30], Batch [60/1045], Loss: 0.5104\n",
      "Epoch [6/30], Batch [70/1045], Loss: 0.5677\n",
      "Epoch [6/30], Batch [80/1045], Loss: 0.9832\n",
      "Epoch [6/30], Batch [90/1045], Loss: 0.5011\n",
      "Epoch [6/30], Batch [100/1045], Loss: 0.8015\n",
      "Epoch [6/30], Batch [110/1045], Loss: 0.5904\n",
      "Epoch [6/30], Batch [120/1045], Loss: 0.3821\n",
      "Epoch [6/30], Batch [130/1045], Loss: 0.7145\n",
      "Epoch [6/30], Batch [140/1045], Loss: 0.4712\n",
      "Epoch [6/30], Batch [150/1045], Loss: 0.7165\n",
      "Epoch [6/30], Batch [160/1045], Loss: 0.6164\n",
      "Epoch [6/30], Batch [170/1045], Loss: 0.6541\n",
      "Epoch [6/30], Batch [180/1045], Loss: 0.5164\n",
      "Epoch [6/30], Batch [190/1045], Loss: 0.6619\n",
      "Epoch [6/30], Batch [200/1045], Loss: 0.4423\n",
      "Epoch [6/30], Batch [210/1045], Loss: 0.7101\n",
      "Epoch [6/30], Batch [220/1045], Loss: 0.5514\n",
      "Epoch [6/30], Batch [230/1045], Loss: 0.3605\n",
      "Epoch [6/30], Batch [240/1045], Loss: 0.5350\n",
      "Epoch [6/30], Batch [250/1045], Loss: 0.6405\n",
      "Epoch [6/30], Batch [260/1045], Loss: 0.5048\n",
      "Epoch [6/30], Batch [270/1045], Loss: 0.6756\n",
      "Epoch [6/30], Batch [280/1045], Loss: 0.5258\n",
      "Epoch [6/30], Batch [290/1045], Loss: 0.6842\n",
      "Epoch [6/30], Batch [300/1045], Loss: 0.5657\n",
      "Epoch [6/30], Batch [310/1045], Loss: 0.6784\n",
      "Epoch [6/30], Batch [320/1045], Loss: 0.4522\n",
      "Epoch [6/30], Batch [330/1045], Loss: 0.5179\n",
      "Epoch [6/30], Batch [340/1045], Loss: 0.8006\n",
      "Epoch [6/30], Batch [350/1045], Loss: 0.5508\n",
      "Epoch [6/30], Batch [360/1045], Loss: 0.3758\n",
      "Epoch [6/30], Batch [370/1045], Loss: 0.5910\n",
      "Epoch [6/30], Batch [380/1045], Loss: 0.4342\n",
      "Epoch [6/30], Batch [390/1045], Loss: 0.5199\n",
      "Epoch [6/30], Batch [400/1045], Loss: 0.3978\n",
      "Epoch [6/30], Batch [410/1045], Loss: 0.7498\n",
      "Epoch [6/30], Batch [420/1045], Loss: 0.5621\n",
      "Epoch [6/30], Batch [430/1045], Loss: 1.2591\n",
      "Epoch [6/30], Batch [440/1045], Loss: 0.5966\n",
      "Epoch [6/30], Batch [450/1045], Loss: 0.8663\n",
      "Epoch [6/30], Batch [460/1045], Loss: 0.6688\n",
      "Epoch [6/30], Batch [470/1045], Loss: 0.5277\n",
      "Epoch [6/30], Batch [480/1045], Loss: 0.8233\n",
      "Epoch [6/30], Batch [490/1045], Loss: 0.8117\n",
      "Epoch [6/30], Batch [500/1045], Loss: 0.4410\n",
      "Epoch [6/30], Batch [510/1045], Loss: 0.5512\n",
      "Epoch [6/30], Batch [520/1045], Loss: 1.3371\n",
      "Epoch [6/30], Batch [530/1045], Loss: 0.5354\n",
      "Epoch [6/30], Batch [540/1045], Loss: 0.6848\n",
      "Epoch [6/30], Batch [550/1045], Loss: 0.7012\n",
      "Epoch [6/30], Batch [560/1045], Loss: 0.4540\n",
      "Epoch [6/30], Batch [570/1045], Loss: 0.5489\n",
      "Epoch [6/30], Batch [580/1045], Loss: 0.7164\n",
      "Epoch [6/30], Batch [590/1045], Loss: 0.6361\n",
      "Epoch [6/30], Batch [600/1045], Loss: 0.5875\n",
      "Epoch [6/30], Batch [610/1045], Loss: 0.8621\n",
      "Epoch [6/30], Batch [620/1045], Loss: 0.5779\n",
      "Epoch [6/30], Batch [630/1045], Loss: 0.8280\n",
      "Epoch [6/30], Batch [640/1045], Loss: 0.7677\n",
      "Epoch [6/30], Batch [650/1045], Loss: 0.7584\n",
      "Epoch [6/30], Batch [660/1045], Loss: 0.8079\n",
      "Epoch [6/30], Batch [670/1045], Loss: 0.5626\n",
      "Epoch [6/30], Batch [680/1045], Loss: 0.4842\n",
      "Epoch [6/30], Batch [690/1045], Loss: 0.5649\n",
      "Epoch [6/30], Batch [700/1045], Loss: 0.5945\n",
      "Epoch [6/30], Batch [710/1045], Loss: 0.4956\n",
      "Epoch [6/30], Batch [720/1045], Loss: 0.7670\n",
      "Epoch [6/30], Batch [730/1045], Loss: 0.5664\n",
      "Epoch [6/30], Batch [740/1045], Loss: 0.8283\n",
      "Epoch [6/30], Batch [750/1045], Loss: 0.5943\n",
      "Epoch [6/30], Batch [760/1045], Loss: 0.7189\n",
      "Epoch [6/30], Batch [770/1045], Loss: 0.4987\n",
      "Epoch [6/30], Batch [780/1045], Loss: 0.4828\n",
      "Epoch [6/30], Batch [790/1045], Loss: 0.5551\n",
      "Epoch [6/30], Batch [800/1045], Loss: 0.7723\n",
      "Epoch [6/30], Batch [810/1045], Loss: 1.1121\n",
      "Epoch [6/30], Batch [820/1045], Loss: 0.8320\n",
      "Epoch [6/30], Batch [830/1045], Loss: 0.4803\n",
      "Epoch [6/30], Batch [840/1045], Loss: 0.7207\n",
      "Epoch [6/30], Batch [850/1045], Loss: 0.7802\n",
      "Epoch [6/30], Batch [860/1045], Loss: 0.9199\n",
      "Epoch [6/30], Batch [870/1045], Loss: 0.7592\n",
      "Epoch [6/30], Batch [880/1045], Loss: 0.8080\n",
      "Epoch [6/30], Batch [890/1045], Loss: 0.5640\n",
      "Epoch [6/30], Batch [900/1045], Loss: 0.4819\n",
      "Epoch [6/30], Batch [910/1045], Loss: 0.9820\n",
      "Epoch [6/30], Batch [920/1045], Loss: 0.5608\n",
      "Epoch [6/30], Batch [930/1045], Loss: 0.5358\n",
      "Epoch [6/30], Batch [940/1045], Loss: 0.7641\n",
      "Epoch [6/30], Batch [950/1045], Loss: 0.4657\n",
      "Epoch [6/30], Batch [960/1045], Loss: 0.7894\n",
      "Epoch [6/30], Batch [970/1045], Loss: 0.9090\n",
      "Epoch [6/30], Batch [980/1045], Loss: 0.4592\n",
      "Epoch [6/30], Batch [990/1045], Loss: 0.4946\n",
      "Epoch [6/30], Batch [1000/1045], Loss: 0.5135\n",
      "Epoch [6/30], Batch [1010/1045], Loss: 0.4852\n",
      "Epoch [6/30], Batch [1020/1045], Loss: 0.7733\n",
      "Epoch [6/30], Batch [1030/1045], Loss: 0.4865\n",
      "Epoch [6/30], Batch [1040/1045], Loss: 0.9963\n",
      "Epoch [6/30] - Average Loss: 0.6486, Accuracy: 0.7499\n",
      "Epoch [7/30], Batch [10/1045], Loss: 0.9606\n",
      "Epoch [7/30], Batch [20/1045], Loss: 0.5629\n",
      "Epoch [7/30], Batch [30/1045], Loss: 0.4890\n",
      "Epoch [7/30], Batch [40/1045], Loss: 0.5317\n",
      "Epoch [7/30], Batch [50/1045], Loss: 0.5506\n",
      "Epoch [7/30], Batch [60/1045], Loss: 0.3937\n",
      "Epoch [7/30], Batch [70/1045], Loss: 0.5102\n",
      "Epoch [7/30], Batch [80/1045], Loss: 0.3900\n",
      "Epoch [7/30], Batch [90/1045], Loss: 0.6020\n",
      "Epoch [7/30], Batch [100/1045], Loss: 0.7128\n",
      "Epoch [7/30], Batch [110/1045], Loss: 0.7747\n",
      "Epoch [7/30], Batch [120/1045], Loss: 0.5187\n",
      "Epoch [7/30], Batch [130/1045], Loss: 0.7607\n",
      "Epoch [7/30], Batch [140/1045], Loss: 0.4668\n",
      "Epoch [7/30], Batch [150/1045], Loss: 0.7003\n",
      "Epoch [7/30], Batch [160/1045], Loss: 0.5492\n",
      "Epoch [7/30], Batch [170/1045], Loss: 0.3129\n",
      "Epoch [7/30], Batch [180/1045], Loss: 0.9529\n",
      "Epoch [7/30], Batch [190/1045], Loss: 0.4890\n",
      "Epoch [7/30], Batch [200/1045], Loss: 0.5466\n",
      "Epoch [7/30], Batch [210/1045], Loss: 0.5915\n",
      "Epoch [7/30], Batch [220/1045], Loss: 0.6588\n",
      "Epoch [7/30], Batch [230/1045], Loss: 0.7388\n",
      "Epoch [7/30], Batch [240/1045], Loss: 0.7343\n",
      "Epoch [7/30], Batch [250/1045], Loss: 0.6151\n",
      "Epoch [7/30], Batch [260/1045], Loss: 0.7531\n",
      "Epoch [7/30], Batch [270/1045], Loss: 0.7505\n",
      "Epoch [7/30], Batch [280/1045], Loss: 0.5745\n",
      "Epoch [7/30], Batch [290/1045], Loss: 0.7457\n",
      "Epoch [7/30], Batch [300/1045], Loss: 0.8606\n",
      "Epoch [7/30], Batch [310/1045], Loss: 0.6179\n",
      "Epoch [7/30], Batch [320/1045], Loss: 0.3571\n",
      "Epoch [7/30], Batch [330/1045], Loss: 0.5060\n",
      "Epoch [7/30], Batch [340/1045], Loss: 0.4740\n",
      "Epoch [7/30], Batch [350/1045], Loss: 0.4773\n",
      "Epoch [7/30], Batch [360/1045], Loss: 0.7337\n",
      "Epoch [7/30], Batch [370/1045], Loss: 0.6140\n",
      "Epoch [7/30], Batch [380/1045], Loss: 0.6814\n",
      "Epoch [7/30], Batch [390/1045], Loss: 0.5640\n",
      "Epoch [7/30], Batch [400/1045], Loss: 0.8977\n",
      "Epoch [7/30], Batch [410/1045], Loss: 0.4659\n",
      "Epoch [7/30], Batch [420/1045], Loss: 0.6493\n",
      "Epoch [7/30], Batch [430/1045], Loss: 0.8428\n",
      "Epoch [7/30], Batch [440/1045], Loss: 0.5025\n",
      "Epoch [7/30], Batch [450/1045], Loss: 0.7158\n",
      "Epoch [7/30], Batch [460/1045], Loss: 0.6622\n",
      "Epoch [7/30], Batch [470/1045], Loss: 0.5728\n",
      "Epoch [7/30], Batch [480/1045], Loss: 0.6296\n",
      "Epoch [7/30], Batch [490/1045], Loss: 0.5529\n",
      "Epoch [7/30], Batch [500/1045], Loss: 0.5971\n",
      "Epoch [7/30], Batch [510/1045], Loss: 0.7156\n",
      "Epoch [7/30], Batch [520/1045], Loss: 0.5888\n",
      "Epoch [7/30], Batch [530/1045], Loss: 0.5088\n",
      "Epoch [7/30], Batch [540/1045], Loss: 0.8963\n",
      "Epoch [7/30], Batch [550/1045], Loss: 0.7957\n",
      "Epoch [7/30], Batch [560/1045], Loss: 0.5457\n",
      "Epoch [7/30], Batch [570/1045], Loss: 0.6804\n",
      "Epoch [7/30], Batch [580/1045], Loss: 0.7625\n",
      "Epoch [7/30], Batch [590/1045], Loss: 0.4761\n",
      "Epoch [7/30], Batch [600/1045], Loss: 0.3269\n",
      "Epoch [7/30], Batch [610/1045], Loss: 0.7821\n",
      "Epoch [7/30], Batch [620/1045], Loss: 0.5177\n",
      "Epoch [7/30], Batch [630/1045], Loss: 1.2513\n",
      "Epoch [7/30], Batch [640/1045], Loss: 0.4788\n",
      "Epoch [7/30], Batch [650/1045], Loss: 0.5559\n",
      "Epoch [7/30], Batch [660/1045], Loss: 0.5744\n",
      "Epoch [7/30], Batch [670/1045], Loss: 0.5803\n",
      "Epoch [7/30], Batch [680/1045], Loss: 0.9484\n",
      "Epoch [7/30], Batch [690/1045], Loss: 0.6071\n",
      "Epoch [7/30], Batch [700/1045], Loss: 0.6358\n",
      "Epoch [7/30], Batch [710/1045], Loss: 0.5284\n",
      "Epoch [7/30], Batch [720/1045], Loss: 0.6083\n",
      "Epoch [7/30], Batch [730/1045], Loss: 0.5809\n",
      "Epoch [7/30], Batch [740/1045], Loss: 0.7708\n",
      "Epoch [7/30], Batch [750/1045], Loss: 0.7617\n",
      "Epoch [7/30], Batch [760/1045], Loss: 0.5718\n",
      "Epoch [7/30], Batch [770/1045], Loss: 0.9484\n",
      "Epoch [7/30], Batch [780/1045], Loss: 0.7073\n",
      "Epoch [7/30], Batch [790/1045], Loss: 0.7055\n",
      "Epoch [7/30], Batch [800/1045], Loss: 0.5598\n",
      "Epoch [7/30], Batch [810/1045], Loss: 0.6747\n",
      "Epoch [7/30], Batch [820/1045], Loss: 0.9053\n",
      "Epoch [7/30], Batch [830/1045], Loss: 0.6371\n",
      "Epoch [7/30], Batch [840/1045], Loss: 0.5109\n",
      "Epoch [7/30], Batch [850/1045], Loss: 1.1758\n",
      "Epoch [7/30], Batch [860/1045], Loss: 0.7577\n",
      "Epoch [7/30], Batch [870/1045], Loss: 0.5765\n",
      "Epoch [7/30], Batch [880/1045], Loss: 0.6885\n",
      "Epoch [7/30], Batch [890/1045], Loss: 0.7667\n",
      "Epoch [7/30], Batch [900/1045], Loss: 0.8825\n",
      "Epoch [7/30], Batch [910/1045], Loss: 0.8018\n",
      "Epoch [7/30], Batch [920/1045], Loss: 0.6744\n",
      "Epoch [7/30], Batch [930/1045], Loss: 1.1783\n",
      "Epoch [7/30], Batch [940/1045], Loss: 0.8520\n",
      "Epoch [7/30], Batch [950/1045], Loss: 0.8458\n",
      "Epoch [7/30], Batch [960/1045], Loss: 0.8001\n",
      "Epoch [7/30], Batch [970/1045], Loss: 0.7829\n",
      "Epoch [7/30], Batch [980/1045], Loss: 0.2637\n",
      "Epoch [7/30], Batch [990/1045], Loss: 0.6384\n",
      "Epoch [7/30], Batch [1000/1045], Loss: 0.5200\n",
      "Epoch [7/30], Batch [1010/1045], Loss: 0.5179\n",
      "Epoch [7/30], Batch [1020/1045], Loss: 0.7580\n",
      "Epoch [7/30], Batch [1030/1045], Loss: 0.8952\n",
      "Epoch [7/30], Batch [1040/1045], Loss: 0.6109\n",
      "Epoch [7/30] - Average Loss: 0.6394, Accuracy: 0.7483\n",
      "Epoch [8/30], Batch [10/1045], Loss: 0.6085\n",
      "Epoch [8/30], Batch [20/1045], Loss: 0.4871\n",
      "Epoch [8/30], Batch [30/1045], Loss: 0.4531\n",
      "Epoch [8/30], Batch [40/1045], Loss: 0.5790\n",
      "Epoch [8/30], Batch [50/1045], Loss: 0.6120\n",
      "Epoch [8/30], Batch [60/1045], Loss: 0.6598\n",
      "Epoch [8/30], Batch [70/1045], Loss: 0.7426\n",
      "Epoch [8/30], Batch [80/1045], Loss: 0.4335\n",
      "Epoch [8/30], Batch [90/1045], Loss: 0.4232\n",
      "Epoch [8/30], Batch [100/1045], Loss: 0.6144\n",
      "Epoch [8/30], Batch [110/1045], Loss: 0.5630\n",
      "Epoch [8/30], Batch [120/1045], Loss: 0.4600\n",
      "Epoch [8/30], Batch [130/1045], Loss: 0.5676\n",
      "Epoch [8/30], Batch [140/1045], Loss: 0.5443\n",
      "Epoch [8/30], Batch [150/1045], Loss: 0.4963\n",
      "Epoch [8/30], Batch [160/1045], Loss: 0.5164\n",
      "Epoch [8/30], Batch [170/1045], Loss: 0.7780\n",
      "Epoch [8/30], Batch [180/1045], Loss: 0.6746\n",
      "Epoch [8/30], Batch [190/1045], Loss: 0.6561\n",
      "Epoch [8/30], Batch [200/1045], Loss: 0.5525\n",
      "Epoch [8/30], Batch [210/1045], Loss: 0.8856\n",
      "Epoch [8/30], Batch [220/1045], Loss: 0.7310\n",
      "Epoch [8/30], Batch [230/1045], Loss: 0.5914\n",
      "Epoch [8/30], Batch [240/1045], Loss: 0.4554\n",
      "Epoch [8/30], Batch [250/1045], Loss: 0.6131\n",
      "Epoch [8/30], Batch [260/1045], Loss: 0.8023\n",
      "Epoch [8/30], Batch [270/1045], Loss: 0.6999\n",
      "Epoch [8/30], Batch [280/1045], Loss: 0.6680\n",
      "Epoch [8/30], Batch [290/1045], Loss: 0.4935\n",
      "Epoch [8/30], Batch [300/1045], Loss: 0.4888\n",
      "Epoch [8/30], Batch [310/1045], Loss: 0.4582\n",
      "Epoch [8/30], Batch [320/1045], Loss: 0.5433\n",
      "Epoch [8/30], Batch [330/1045], Loss: 0.4688\n",
      "Epoch [8/30], Batch [340/1045], Loss: 0.6669\n",
      "Epoch [8/30], Batch [350/1045], Loss: 0.4136\n",
      "Epoch [8/30], Batch [360/1045], Loss: 0.5708\n",
      "Epoch [8/30], Batch [370/1045], Loss: 0.7530\n",
      "Epoch [8/30], Batch [380/1045], Loss: 0.5066\n",
      "Epoch [8/30], Batch [390/1045], Loss: 0.8360\n",
      "Epoch [8/30], Batch [400/1045], Loss: 0.5868\n",
      "Epoch [8/30], Batch [410/1045], Loss: 0.6616\n",
      "Epoch [8/30], Batch [420/1045], Loss: 0.6184\n",
      "Epoch [8/30], Batch [430/1045], Loss: 0.5415\n",
      "Epoch [8/30], Batch [440/1045], Loss: 0.5636\n",
      "Epoch [8/30], Batch [450/1045], Loss: 0.6377\n",
      "Epoch [8/30], Batch [460/1045], Loss: 0.5214\n",
      "Epoch [8/30], Batch [470/1045], Loss: 0.7319\n",
      "Epoch [8/30], Batch [480/1045], Loss: 0.5259\n",
      "Epoch [8/30], Batch [490/1045], Loss: 1.0075\n",
      "Epoch [8/30], Batch [500/1045], Loss: 0.6363\n",
      "Epoch [8/30], Batch [510/1045], Loss: 0.5527\n",
      "Epoch [8/30], Batch [520/1045], Loss: 0.6506\n",
      "Epoch [8/30], Batch [530/1045], Loss: 0.6175\n",
      "Epoch [8/30], Batch [540/1045], Loss: 0.6088\n",
      "Epoch [8/30], Batch [550/1045], Loss: 0.6328\n",
      "Epoch [8/30], Batch [560/1045], Loss: 0.6739\n",
      "Epoch [8/30], Batch [570/1045], Loss: 0.5970\n",
      "Epoch [8/30], Batch [580/1045], Loss: 0.4871\n",
      "Epoch [8/30], Batch [590/1045], Loss: 0.5828\n",
      "Epoch [8/30], Batch [600/1045], Loss: 0.7821\n",
      "Epoch [8/30], Batch [610/1045], Loss: 0.5414\n",
      "Epoch [8/30], Batch [620/1045], Loss: 0.5738\n",
      "Epoch [8/30], Batch [630/1045], Loss: 0.6604\n",
      "Epoch [8/30], Batch [640/1045], Loss: 0.7432\n",
      "Epoch [8/30], Batch [650/1045], Loss: 0.5969\n",
      "Epoch [8/30], Batch [660/1045], Loss: 0.7383\n",
      "Epoch [8/30], Batch [670/1045], Loss: 0.5235\n",
      "Epoch [8/30], Batch [680/1045], Loss: 0.5370\n",
      "Epoch [8/30], Batch [690/1045], Loss: 0.9200\n",
      "Epoch [8/30], Batch [700/1045], Loss: 0.4588\n",
      "Epoch [8/30], Batch [710/1045], Loss: 0.5995\n",
      "Epoch [8/30], Batch [720/1045], Loss: 0.5422\n",
      "Epoch [8/30], Batch [730/1045], Loss: 0.6631\n",
      "Epoch [8/30], Batch [740/1045], Loss: 0.6274\n",
      "Epoch [8/30], Batch [750/1045], Loss: 0.8503\n",
      "Epoch [8/30], Batch [760/1045], Loss: 0.9630\n",
      "Epoch [8/30], Batch [770/1045], Loss: 0.5185\n",
      "Epoch [8/30], Batch [780/1045], Loss: 0.8236\n",
      "Epoch [8/30], Batch [790/1045], Loss: 0.5686\n",
      "Epoch [8/30], Batch [800/1045], Loss: 0.6458\n",
      "Epoch [8/30], Batch [810/1045], Loss: 0.4614\n",
      "Epoch [8/30], Batch [820/1045], Loss: 0.7064\n",
      "Epoch [8/30], Batch [830/1045], Loss: 0.8538\n",
      "Epoch [8/30], Batch [840/1045], Loss: 0.4739\n",
      "Epoch [8/30], Batch [850/1045], Loss: 0.5370\n",
      "Epoch [8/30], Batch [860/1045], Loss: 0.7176\n",
      "Epoch [8/30], Batch [870/1045], Loss: 0.4752\n",
      "Epoch [8/30], Batch [880/1045], Loss: 0.3798\n",
      "Epoch [8/30], Batch [890/1045], Loss: 0.7557\n",
      "Epoch [8/30], Batch [900/1045], Loss: 0.4401\n",
      "Epoch [8/30], Batch [910/1045], Loss: 0.5619\n",
      "Epoch [8/30], Batch [920/1045], Loss: 0.4674\n",
      "Epoch [8/30], Batch [930/1045], Loss: 0.6981\n",
      "Epoch [8/30], Batch [940/1045], Loss: 0.5171\n",
      "Epoch [8/30], Batch [950/1045], Loss: 0.6191\n",
      "Epoch [8/30], Batch [960/1045], Loss: 0.6263\n",
      "Epoch [8/30], Batch [970/1045], Loss: 0.7427\n",
      "Epoch [8/30], Batch [980/1045], Loss: 0.7761\n",
      "Epoch [8/30], Batch [990/1045], Loss: 0.7501\n",
      "Epoch [8/30], Batch [1000/1045], Loss: 0.7115\n",
      "Epoch [8/30], Batch [1010/1045], Loss: 0.8474\n",
      "Epoch [8/30], Batch [1020/1045], Loss: 0.7027\n",
      "Epoch [8/30], Batch [1030/1045], Loss: 0.4651\n",
      "Epoch [8/30], Batch [1040/1045], Loss: 0.5945\n",
      "Epoch [8/30] - Average Loss: 0.6234, Accuracy: 0.7534\n",
      "Epoch [9/30], Batch [10/1045], Loss: 0.6699\n",
      "Epoch [9/30], Batch [20/1045], Loss: 0.6607\n",
      "Epoch [9/30], Batch [30/1045], Loss: 0.6868\n",
      "Epoch [9/30], Batch [40/1045], Loss: 0.8254\n",
      "Epoch [9/30], Batch [50/1045], Loss: 0.7175\n",
      "Epoch [9/30], Batch [60/1045], Loss: 0.7410\n",
      "Epoch [9/30], Batch [70/1045], Loss: 0.7504\n",
      "Epoch [9/30], Batch [80/1045], Loss: 0.8120\n",
      "Epoch [9/30], Batch [90/1045], Loss: 0.4439\n",
      "Epoch [9/30], Batch [100/1045], Loss: 0.5522\n",
      "Epoch [9/30], Batch [110/1045], Loss: 0.8348\n",
      "Epoch [9/30], Batch [120/1045], Loss: 0.6371\n",
      "Epoch [9/30], Batch [130/1045], Loss: 0.4896\n",
      "Epoch [9/30], Batch [140/1045], Loss: 0.6309\n",
      "Epoch [9/30], Batch [150/1045], Loss: 0.3873\n",
      "Epoch [9/30], Batch [160/1045], Loss: 0.7844\n",
      "Epoch [9/30], Batch [170/1045], Loss: 0.6656\n",
      "Epoch [9/30], Batch [180/1045], Loss: 0.6770\n",
      "Epoch [9/30], Batch [190/1045], Loss: 0.6485\n",
      "Epoch [9/30], Batch [200/1045], Loss: 0.6242\n",
      "Epoch [9/30], Batch [210/1045], Loss: 0.5267\n",
      "Epoch [9/30], Batch [220/1045], Loss: 0.4894\n",
      "Epoch [9/30], Batch [230/1045], Loss: 0.3985\n",
      "Epoch [9/30], Batch [240/1045], Loss: 0.6269\n",
      "Epoch [9/30], Batch [250/1045], Loss: 0.4291\n",
      "Epoch [9/30], Batch [260/1045], Loss: 0.5822\n",
      "Epoch [9/30], Batch [270/1045], Loss: 0.6866\n",
      "Epoch [9/30], Batch [280/1045], Loss: 0.4347\n",
      "Epoch [9/30], Batch [290/1045], Loss: 0.6832\n",
      "Epoch [9/30], Batch [300/1045], Loss: 0.6153\n",
      "Epoch [9/30], Batch [310/1045], Loss: 0.9951\n",
      "Epoch [9/30], Batch [320/1045], Loss: 0.5068\n",
      "Epoch [9/30], Batch [330/1045], Loss: 0.4674\n",
      "Epoch [9/30], Batch [340/1045], Loss: 0.4992\n",
      "Epoch [9/30], Batch [350/1045], Loss: 0.4057\n",
      "Epoch [9/30], Batch [360/1045], Loss: 0.6884\n",
      "Epoch [9/30], Batch [370/1045], Loss: 0.7516\n",
      "Epoch [9/30], Batch [380/1045], Loss: 0.5861\n",
      "Epoch [9/30], Batch [390/1045], Loss: 0.7191\n",
      "Epoch [9/30], Batch [400/1045], Loss: 0.4676\n",
      "Epoch [9/30], Batch [410/1045], Loss: 0.5561\n",
      "Epoch [9/30], Batch [420/1045], Loss: 0.5688\n",
      "Epoch [9/30], Batch [430/1045], Loss: 0.7306\n",
      "Epoch [9/30], Batch [440/1045], Loss: 0.5322\n",
      "Epoch [9/30], Batch [450/1045], Loss: 0.5712\n",
      "Epoch [9/30], Batch [460/1045], Loss: 0.7075\n",
      "Epoch [9/30], Batch [470/1045], Loss: 0.4188\n",
      "Epoch [9/30], Batch [480/1045], Loss: 0.6175\n",
      "Epoch [9/30], Batch [490/1045], Loss: 0.6441\n",
      "Epoch [9/30], Batch [500/1045], Loss: 0.4921\n",
      "Epoch [9/30], Batch [510/1045], Loss: 0.5288\n",
      "Epoch [9/30], Batch [520/1045], Loss: 0.6221\n",
      "Epoch [9/30], Batch [530/1045], Loss: 0.7495\n",
      "Epoch [9/30], Batch [540/1045], Loss: 0.7391\n",
      "Epoch [9/30], Batch [550/1045], Loss: 0.5449\n",
      "Epoch [9/30], Batch [560/1045], Loss: 0.7165\n",
      "Epoch [9/30], Batch [570/1045], Loss: 0.5299\n",
      "Epoch [9/30], Batch [580/1045], Loss: 0.3866\n",
      "Epoch [9/30], Batch [590/1045], Loss: 0.4585\n",
      "Epoch [9/30], Batch [600/1045], Loss: 0.7473\n",
      "Epoch [9/30], Batch [610/1045], Loss: 0.4291\n",
      "Epoch [9/30], Batch [620/1045], Loss: 0.4995\n",
      "Epoch [9/30], Batch [630/1045], Loss: 0.6510\n",
      "Epoch [9/30], Batch [640/1045], Loss: 0.4184\n",
      "Epoch [9/30], Batch [650/1045], Loss: 0.5651\n",
      "Epoch [9/30], Batch [660/1045], Loss: 0.4743\n",
      "Epoch [9/30], Batch [670/1045], Loss: 0.5783\n",
      "Epoch [9/30], Batch [680/1045], Loss: 0.7504\n",
      "Epoch [9/30], Batch [690/1045], Loss: 0.6497\n",
      "Epoch [9/30], Batch [700/1045], Loss: 0.5800\n",
      "Epoch [9/30], Batch [710/1045], Loss: 0.4975\n",
      "Epoch [9/30], Batch [720/1045], Loss: 0.6329\n",
      "Epoch [9/30], Batch [730/1045], Loss: 0.4543\n",
      "Epoch [9/30], Batch [740/1045], Loss: 0.5695\n",
      "Epoch [9/30], Batch [750/1045], Loss: 0.7278\n",
      "Epoch [9/30], Batch [760/1045], Loss: 0.5184\n",
      "Epoch [9/30], Batch [770/1045], Loss: 0.6815\n",
      "Epoch [9/30], Batch [780/1045], Loss: 0.4774\n",
      "Epoch [9/30], Batch [790/1045], Loss: 0.7988\n",
      "Epoch [9/30], Batch [800/1045], Loss: 0.3980\n",
      "Epoch [9/30], Batch [810/1045], Loss: 0.6426\n",
      "Epoch [9/30], Batch [820/1045], Loss: 0.5994\n",
      "Epoch [9/30], Batch [830/1045], Loss: 1.0276\n",
      "Epoch [9/30], Batch [840/1045], Loss: 0.5813\n",
      "Epoch [9/30], Batch [850/1045], Loss: 0.5944\n",
      "Epoch [9/30], Batch [860/1045], Loss: 0.6331\n",
      "Epoch [9/30], Batch [870/1045], Loss: 0.7114\n",
      "Epoch [9/30], Batch [880/1045], Loss: 0.4884\n",
      "Epoch [9/30], Batch [890/1045], Loss: 0.6609\n",
      "Epoch [9/30], Batch [900/1045], Loss: 0.5056\n",
      "Epoch [9/30], Batch [910/1045], Loss: 0.4571\n",
      "Epoch [9/30], Batch [920/1045], Loss: 0.4701\n",
      "Epoch [9/30], Batch [930/1045], Loss: 0.8086\n",
      "Epoch [9/30], Batch [940/1045], Loss: 0.6808\n",
      "Epoch [9/30], Batch [950/1045], Loss: 0.7801\n",
      "Epoch [9/30], Batch [960/1045], Loss: 0.5396\n",
      "Epoch [9/30], Batch [970/1045], Loss: 0.5315\n",
      "Epoch [9/30], Batch [980/1045], Loss: 0.4714\n",
      "Epoch [9/30], Batch [990/1045], Loss: 0.6084\n",
      "Epoch [9/30], Batch [1000/1045], Loss: 0.6400\n",
      "Epoch [9/30], Batch [1010/1045], Loss: 0.5702\n",
      "Epoch [9/30], Batch [1020/1045], Loss: 0.7224\n",
      "Epoch [9/30], Batch [1030/1045], Loss: 0.4516\n",
      "Epoch [9/30], Batch [1040/1045], Loss: 0.5674\n",
      "Epoch [9/30] - Average Loss: 0.6207, Accuracy: 0.7518\n",
      "Epoch [10/30], Batch [10/1045], Loss: 0.6106\n",
      "Epoch [10/30], Batch [20/1045], Loss: 0.7031\n",
      "Epoch [10/30], Batch [30/1045], Loss: 0.6629\n",
      "Epoch [10/30], Batch [40/1045], Loss: 0.7394\n",
      "Epoch [10/30], Batch [50/1045], Loss: 0.6363\n",
      "Epoch [10/30], Batch [60/1045], Loss: 0.5301\n",
      "Epoch [10/30], Batch [70/1045], Loss: 0.6621\n",
      "Epoch [10/30], Batch [80/1045], Loss: 0.5726\n",
      "Epoch [10/30], Batch [90/1045], Loss: 0.6916\n",
      "Epoch [10/30], Batch [100/1045], Loss: 0.6563\n",
      "Epoch [10/30], Batch [110/1045], Loss: 0.5744\n",
      "Epoch [10/30], Batch [120/1045], Loss: 0.4054\n",
      "Epoch [10/30], Batch [130/1045], Loss: 0.7159\n",
      "Epoch [10/30], Batch [140/1045], Loss: 0.7701\n",
      "Epoch [10/30], Batch [150/1045], Loss: 0.8439\n",
      "Epoch [10/30], Batch [160/1045], Loss: 0.3678\n",
      "Epoch [10/30], Batch [170/1045], Loss: 0.4273\n",
      "Epoch [10/30], Batch [180/1045], Loss: 0.4795\n",
      "Epoch [10/30], Batch [190/1045], Loss: 1.0257\n",
      "Epoch [10/30], Batch [200/1045], Loss: 0.9884\n",
      "Epoch [10/30], Batch [210/1045], Loss: 0.4128\n",
      "Epoch [10/30], Batch [220/1045], Loss: 0.5291\n",
      "Epoch [10/30], Batch [230/1045], Loss: 0.5767\n",
      "Epoch [10/30], Batch [240/1045], Loss: 0.7244\n",
      "Epoch [10/30], Batch [250/1045], Loss: 0.4857\n",
      "Epoch [10/30], Batch [260/1045], Loss: 0.7087\n",
      "Epoch [10/30], Batch [270/1045], Loss: 0.5704\n",
      "Epoch [10/30], Batch [280/1045], Loss: 0.5176\n",
      "Epoch [10/30], Batch [290/1045], Loss: 0.3471\n",
      "Epoch [10/30], Batch [300/1045], Loss: 0.4781\n",
      "Epoch [10/30], Batch [310/1045], Loss: 0.6805\n",
      "Epoch [10/30], Batch [320/1045], Loss: 0.6421\n",
      "Epoch [10/30], Batch [330/1045], Loss: 0.5561\n",
      "Epoch [10/30], Batch [340/1045], Loss: 0.6205\n",
      "Epoch [10/30], Batch [350/1045], Loss: 0.5329\n",
      "Epoch [10/30], Batch [360/1045], Loss: 0.3948\n",
      "Epoch [10/30], Batch [370/1045], Loss: 0.4855\n",
      "Epoch [10/30], Batch [380/1045], Loss: 0.7966\n",
      "Epoch [10/30], Batch [390/1045], Loss: 0.4804\n",
      "Epoch [10/30], Batch [400/1045], Loss: 0.5763\n",
      "Epoch [10/30], Batch [410/1045], Loss: 0.6729\n",
      "Epoch [10/30], Batch [420/1045], Loss: 0.4937\n",
      "Epoch [10/30], Batch [430/1045], Loss: 0.8927\n",
      "Epoch [10/30], Batch [440/1045], Loss: 0.6502\n",
      "Epoch [10/30], Batch [450/1045], Loss: 0.7691\n",
      "Epoch [10/30], Batch [460/1045], Loss: 0.6849\n",
      "Epoch [10/30], Batch [470/1045], Loss: 0.6597\n",
      "Epoch [10/30], Batch [480/1045], Loss: 0.7242\n",
      "Epoch [10/30], Batch [490/1045], Loss: 0.6505\n",
      "Epoch [10/30], Batch [500/1045], Loss: 0.7320\n",
      "Epoch [10/30], Batch [510/1045], Loss: 0.6592\n",
      "Epoch [10/30], Batch [520/1045], Loss: 0.6325\n",
      "Epoch [10/30], Batch [530/1045], Loss: 0.6716\n",
      "Epoch [10/30], Batch [540/1045], Loss: 0.4455\n",
      "Epoch [10/30], Batch [550/1045], Loss: 0.3650\n",
      "Epoch [10/30], Batch [560/1045], Loss: 0.6183\n",
      "Epoch [10/30], Batch [570/1045], Loss: 0.5125\n",
      "Epoch [10/30], Batch [580/1045], Loss: 0.5908\n",
      "Epoch [10/30], Batch [590/1045], Loss: 0.6407\n",
      "Epoch [10/30], Batch [600/1045], Loss: 0.4933\n",
      "Epoch [10/30], Batch [610/1045], Loss: 0.6916\n",
      "Epoch [10/30], Batch [620/1045], Loss: 0.7990\n",
      "Epoch [10/30], Batch [630/1045], Loss: 0.7615\n",
      "Epoch [10/30], Batch [640/1045], Loss: 0.4047\n",
      "Epoch [10/30], Batch [650/1045], Loss: 0.6500\n",
      "Epoch [10/30], Batch [660/1045], Loss: 0.7563\n",
      "Epoch [10/30], Batch [670/1045], Loss: 0.7621\n",
      "Epoch [10/30], Batch [680/1045], Loss: 0.5174\n",
      "Epoch [10/30], Batch [690/1045], Loss: 0.6402\n",
      "Epoch [10/30], Batch [700/1045], Loss: 0.3652\n",
      "Epoch [10/30], Batch [710/1045], Loss: 0.6508\n",
      "Epoch [10/30], Batch [720/1045], Loss: 0.4276\n",
      "Epoch [10/30], Batch [730/1045], Loss: 0.5589\n",
      "Epoch [10/30], Batch [740/1045], Loss: 0.8007\n",
      "Epoch [10/30], Batch [750/1045], Loss: 0.4659\n",
      "Epoch [10/30], Batch [760/1045], Loss: 0.5927\n",
      "Epoch [10/30], Batch [770/1045], Loss: 0.5606\n",
      "Epoch [10/30], Batch [780/1045], Loss: 0.5322\n",
      "Epoch [10/30], Batch [790/1045], Loss: 0.8021\n",
      "Epoch [10/30], Batch [800/1045], Loss: 0.5321\n",
      "Epoch [10/30], Batch [810/1045], Loss: 0.7278\n",
      "Epoch [10/30], Batch [820/1045], Loss: 0.4587\n",
      "Epoch [10/30], Batch [830/1045], Loss: 0.5105\n",
      "Epoch [10/30], Batch [840/1045], Loss: 0.7026\n",
      "Epoch [10/30], Batch [850/1045], Loss: 0.6149\n",
      "Epoch [10/30], Batch [860/1045], Loss: 0.9178\n",
      "Epoch [10/30], Batch [870/1045], Loss: 0.9495\n",
      "Epoch [10/30], Batch [880/1045], Loss: 0.5996\n",
      "Epoch [10/30], Batch [890/1045], Loss: 0.6745\n",
      "Epoch [10/30], Batch [900/1045], Loss: 0.7331\n",
      "Epoch [10/30], Batch [910/1045], Loss: 0.5314\n",
      "Epoch [10/30], Batch [920/1045], Loss: 0.3557\n",
      "Epoch [10/30], Batch [930/1045], Loss: 0.7221\n",
      "Epoch [10/30], Batch [940/1045], Loss: 0.5874\n",
      "Epoch [10/30], Batch [950/1045], Loss: 0.4777\n",
      "Epoch [10/30], Batch [960/1045], Loss: 0.4906\n",
      "Epoch [10/30], Batch [970/1045], Loss: 0.6821\n",
      "Epoch [10/30], Batch [980/1045], Loss: 0.6298\n",
      "Epoch [10/30], Batch [990/1045], Loss: 0.2849\n",
      "Epoch [10/30], Batch [1000/1045], Loss: 0.5749\n",
      "Epoch [10/30], Batch [1010/1045], Loss: 0.7727\n",
      "Epoch [10/30], Batch [1020/1045], Loss: 0.5843\n",
      "Epoch [10/30], Batch [1030/1045], Loss: 0.5542\n",
      "Epoch [10/30], Batch [1040/1045], Loss: 0.3097\n",
      "Epoch [10/30] - Average Loss: 0.6107, Accuracy: 0.7537\n",
      "Epoch [11/30], Batch [10/1045], Loss: 0.8458\n",
      "Epoch [11/30], Batch [20/1045], Loss: 0.4652\n",
      "Epoch [11/30], Batch [30/1045], Loss: 0.4986\n",
      "Epoch [11/30], Batch [40/1045], Loss: 0.4882\n",
      "Epoch [11/30], Batch [50/1045], Loss: 0.7421\n",
      "Epoch [11/30], Batch [60/1045], Loss: 0.5290\n",
      "Epoch [11/30], Batch [70/1045], Loss: 0.6794\n",
      "Epoch [11/30], Batch [80/1045], Loss: 0.2667\n",
      "Epoch [11/30], Batch [90/1045], Loss: 0.8136\n",
      "Epoch [11/30], Batch [100/1045], Loss: 0.6481\n",
      "Epoch [11/30], Batch [110/1045], Loss: 0.4588\n",
      "Epoch [11/30], Batch [120/1045], Loss: 0.5610\n",
      "Epoch [11/30], Batch [130/1045], Loss: 0.4961\n",
      "Epoch [11/30], Batch [140/1045], Loss: 0.5133\n",
      "Epoch [11/30], Batch [150/1045], Loss: 0.4806\n",
      "Epoch [11/30], Batch [160/1045], Loss: 0.5746\n",
      "Epoch [11/30], Batch [170/1045], Loss: 0.6750\n",
      "Epoch [11/30], Batch [180/1045], Loss: 0.8043\n",
      "Epoch [11/30], Batch [190/1045], Loss: 0.7094\n",
      "Epoch [11/30], Batch [200/1045], Loss: 0.6698\n",
      "Epoch [11/30], Batch [210/1045], Loss: 0.7881\n",
      "Epoch [11/30], Batch [220/1045], Loss: 0.5295\n",
      "Epoch [11/30], Batch [230/1045], Loss: 0.6928\n",
      "Epoch [11/30], Batch [240/1045], Loss: 0.6652\n",
      "Epoch [11/30], Batch [250/1045], Loss: 0.3627\n",
      "Epoch [11/30], Batch [260/1045], Loss: 0.6298\n",
      "Epoch [11/30], Batch [270/1045], Loss: 0.4243\n",
      "Epoch [11/30], Batch [280/1045], Loss: 0.4256\n",
      "Epoch [11/30], Batch [290/1045], Loss: 0.4238\n",
      "Epoch [11/30], Batch [300/1045], Loss: 0.5178\n",
      "Epoch [11/30], Batch [310/1045], Loss: 0.8346\n",
      "Epoch [11/30], Batch [320/1045], Loss: 0.6945\n",
      "Epoch [11/30], Batch [330/1045], Loss: 0.4582\n",
      "Epoch [11/30], Batch [340/1045], Loss: 0.6463\n",
      "Epoch [11/30], Batch [350/1045], Loss: 0.5970\n",
      "Epoch [11/30], Batch [360/1045], Loss: 0.8097\n",
      "Epoch [11/30], Batch [370/1045], Loss: 1.5373\n",
      "Epoch [11/30], Batch [380/1045], Loss: 0.4882\n",
      "Epoch [11/30], Batch [390/1045], Loss: 0.3823\n",
      "Epoch [11/30], Batch [400/1045], Loss: 0.5493\n",
      "Epoch [11/30], Batch [410/1045], Loss: 0.4273\n",
      "Epoch [11/30], Batch [420/1045], Loss: 1.0027\n",
      "Epoch [11/30], Batch [430/1045], Loss: 0.5461\n",
      "Epoch [11/30], Batch [440/1045], Loss: 0.6556\n",
      "Epoch [11/30], Batch [450/1045], Loss: 0.5544\n",
      "Epoch [11/30], Batch [460/1045], Loss: 0.5196\n",
      "Epoch [11/30], Batch [470/1045], Loss: 0.7857\n",
      "Epoch [11/30], Batch [480/1045], Loss: 0.5022\n",
      "Epoch [11/30], Batch [490/1045], Loss: 0.5284\n",
      "Epoch [11/30], Batch [500/1045], Loss: 0.6594\n",
      "Epoch [11/30], Batch [510/1045], Loss: 0.7297\n",
      "Epoch [11/30], Batch [520/1045], Loss: 0.6284\n",
      "Epoch [11/30], Batch [530/1045], Loss: 0.3930\n",
      "Epoch [11/30], Batch [540/1045], Loss: 0.6675\n",
      "Epoch [11/30], Batch [550/1045], Loss: 0.6250\n",
      "Epoch [11/30], Batch [560/1045], Loss: 0.6378\n",
      "Epoch [11/30], Batch [570/1045], Loss: 0.7730\n",
      "Epoch [11/30], Batch [580/1045], Loss: 0.3189\n",
      "Epoch [11/30], Batch [590/1045], Loss: 0.6962\n",
      "Epoch [11/30], Batch [600/1045], Loss: 0.5610\n",
      "Epoch [11/30], Batch [610/1045], Loss: 0.6022\n",
      "Epoch [11/30], Batch [620/1045], Loss: 0.8826\n",
      "Epoch [11/30], Batch [630/1045], Loss: 0.6316\n",
      "Epoch [11/30], Batch [640/1045], Loss: 0.5393\n",
      "Epoch [11/30], Batch [650/1045], Loss: 0.4472\n",
      "Epoch [11/30], Batch [660/1045], Loss: 0.5759\n",
      "Epoch [11/30], Batch [670/1045], Loss: 0.5440\n",
      "Epoch [11/30], Batch [680/1045], Loss: 0.8281\n",
      "Epoch [11/30], Batch [690/1045], Loss: 0.4209\n",
      "Epoch [11/30], Batch [700/1045], Loss: 0.4895\n",
      "Epoch [11/30], Batch [710/1045], Loss: 0.4815\n",
      "Epoch [11/30], Batch [720/1045], Loss: 0.7977\n",
      "Epoch [11/30], Batch [730/1045], Loss: 0.5012\n",
      "Epoch [11/30], Batch [740/1045], Loss: 0.5959\n",
      "Epoch [11/30], Batch [750/1045], Loss: 0.6836\n",
      "Epoch [11/30], Batch [760/1045], Loss: 0.4622\n",
      "Epoch [11/30], Batch [770/1045], Loss: 0.6130\n",
      "Epoch [11/30], Batch [780/1045], Loss: 0.6320\n",
      "Epoch [11/30], Batch [790/1045], Loss: 0.6674\n",
      "Epoch [11/30], Batch [800/1045], Loss: 0.5986\n",
      "Epoch [11/30], Batch [810/1045], Loss: 0.5670\n",
      "Epoch [11/30], Batch [820/1045], Loss: 0.3990\n",
      "Epoch [11/30], Batch [830/1045], Loss: 0.8063\n",
      "Epoch [11/30], Batch [840/1045], Loss: 0.6187\n",
      "Epoch [11/30], Batch [850/1045], Loss: 0.6330\n",
      "Epoch [11/30], Batch [860/1045], Loss: 0.5499\n",
      "Epoch [11/30], Batch [870/1045], Loss: 0.7898\n",
      "Epoch [11/30], Batch [880/1045], Loss: 0.6673\n",
      "Epoch [11/30], Batch [890/1045], Loss: 0.5575\n",
      "Epoch [11/30], Batch [900/1045], Loss: 0.4858\n",
      "Epoch [11/30], Batch [910/1045], Loss: 0.4260\n",
      "Epoch [11/30], Batch [920/1045], Loss: 0.6308\n",
      "Epoch [11/30], Batch [930/1045], Loss: 0.8431\n",
      "Epoch [11/30], Batch [940/1045], Loss: 0.7354\n",
      "Epoch [11/30], Batch [950/1045], Loss: 0.4393\n",
      "Epoch [11/30], Batch [960/1045], Loss: 0.4879\n",
      "Epoch [11/30], Batch [970/1045], Loss: 0.6261\n",
      "Epoch [11/30], Batch [980/1045], Loss: 0.6275\n",
      "Epoch [11/30], Batch [990/1045], Loss: 0.4536\n",
      "Epoch [11/30], Batch [1000/1045], Loss: 0.5231\n",
      "Epoch [11/30], Batch [1010/1045], Loss: 0.7462\n",
      "Epoch [11/30], Batch [1020/1045], Loss: 0.5778\n",
      "Epoch [11/30], Batch [1030/1045], Loss: 0.7233\n",
      "Epoch [11/30], Batch [1040/1045], Loss: 1.1833\n",
      "Epoch [11/30] - Average Loss: 0.6062, Accuracy: 0.7542\n",
      "Epoch [12/30], Batch [10/1045], Loss: 0.5719\n",
      "Epoch [12/30], Batch [20/1045], Loss: 0.4418\n",
      "Epoch [12/30], Batch [30/1045], Loss: 0.5674\n",
      "Epoch [12/30], Batch [40/1045], Loss: 0.5750\n",
      "Epoch [12/30], Batch [50/1045], Loss: 0.3908\n",
      "Epoch [12/30], Batch [60/1045], Loss: 0.8683\n",
      "Epoch [12/30], Batch [70/1045], Loss: 0.7385\n",
      "Epoch [12/30], Batch [80/1045], Loss: 0.6281\n",
      "Epoch [12/30], Batch [90/1045], Loss: 0.5056\n",
      "Epoch [12/30], Batch [100/1045], Loss: 0.4452\n",
      "Epoch [12/30], Batch [110/1045], Loss: 0.5434\n",
      "Epoch [12/30], Batch [120/1045], Loss: 0.6279\n",
      "Epoch [12/30], Batch [130/1045], Loss: 0.5839\n",
      "Epoch [12/30], Batch [140/1045], Loss: 0.4595\n",
      "Epoch [12/30], Batch [150/1045], Loss: 0.7361\n",
      "Epoch [12/30], Batch [160/1045], Loss: 0.7677\n",
      "Epoch [12/30], Batch [170/1045], Loss: 0.4913\n",
      "Epoch [12/30], Batch [180/1045], Loss: 0.6776\n",
      "Epoch [12/30], Batch [190/1045], Loss: 0.7815\n",
      "Epoch [12/30], Batch [200/1045], Loss: 0.5209\n",
      "Epoch [12/30], Batch [210/1045], Loss: 0.6740\n",
      "Epoch [12/30], Batch [220/1045], Loss: 0.5563\n",
      "Epoch [12/30], Batch [230/1045], Loss: 0.9188\n",
      "Epoch [12/30], Batch [240/1045], Loss: 0.7217\n",
      "Epoch [12/30], Batch [250/1045], Loss: 0.4900\n",
      "Epoch [12/30], Batch [260/1045], Loss: 0.4705\n",
      "Epoch [12/30], Batch [270/1045], Loss: 0.6259\n",
      "Epoch [12/30], Batch [280/1045], Loss: 0.4945\n",
      "Epoch [12/30], Batch [290/1045], Loss: 0.8094\n",
      "Epoch [12/30], Batch [300/1045], Loss: 0.5209\n",
      "Epoch [12/30], Batch [310/1045], Loss: 0.6729\n",
      "Epoch [12/30], Batch [320/1045], Loss: 0.4909\n",
      "Epoch [12/30], Batch [330/1045], Loss: 0.5380\n",
      "Epoch [12/30], Batch [340/1045], Loss: 0.6230\n",
      "Epoch [12/30], Batch [350/1045], Loss: 0.4288\n",
      "Epoch [12/30], Batch [360/1045], Loss: 0.7767\n",
      "Epoch [12/30], Batch [370/1045], Loss: 0.7807\n",
      "Epoch [12/30], Batch [380/1045], Loss: 0.8827\n",
      "Epoch [12/30], Batch [390/1045], Loss: 0.7636\n",
      "Epoch [12/30], Batch [400/1045], Loss: 0.7477\n",
      "Epoch [12/30], Batch [410/1045], Loss: 0.4976\n",
      "Epoch [12/30], Batch [420/1045], Loss: 0.6305\n",
      "Epoch [12/30], Batch [430/1045], Loss: 0.7249\n",
      "Epoch [12/30], Batch [440/1045], Loss: 0.5267\n",
      "Epoch [12/30], Batch [450/1045], Loss: 0.8414\n",
      "Epoch [12/30], Batch [460/1045], Loss: 0.5517\n",
      "Epoch [12/30], Batch [470/1045], Loss: 0.5987\n",
      "Epoch [12/30], Batch [480/1045], Loss: 0.5401\n",
      "Epoch [12/30], Batch [490/1045], Loss: 0.6174\n",
      "Epoch [12/30], Batch [500/1045], Loss: 0.6417\n",
      "Epoch [12/30], Batch [510/1045], Loss: 0.5247\n",
      "Epoch [12/30], Batch [520/1045], Loss: 0.4951\n",
      "Epoch [12/30], Batch [530/1045], Loss: 0.4940\n",
      "Epoch [12/30], Batch [540/1045], Loss: 0.3970\n",
      "Epoch [12/30], Batch [550/1045], Loss: 0.4188\n",
      "Epoch [12/30], Batch [560/1045], Loss: 0.5390\n",
      "Epoch [12/30], Batch [570/1045], Loss: 0.9163\n",
      "Epoch [12/30], Batch [580/1045], Loss: 0.6592\n",
      "Epoch [12/30], Batch [590/1045], Loss: 0.6947\n",
      "Epoch [12/30], Batch [600/1045], Loss: 0.5682\n",
      "Epoch [12/30], Batch [610/1045], Loss: 0.7547\n",
      "Epoch [12/30], Batch [620/1045], Loss: 0.5834\n",
      "Epoch [12/30], Batch [630/1045], Loss: 0.6304\n",
      "Epoch [12/30], Batch [640/1045], Loss: 0.4175\n",
      "Epoch [12/30], Batch [650/1045], Loss: 0.7206\n",
      "Epoch [12/30], Batch [660/1045], Loss: 0.4605\n",
      "Epoch [12/30], Batch [670/1045], Loss: 0.6242\n",
      "Epoch [12/30], Batch [680/1045], Loss: 0.6468\n",
      "Epoch [12/30], Batch [690/1045], Loss: 0.5750\n",
      "Epoch [12/30], Batch [700/1045], Loss: 0.4935\n",
      "Epoch [12/30], Batch [710/1045], Loss: 0.5573\n",
      "Epoch [12/30], Batch [720/1045], Loss: 0.6498\n",
      "Epoch [12/30], Batch [730/1045], Loss: 0.4623\n",
      "Epoch [12/30], Batch [740/1045], Loss: 0.6045\n",
      "Epoch [12/30], Batch [750/1045], Loss: 0.5382\n",
      "Epoch [12/30], Batch [760/1045], Loss: 0.4677\n",
      "Epoch [12/30], Batch [770/1045], Loss: 0.5581\n",
      "Epoch [12/30], Batch [780/1045], Loss: 0.5379\n",
      "Epoch [12/30], Batch [790/1045], Loss: 0.5999\n",
      "Epoch [12/30], Batch [800/1045], Loss: 0.4247\n",
      "Epoch [12/30], Batch [810/1045], Loss: 0.6706\n",
      "Epoch [12/30], Batch [820/1045], Loss: 0.6775\n",
      "Epoch [12/30], Batch [830/1045], Loss: 0.7034\n",
      "Epoch [12/30], Batch [840/1045], Loss: 0.7550\n",
      "Epoch [12/30], Batch [850/1045], Loss: 0.4617\n",
      "Epoch [12/30], Batch [860/1045], Loss: 0.4522\n",
      "Epoch [12/30], Batch [870/1045], Loss: 0.5067\n",
      "Epoch [12/30], Batch [880/1045], Loss: 0.4862\n",
      "Epoch [12/30], Batch [890/1045], Loss: 0.6205\n",
      "Epoch [12/30], Batch [900/1045], Loss: 0.6636\n",
      "Epoch [12/30], Batch [910/1045], Loss: 0.6936\n",
      "Epoch [12/30], Batch [920/1045], Loss: 0.6003\n",
      "Epoch [12/30], Batch [930/1045], Loss: 0.6804\n",
      "Epoch [12/30], Batch [940/1045], Loss: 0.5342\n",
      "Epoch [12/30], Batch [950/1045], Loss: 0.4147\n",
      "Epoch [12/30], Batch [960/1045], Loss: 0.7121\n",
      "Epoch [12/30], Batch [970/1045], Loss: 0.6214\n",
      "Epoch [12/30], Batch [980/1045], Loss: 0.4540\n",
      "Epoch [12/30], Batch [990/1045], Loss: 0.5262\n",
      "Epoch [12/30], Batch [1000/1045], Loss: 0.6521\n",
      "Epoch [12/30], Batch [1010/1045], Loss: 0.3951\n",
      "Epoch [12/30], Batch [1020/1045], Loss: 0.3761\n",
      "Epoch [12/30], Batch [1030/1045], Loss: 0.7266\n",
      "Epoch [12/30], Batch [1040/1045], Loss: 0.9068\n",
      "Epoch [12/30] - Average Loss: 0.5964, Accuracy: 0.7564\n",
      "Epoch [13/30], Batch [10/1045], Loss: 0.5350\n",
      "Epoch [13/30], Batch [20/1045], Loss: 0.6244\n",
      "Epoch [13/30], Batch [30/1045], Loss: 0.6682\n",
      "Epoch [13/30], Batch [40/1045], Loss: 0.5755\n",
      "Epoch [13/30], Batch [50/1045], Loss: 0.4677\n",
      "Epoch [13/30], Batch [60/1045], Loss: 0.3918\n",
      "Epoch [13/30], Batch [70/1045], Loss: 0.5241\n",
      "Epoch [13/30], Batch [80/1045], Loss: 0.7398\n",
      "Epoch [13/30], Batch [90/1045], Loss: 0.6128\n",
      "Epoch [13/30], Batch [100/1045], Loss: 0.8186\n",
      "Epoch [13/30], Batch [110/1045], Loss: 0.5802\n",
      "Epoch [13/30], Batch [120/1045], Loss: 0.5731\n",
      "Epoch [13/30], Batch [130/1045], Loss: 0.3795\n",
      "Epoch [13/30], Batch [140/1045], Loss: 0.4039\n",
      "Epoch [13/30], Batch [150/1045], Loss: 0.4806\n",
      "Epoch [13/30], Batch [160/1045], Loss: 0.3541\n",
      "Epoch [13/30], Batch [170/1045], Loss: 0.7158\n",
      "Epoch [13/30], Batch [180/1045], Loss: 0.7691\n",
      "Epoch [13/30], Batch [190/1045], Loss: 0.7114\n",
      "Epoch [13/30], Batch [200/1045], Loss: 0.5012\n",
      "Epoch [13/30], Batch [210/1045], Loss: 0.7684\n",
      "Epoch [13/30], Batch [220/1045], Loss: 0.7825\n",
      "Epoch [13/30], Batch [230/1045], Loss: 0.4560\n",
      "Epoch [13/30], Batch [240/1045], Loss: 0.7310\n",
      "Epoch [13/30], Batch [250/1045], Loss: 0.5355\n",
      "Epoch [13/30], Batch [260/1045], Loss: 0.6337\n",
      "Epoch [13/30], Batch [270/1045], Loss: 0.5048\n",
      "Epoch [13/30], Batch [280/1045], Loss: 0.5733\n",
      "Epoch [13/30], Batch [290/1045], Loss: 0.4461\n",
      "Epoch [13/30], Batch [300/1045], Loss: 0.4936\n",
      "Epoch [13/30], Batch [310/1045], Loss: 0.4691\n",
      "Epoch [13/30], Batch [320/1045], Loss: 0.6923\n",
      "Epoch [13/30], Batch [330/1045], Loss: 0.8124\n",
      "Epoch [13/30], Batch [340/1045], Loss: 0.6885\n",
      "Epoch [13/30], Batch [350/1045], Loss: 0.4315\n",
      "Epoch [13/30], Batch [360/1045], Loss: 0.9576\n",
      "Epoch [13/30], Batch [370/1045], Loss: 0.4508\n",
      "Epoch [13/30], Batch [380/1045], Loss: 0.6225\n",
      "Epoch [13/30], Batch [390/1045], Loss: 0.6871\n",
      "Epoch [13/30], Batch [400/1045], Loss: 0.7334\n",
      "Epoch [13/30], Batch [410/1045], Loss: 0.7536\n",
      "Epoch [13/30], Batch [420/1045], Loss: 0.6720\n",
      "Epoch [13/30], Batch [430/1045], Loss: 0.4811\n",
      "Epoch [13/30], Batch [440/1045], Loss: 0.5232\n",
      "Epoch [13/30], Batch [450/1045], Loss: 0.4889\n",
      "Epoch [13/30], Batch [460/1045], Loss: 0.5095\n",
      "Epoch [13/30], Batch [470/1045], Loss: 0.6747\n",
      "Epoch [13/30], Batch [480/1045], Loss: 0.3579\n",
      "Epoch [13/30], Batch [490/1045], Loss: 0.8543\n",
      "Epoch [13/30], Batch [500/1045], Loss: 0.7216\n",
      "Epoch [13/30], Batch [510/1045], Loss: 0.6111\n",
      "Epoch [13/30], Batch [520/1045], Loss: 0.4935\n",
      "Epoch [13/30], Batch [530/1045], Loss: 0.6506\n",
      "Epoch [13/30], Batch [540/1045], Loss: 0.8189\n",
      "Epoch [13/30], Batch [550/1045], Loss: 0.4049\n",
      "Epoch [13/30], Batch [560/1045], Loss: 0.5415\n",
      "Epoch [13/30], Batch [570/1045], Loss: 0.5557\n",
      "Epoch [13/30], Batch [580/1045], Loss: 0.5463\n",
      "Epoch [13/30], Batch [590/1045], Loss: 0.5582\n",
      "Epoch [13/30], Batch [600/1045], Loss: 0.7465\n",
      "Epoch [13/30], Batch [610/1045], Loss: 0.5560\n",
      "Epoch [13/30], Batch [620/1045], Loss: 0.6262\n",
      "Epoch [13/30], Batch [630/1045], Loss: 0.8378\n",
      "Epoch [13/30], Batch [640/1045], Loss: 0.5621\n",
      "Epoch [13/30], Batch [650/1045], Loss: 0.6779\n",
      "Epoch [13/30], Batch [660/1045], Loss: 1.1561\n",
      "Epoch [13/30], Batch [670/1045], Loss: 0.7756\n",
      "Epoch [13/30], Batch [680/1045], Loss: 0.5608\n",
      "Epoch [13/30], Batch [690/1045], Loss: 0.6683\n",
      "Epoch [13/30], Batch [700/1045], Loss: 0.8415\n",
      "Epoch [13/30], Batch [710/1045], Loss: 0.4985\n",
      "Epoch [13/30], Batch [720/1045], Loss: 0.6583\n",
      "Epoch [13/30], Batch [730/1045], Loss: 0.3750\n",
      "Epoch [13/30], Batch [740/1045], Loss: 0.6136\n",
      "Epoch [13/30], Batch [750/1045], Loss: 0.6355\n",
      "Epoch [13/30], Batch [760/1045], Loss: 0.5119\n",
      "Epoch [13/30], Batch [770/1045], Loss: 0.4506\n",
      "Epoch [13/30], Batch [780/1045], Loss: 0.2127\n",
      "Epoch [13/30], Batch [790/1045], Loss: 0.6001\n",
      "Epoch [13/30], Batch [800/1045], Loss: 0.5716\n",
      "Epoch [13/30], Batch [810/1045], Loss: 0.5151\n",
      "Epoch [13/30], Batch [820/1045], Loss: 0.6593\n",
      "Epoch [13/30], Batch [830/1045], Loss: 0.5585\n",
      "Epoch [13/30], Batch [840/1045], Loss: 0.5903\n",
      "Epoch [13/30], Batch [850/1045], Loss: 0.3520\n",
      "Epoch [13/30], Batch [860/1045], Loss: 0.6510\n",
      "Epoch [13/30], Batch [870/1045], Loss: 0.4681\n",
      "Epoch [13/30], Batch [880/1045], Loss: 0.6297\n",
      "Epoch [13/30], Batch [890/1045], Loss: 0.6240\n",
      "Epoch [13/30], Batch [900/1045], Loss: 0.5880\n",
      "Epoch [13/30], Batch [910/1045], Loss: 0.6065\n",
      "Epoch [13/30], Batch [920/1045], Loss: 0.4267\n",
      "Epoch [13/30], Batch [930/1045], Loss: 0.5913\n",
      "Epoch [13/30], Batch [940/1045], Loss: 0.4623\n",
      "Epoch [13/30], Batch [950/1045], Loss: 0.5333\n",
      "Epoch [13/30], Batch [960/1045], Loss: 0.5566\n",
      "Epoch [13/30], Batch [970/1045], Loss: 0.5569\n",
      "Epoch [13/30], Batch [980/1045], Loss: 0.3884\n",
      "Epoch [13/30], Batch [990/1045], Loss: 0.3832\n",
      "Epoch [13/30], Batch [1000/1045], Loss: 0.6486\n",
      "Epoch [13/30], Batch [1010/1045], Loss: 0.8466\n",
      "Epoch [13/30], Batch [1020/1045], Loss: 0.5029\n",
      "Epoch [13/30], Batch [1030/1045], Loss: 0.5424\n",
      "Epoch [13/30], Batch [1040/1045], Loss: 0.5933\n",
      "Epoch [13/30] - Average Loss: 0.5894, Accuracy: 0.7565\n",
      "Epoch [14/30], Batch [10/1045], Loss: 0.6545\n",
      "Epoch [14/30], Batch [20/1045], Loss: 0.5897\n",
      "Epoch [14/30], Batch [30/1045], Loss: 0.5529\n",
      "Epoch [14/30], Batch [40/1045], Loss: 0.7410\n",
      "Epoch [14/30], Batch [50/1045], Loss: 0.4872\n",
      "Epoch [14/30], Batch [60/1045], Loss: 0.5664\n",
      "Epoch [14/30], Batch [70/1045], Loss: 0.3650\n",
      "Epoch [14/30], Batch [80/1045], Loss: 0.7812\n",
      "Epoch [14/30], Batch [90/1045], Loss: 0.5257\n",
      "Epoch [14/30], Batch [100/1045], Loss: 0.5091\n",
      "Epoch [14/30], Batch [110/1045], Loss: 0.5441\n",
      "Epoch [14/30], Batch [120/1045], Loss: 0.4391\n",
      "Epoch [14/30], Batch [130/1045], Loss: 0.8980\n",
      "Epoch [14/30], Batch [140/1045], Loss: 0.5679\n",
      "Epoch [14/30], Batch [150/1045], Loss: 0.5702\n",
      "Epoch [14/30], Batch [160/1045], Loss: 0.5279\n",
      "Epoch [14/30], Batch [170/1045], Loss: 0.5224\n",
      "Epoch [14/30], Batch [180/1045], Loss: 0.7854\n",
      "Epoch [14/30], Batch [190/1045], Loss: 0.3457\n",
      "Epoch [14/30], Batch [200/1045], Loss: 0.4867\n",
      "Epoch [14/30], Batch [210/1045], Loss: 0.6158\n",
      "Epoch [14/30], Batch [220/1045], Loss: 0.6039\n",
      "Epoch [14/30], Batch [230/1045], Loss: 0.6447\n",
      "Epoch [14/30], Batch [240/1045], Loss: 0.8702\n",
      "Epoch [14/30], Batch [250/1045], Loss: 0.5327\n",
      "Epoch [14/30], Batch [260/1045], Loss: 0.5919\n",
      "Epoch [14/30], Batch [270/1045], Loss: 0.7066\n",
      "Epoch [14/30], Batch [280/1045], Loss: 0.6647\n",
      "Epoch [14/30], Batch [290/1045], Loss: 0.8874\n",
      "Epoch [14/30], Batch [300/1045], Loss: 0.4976\n",
      "Epoch [14/30], Batch [310/1045], Loss: 0.3801\n",
      "Epoch [14/30], Batch [320/1045], Loss: 0.6135\n",
      "Epoch [14/30], Batch [330/1045], Loss: 0.6635\n",
      "Epoch [14/30], Batch [340/1045], Loss: 0.7160\n",
      "Epoch [14/30], Batch [350/1045], Loss: 0.4795\n",
      "Epoch [14/30], Batch [360/1045], Loss: 0.5295\n",
      "Epoch [14/30], Batch [370/1045], Loss: 0.4623\n",
      "Epoch [14/30], Batch [380/1045], Loss: 0.4367\n",
      "Epoch [14/30], Batch [390/1045], Loss: 0.5983\n",
      "Epoch [14/30], Batch [400/1045], Loss: 0.5377\n",
      "Epoch [14/30], Batch [410/1045], Loss: 0.4363\n",
      "Epoch [14/30], Batch [420/1045], Loss: 0.8888\n",
      "Epoch [14/30], Batch [430/1045], Loss: 0.5400\n",
      "Epoch [14/30], Batch [440/1045], Loss: 0.5786\n",
      "Epoch [14/30], Batch [450/1045], Loss: 0.5413\n",
      "Epoch [14/30], Batch [460/1045], Loss: 0.5795\n",
      "Epoch [14/30], Batch [470/1045], Loss: 0.9847\n",
      "Epoch [14/30], Batch [480/1045], Loss: 0.4264\n",
      "Epoch [14/30], Batch [490/1045], Loss: 0.8693\n",
      "Epoch [14/30], Batch [500/1045], Loss: 0.6001\n",
      "Epoch [14/30], Batch [510/1045], Loss: 0.6191\n",
      "Epoch [14/30], Batch [520/1045], Loss: 0.4846\n",
      "Epoch [14/30], Batch [530/1045], Loss: 0.4338\n",
      "Epoch [14/30], Batch [540/1045], Loss: 0.7428\n",
      "Epoch [14/30], Batch [550/1045], Loss: 0.6492\n",
      "Epoch [14/30], Batch [560/1045], Loss: 0.5301\n",
      "Epoch [14/30], Batch [570/1045], Loss: 0.4844\n",
      "Epoch [14/30], Batch [580/1045], Loss: 0.4118\n",
      "Epoch [14/30], Batch [590/1045], Loss: 0.6469\n",
      "Epoch [14/30], Batch [600/1045], Loss: 0.4653\n",
      "Epoch [14/30], Batch [610/1045], Loss: 0.5594\n",
      "Epoch [14/30], Batch [620/1045], Loss: 0.4148\n",
      "Epoch [14/30], Batch [630/1045], Loss: 0.3426\n",
      "Epoch [14/30], Batch [640/1045], Loss: 0.5306\n",
      "Epoch [14/30], Batch [650/1045], Loss: 0.6309\n",
      "Epoch [14/30], Batch [660/1045], Loss: 0.6898\n",
      "Epoch [14/30], Batch [670/1045], Loss: 0.7064\n",
      "Epoch [14/30], Batch [680/1045], Loss: 0.6612\n",
      "Epoch [14/30], Batch [690/1045], Loss: 0.5987\n",
      "Epoch [14/30], Batch [700/1045], Loss: 0.5661\n",
      "Epoch [14/30], Batch [710/1045], Loss: 0.5656\n",
      "Epoch [14/30], Batch [720/1045], Loss: 0.7158\n",
      "Epoch [14/30], Batch [730/1045], Loss: 0.4353\n",
      "Epoch [14/30], Batch [740/1045], Loss: 0.7202\n",
      "Epoch [14/30], Batch [750/1045], Loss: 0.7032\n",
      "Epoch [14/30], Batch [760/1045], Loss: 0.5339\n",
      "Epoch [14/30], Batch [770/1045], Loss: 0.3264\n",
      "Epoch [14/30], Batch [780/1045], Loss: 0.4234\n",
      "Epoch [14/30], Batch [790/1045], Loss: 0.5132\n",
      "Epoch [14/30], Batch [800/1045], Loss: 0.9678\n",
      "Epoch [14/30], Batch [810/1045], Loss: 0.4818\n",
      "Epoch [14/30], Batch [820/1045], Loss: 0.4961\n",
      "Epoch [14/30], Batch [830/1045], Loss: 0.6598\n",
      "Epoch [14/30], Batch [840/1045], Loss: 0.4147\n",
      "Epoch [14/30], Batch [850/1045], Loss: 0.6292\n",
      "Epoch [14/30], Batch [860/1045], Loss: 0.6124\n",
      "Epoch [14/30], Batch [870/1045], Loss: 0.6750\n",
      "Epoch [14/30], Batch [880/1045], Loss: 0.7149\n",
      "Epoch [14/30], Batch [890/1045], Loss: 0.6233\n",
      "Epoch [14/30], Batch [900/1045], Loss: 0.4532\n",
      "Epoch [14/30], Batch [910/1045], Loss: 0.7539\n",
      "Epoch [14/30], Batch [920/1045], Loss: 0.7028\n",
      "Epoch [14/30], Batch [930/1045], Loss: 0.7493\n",
      "Epoch [14/30], Batch [940/1045], Loss: 0.4907\n",
      "Epoch [14/30], Batch [950/1045], Loss: 0.6899\n",
      "Epoch [14/30], Batch [960/1045], Loss: 0.5488\n",
      "Epoch [14/30], Batch [970/1045], Loss: 0.6122\n",
      "Epoch [14/30], Batch [980/1045], Loss: 0.6056\n",
      "Epoch [14/30], Batch [990/1045], Loss: 0.6641\n",
      "Epoch [14/30], Batch [1000/1045], Loss: 0.4343\n",
      "Epoch [14/30], Batch [1010/1045], Loss: 0.6988\n",
      "Epoch [14/30], Batch [1020/1045], Loss: 0.5869\n",
      "Epoch [14/30], Batch [1030/1045], Loss: 0.6252\n",
      "Epoch [14/30], Batch [1040/1045], Loss: 0.5684\n",
      "Epoch [14/30] - Average Loss: 0.5889, Accuracy: 0.7582\n",
      "Epoch [15/30], Batch [10/1045], Loss: 0.7541\n",
      "Epoch [15/30], Batch [20/1045], Loss: 0.4012\n",
      "Epoch [15/30], Batch [30/1045], Loss: 1.1285\n",
      "Epoch [15/30], Batch [40/1045], Loss: 0.6554\n",
      "Epoch [15/30], Batch [50/1045], Loss: 0.4846\n",
      "Epoch [15/30], Batch [60/1045], Loss: 0.3510\n",
      "Epoch [15/30], Batch [70/1045], Loss: 0.5916\n",
      "Epoch [15/30], Batch [80/1045], Loss: 0.5760\n",
      "Epoch [15/30], Batch [90/1045], Loss: 0.4931\n",
      "Epoch [15/30], Batch [100/1045], Loss: 0.4496\n",
      "Epoch [15/30], Batch [110/1045], Loss: 0.7493\n",
      "Epoch [15/30], Batch [120/1045], Loss: 0.4918\n",
      "Epoch [15/30], Batch [130/1045], Loss: 0.7554\n",
      "Epoch [15/30], Batch [140/1045], Loss: 0.5140\n",
      "Epoch [15/30], Batch [150/1045], Loss: 0.4561\n",
      "Epoch [15/30], Batch [160/1045], Loss: 0.7276\n",
      "Epoch [15/30], Batch [170/1045], Loss: 0.4975\n",
      "Epoch [15/30], Batch [180/1045], Loss: 0.5549\n",
      "Epoch [15/30], Batch [190/1045], Loss: 0.4779\n",
      "Epoch [15/30], Batch [200/1045], Loss: 0.3787\n",
      "Epoch [15/30], Batch [210/1045], Loss: 0.4511\n",
      "Epoch [15/30], Batch [220/1045], Loss: 0.6373\n",
      "Epoch [15/30], Batch [230/1045], Loss: 0.5066\n",
      "Epoch [15/30], Batch [240/1045], Loss: 0.6992\n",
      "Epoch [15/30], Batch [250/1045], Loss: 0.3435\n",
      "Epoch [15/30], Batch [260/1045], Loss: 0.3573\n",
      "Epoch [15/30], Batch [270/1045], Loss: 0.7140\n",
      "Epoch [15/30], Batch [280/1045], Loss: 0.5778\n",
      "Epoch [15/30], Batch [290/1045], Loss: 0.4313\n",
      "Epoch [15/30], Batch [300/1045], Loss: 0.7591\n",
      "Epoch [15/30], Batch [310/1045], Loss: 0.6503\n",
      "Epoch [15/30], Batch [320/1045], Loss: 0.7168\n",
      "Epoch [15/30], Batch [330/1045], Loss: 0.4729\n",
      "Epoch [15/30], Batch [340/1045], Loss: 0.7078\n",
      "Epoch [15/30], Batch [350/1045], Loss: 0.4909\n",
      "Epoch [15/30], Batch [360/1045], Loss: 0.6056\n",
      "Epoch [15/30], Batch [370/1045], Loss: 0.4575\n",
      "Epoch [15/30], Batch [380/1045], Loss: 0.4835\n",
      "Epoch [15/30], Batch [390/1045], Loss: 0.4639\n",
      "Epoch [15/30], Batch [400/1045], Loss: 0.3077\n",
      "Epoch [15/30], Batch [410/1045], Loss: 0.5883\n",
      "Epoch [15/30], Batch [420/1045], Loss: 0.4002\n",
      "Epoch [15/30], Batch [430/1045], Loss: 0.5058\n",
      "Epoch [15/30], Batch [440/1045], Loss: 0.5965\n",
      "Epoch [15/30], Batch [450/1045], Loss: 0.3460\n",
      "Epoch [15/30], Batch [460/1045], Loss: 0.7145\n",
      "Epoch [15/30], Batch [470/1045], Loss: 0.5982\n",
      "Epoch [15/30], Batch [480/1045], Loss: 0.4702\n",
      "Epoch [15/30], Batch [490/1045], Loss: 0.5523\n",
      "Epoch [15/30], Batch [500/1045], Loss: 0.4910\n",
      "Epoch [15/30], Batch [510/1045], Loss: 0.5169\n",
      "Epoch [15/30], Batch [520/1045], Loss: 0.5795\n",
      "Epoch [15/30], Batch [530/1045], Loss: 0.7111\n",
      "Epoch [15/30], Batch [540/1045], Loss: 0.5288\n",
      "Epoch [15/30], Batch [550/1045], Loss: 0.3441\n",
      "Epoch [15/30], Batch [560/1045], Loss: 0.5652\n",
      "Epoch [15/30], Batch [570/1045], Loss: 0.5468\n",
      "Epoch [15/30], Batch [580/1045], Loss: 0.5480\n",
      "Epoch [15/30], Batch [590/1045], Loss: 0.7443\n",
      "Epoch [15/30], Batch [600/1045], Loss: 0.4379\n",
      "Epoch [15/30], Batch [610/1045], Loss: 0.5959\n",
      "Epoch [15/30], Batch [620/1045], Loss: 0.5849\n",
      "Epoch [15/30], Batch [630/1045], Loss: 0.5405\n",
      "Epoch [15/30], Batch [640/1045], Loss: 0.3694\n",
      "Epoch [15/30], Batch [650/1045], Loss: 0.5619\n",
      "Epoch [15/30], Batch [660/1045], Loss: 0.4945\n",
      "Epoch [15/30], Batch [670/1045], Loss: 0.6446\n",
      "Epoch [15/30], Batch [680/1045], Loss: 0.5210\n",
      "Epoch [15/30], Batch [690/1045], Loss: 0.5137\n",
      "Epoch [15/30], Batch [700/1045], Loss: 0.6808\n",
      "Epoch [15/30], Batch [710/1045], Loss: 0.6058\n",
      "Epoch [15/30], Batch [720/1045], Loss: 0.8465\n",
      "Epoch [15/30], Batch [730/1045], Loss: 0.6901\n",
      "Epoch [15/30], Batch [740/1045], Loss: 0.7421\n",
      "Epoch [15/30], Batch [750/1045], Loss: 0.6035\n",
      "Epoch [15/30], Batch [760/1045], Loss: 0.4378\n",
      "Epoch [15/30], Batch [770/1045], Loss: 0.5955\n",
      "Epoch [15/30], Batch [780/1045], Loss: 0.4003\n",
      "Epoch [15/30], Batch [790/1045], Loss: 0.5178\n",
      "Epoch [15/30], Batch [800/1045], Loss: 0.4478\n",
      "Epoch [15/30], Batch [810/1045], Loss: 0.6150\n",
      "Epoch [15/30], Batch [820/1045], Loss: 0.6858\n",
      "Epoch [15/30], Batch [830/1045], Loss: 0.3483\n",
      "Epoch [15/30], Batch [840/1045], Loss: 0.5307\n",
      "Epoch [15/30], Batch [850/1045], Loss: 0.5696\n",
      "Epoch [15/30], Batch [860/1045], Loss: 0.5363\n",
      "Epoch [15/30], Batch [870/1045], Loss: 0.5222\n",
      "Epoch [15/30], Batch [880/1045], Loss: 0.7265\n",
      "Epoch [15/30], Batch [890/1045], Loss: 0.6173\n",
      "Epoch [15/30], Batch [900/1045], Loss: 0.7407\n",
      "Epoch [15/30], Batch [910/1045], Loss: 0.4447\n",
      "Epoch [15/30], Batch [920/1045], Loss: 0.9329\n",
      "Epoch [15/30], Batch [930/1045], Loss: 0.6863\n",
      "Epoch [15/30], Batch [940/1045], Loss: 0.6538\n",
      "Epoch [15/30], Batch [950/1045], Loss: 0.4488\n",
      "Epoch [15/30], Batch [960/1045], Loss: 0.6275\n",
      "Epoch [15/30], Batch [970/1045], Loss: 0.4279\n",
      "Epoch [15/30], Batch [980/1045], Loss: 0.5441\n",
      "Epoch [15/30], Batch [990/1045], Loss: 0.6395\n",
      "Epoch [15/30], Batch [1000/1045], Loss: 0.5588\n",
      "Epoch [15/30], Batch [1010/1045], Loss: 0.5330\n",
      "Epoch [15/30], Batch [1020/1045], Loss: 0.6315\n",
      "Epoch [15/30], Batch [1030/1045], Loss: 0.6631\n",
      "Epoch [15/30], Batch [1040/1045], Loss: 0.6541\n",
      "Epoch [15/30] - Average Loss: 0.5839, Accuracy: 0.7553\n",
      "Epoch [16/30], Batch [10/1045], Loss: 0.5069\n",
      "Epoch [16/30], Batch [20/1045], Loss: 0.5694\n",
      "Epoch [16/30], Batch [30/1045], Loss: 0.8131\n",
      "Epoch [16/30], Batch [40/1045], Loss: 0.8838\n",
      "Epoch [16/30], Batch [50/1045], Loss: 0.6677\n",
      "Epoch [16/30], Batch [60/1045], Loss: 0.6099\n",
      "Epoch [16/30], Batch [70/1045], Loss: 0.8700\n",
      "Epoch [16/30], Batch [80/1045], Loss: 0.4814\n",
      "Epoch [16/30], Batch [90/1045], Loss: 0.3479\n",
      "Epoch [16/30], Batch [100/1045], Loss: 0.7945\n",
      "Epoch [16/30], Batch [110/1045], Loss: 0.4919\n",
      "Epoch [16/30], Batch [120/1045], Loss: 0.4140\n",
      "Epoch [16/30], Batch [130/1045], Loss: 0.4570\n",
      "Epoch [16/30], Batch [140/1045], Loss: 0.5935\n",
      "Epoch [16/30], Batch [150/1045], Loss: 0.5572\n",
      "Epoch [16/30], Batch [160/1045], Loss: 0.6595\n",
      "Epoch [16/30], Batch [170/1045], Loss: 0.4934\n",
      "Epoch [16/30], Batch [180/1045], Loss: 0.6247\n",
      "Epoch [16/30], Batch [190/1045], Loss: 0.5148\n",
      "Epoch [16/30], Batch [200/1045], Loss: 0.6536\n",
      "Epoch [16/30], Batch [210/1045], Loss: 0.5179\n",
      "Epoch [16/30], Batch [220/1045], Loss: 0.7242\n",
      "Epoch [16/30], Batch [230/1045], Loss: 0.5109\n",
      "Epoch [16/30], Batch [240/1045], Loss: 0.8398\n",
      "Epoch [16/30], Batch [250/1045], Loss: 0.3427\n",
      "Epoch [16/30], Batch [260/1045], Loss: 0.4281\n",
      "Epoch [16/30], Batch [270/1045], Loss: 0.4565\n",
      "Epoch [16/30], Batch [280/1045], Loss: 0.8933\n",
      "Epoch [16/30], Batch [290/1045], Loss: 0.6799\n",
      "Epoch [16/30], Batch [300/1045], Loss: 0.4383\n",
      "Epoch [16/30], Batch [310/1045], Loss: 0.5117\n",
      "Epoch [16/30], Batch [320/1045], Loss: 0.4952\n",
      "Epoch [16/30], Batch [330/1045], Loss: 0.7615\n",
      "Epoch [16/30], Batch [340/1045], Loss: 0.6320\n",
      "Epoch [16/30], Batch [350/1045], Loss: 0.4375\n",
      "Epoch [16/30], Batch [360/1045], Loss: 0.3968\n",
      "Epoch [16/30], Batch [370/1045], Loss: 0.3753\n",
      "Epoch [16/30], Batch [380/1045], Loss: 0.6682\n",
      "Epoch [16/30], Batch [390/1045], Loss: 0.5136\n",
      "Epoch [16/30], Batch [400/1045], Loss: 0.6191\n",
      "Epoch [16/30], Batch [410/1045], Loss: 0.5449\n",
      "Epoch [16/30], Batch [420/1045], Loss: 0.5537\n",
      "Epoch [16/30], Batch [430/1045], Loss: 0.3641\n",
      "Epoch [16/30], Batch [440/1045], Loss: 0.7002\n",
      "Epoch [16/30], Batch [450/1045], Loss: 0.4075\n",
      "Epoch [16/30], Batch [460/1045], Loss: 0.3611\n",
      "Epoch [16/30], Batch [470/1045], Loss: 0.5374\n",
      "Epoch [16/30], Batch [480/1045], Loss: 0.5273\n",
      "Epoch [16/30], Batch [490/1045], Loss: 0.6416\n",
      "Epoch [16/30], Batch [500/1045], Loss: 0.6176\n",
      "Epoch [16/30], Batch [510/1045], Loss: 0.5368\n",
      "Epoch [16/30], Batch [520/1045], Loss: 0.5312\n",
      "Epoch [16/30], Batch [530/1045], Loss: 0.6593\n",
      "Epoch [16/30], Batch [540/1045], Loss: 0.5934\n",
      "Epoch [16/30], Batch [550/1045], Loss: 0.6542\n",
      "Epoch [16/30], Batch [560/1045], Loss: 0.6486\n",
      "Epoch [16/30], Batch [570/1045], Loss: 0.4495\n",
      "Epoch [16/30], Batch [580/1045], Loss: 0.6691\n",
      "Epoch [16/30], Batch [590/1045], Loss: 0.7051\n",
      "Epoch [16/30], Batch [600/1045], Loss: 0.3999\n",
      "Epoch [16/30], Batch [610/1045], Loss: 0.5111\n",
      "Epoch [16/30], Batch [620/1045], Loss: 0.5691\n",
      "Epoch [16/30], Batch [630/1045], Loss: 0.3290\n",
      "Epoch [16/30], Batch [640/1045], Loss: 0.8400\n",
      "Epoch [16/30], Batch [650/1045], Loss: 0.4993\n",
      "Epoch [16/30], Batch [660/1045], Loss: 0.7717\n",
      "Epoch [16/30], Batch [670/1045], Loss: 0.4986\n",
      "Epoch [16/30], Batch [680/1045], Loss: 0.6636\n",
      "Epoch [16/30], Batch [690/1045], Loss: 0.5330\n",
      "Epoch [16/30], Batch [700/1045], Loss: 0.5254\n",
      "Epoch [16/30], Batch [710/1045], Loss: 0.7756\n",
      "Epoch [16/30], Batch [720/1045], Loss: 0.7508\n",
      "Epoch [16/30], Batch [730/1045], Loss: 0.6500\n",
      "Epoch [16/30], Batch [740/1045], Loss: 0.4721\n",
      "Epoch [16/30], Batch [750/1045], Loss: 0.3978\n",
      "Epoch [16/30], Batch [760/1045], Loss: 0.6598\n",
      "Epoch [16/30], Batch [770/1045], Loss: 0.5076\n",
      "Epoch [16/30], Batch [780/1045], Loss: 0.5331\n",
      "Epoch [16/30], Batch [790/1045], Loss: 0.7097\n",
      "Epoch [16/30], Batch [800/1045], Loss: 0.7074\n",
      "Epoch [16/30], Batch [810/1045], Loss: 0.4681\n",
      "Epoch [16/30], Batch [820/1045], Loss: 0.6616\n",
      "Epoch [16/30], Batch [830/1045], Loss: 0.4973\n",
      "Epoch [16/30], Batch [840/1045], Loss: 0.3990\n",
      "Epoch [16/30], Batch [850/1045], Loss: 0.2670\n",
      "Epoch [16/30], Batch [860/1045], Loss: 0.6767\n",
      "Epoch [16/30], Batch [870/1045], Loss: 0.6539\n",
      "Epoch [16/30], Batch [880/1045], Loss: 0.6668\n",
      "Epoch [16/30], Batch [890/1045], Loss: 0.6578\n",
      "Epoch [16/30], Batch [900/1045], Loss: 0.5030\n",
      "Epoch [16/30], Batch [910/1045], Loss: 0.4990\n",
      "Epoch [16/30], Batch [920/1045], Loss: 0.7650\n",
      "Epoch [16/30], Batch [930/1045], Loss: 0.7116\n",
      "Epoch [16/30], Batch [940/1045], Loss: 0.5797\n",
      "Epoch [16/30], Batch [950/1045], Loss: 0.6230\n",
      "Epoch [16/30], Batch [960/1045], Loss: 0.5342\n",
      "Epoch [16/30], Batch [970/1045], Loss: 0.7722\n",
      "Epoch [16/30], Batch [980/1045], Loss: 0.5080\n",
      "Epoch [16/30], Batch [990/1045], Loss: 0.3681\n",
      "Epoch [16/30], Batch [1000/1045], Loss: 0.4346\n",
      "Epoch [16/30], Batch [1010/1045], Loss: 0.5015\n",
      "Epoch [16/30], Batch [1020/1045], Loss: 0.3855\n",
      "Epoch [16/30], Batch [1030/1045], Loss: 0.5869\n",
      "Epoch [16/30], Batch [1040/1045], Loss: 0.4790\n",
      "Epoch [16/30] - Average Loss: 0.5826, Accuracy: 0.7590\n",
      "Epoch [17/30], Batch [10/1045], Loss: 0.3954\n",
      "Epoch [17/30], Batch [20/1045], Loss: 0.6304\n",
      "Epoch [17/30], Batch [30/1045], Loss: 0.4821\n",
      "Epoch [17/30], Batch [40/1045], Loss: 0.6368\n",
      "Epoch [17/30], Batch [50/1045], Loss: 0.8313\n",
      "Epoch [17/30], Batch [60/1045], Loss: 0.4184\n",
      "Epoch [17/30], Batch [70/1045], Loss: 0.7091\n",
      "Epoch [17/30], Batch [80/1045], Loss: 0.7282\n",
      "Epoch [17/30], Batch [90/1045], Loss: 0.4548\n",
      "Epoch [17/30], Batch [100/1045], Loss: 0.5007\n",
      "Epoch [17/30], Batch [110/1045], Loss: 0.3352\n",
      "Epoch [17/30], Batch [120/1045], Loss: 0.4261\n",
      "Epoch [17/30], Batch [130/1045], Loss: 0.4459\n",
      "Epoch [17/30], Batch [140/1045], Loss: 0.5182\n",
      "Epoch [17/30], Batch [150/1045], Loss: 0.5867\n",
      "Epoch [17/30], Batch [160/1045], Loss: 0.4378\n",
      "Epoch [17/30], Batch [170/1045], Loss: 0.4295\n",
      "Epoch [17/30], Batch [180/1045], Loss: 0.3620\n",
      "Epoch [17/30], Batch [190/1045], Loss: 0.4269\n",
      "Epoch [17/30], Batch [200/1045], Loss: 0.6274\n",
      "Epoch [17/30], Batch [210/1045], Loss: 0.6003\n",
      "Epoch [17/30], Batch [220/1045], Loss: 0.5154\n",
      "Epoch [17/30], Batch [230/1045], Loss: 0.3539\n",
      "Epoch [17/30], Batch [240/1045], Loss: 0.5741\n",
      "Epoch [17/30], Batch [250/1045], Loss: 0.4411\n",
      "Epoch [17/30], Batch [260/1045], Loss: 0.7894\n",
      "Epoch [17/30], Batch [270/1045], Loss: 0.5931\n",
      "Epoch [17/30], Batch [280/1045], Loss: 0.5500\n",
      "Epoch [17/30], Batch [290/1045], Loss: 0.5145\n",
      "Epoch [17/30], Batch [300/1045], Loss: 0.4483\n",
      "Epoch [17/30], Batch [310/1045], Loss: 0.8214\n",
      "Epoch [17/30], Batch [320/1045], Loss: 0.7938\n",
      "Epoch [17/30], Batch [330/1045], Loss: 0.7283\n",
      "Epoch [17/30], Batch [340/1045], Loss: 0.5751\n",
      "Epoch [17/30], Batch [350/1045], Loss: 0.5492\n",
      "Epoch [17/30], Batch [360/1045], Loss: 0.6238\n",
      "Epoch [17/30], Batch [370/1045], Loss: 0.2949\n",
      "Epoch [17/30], Batch [380/1045], Loss: 0.5845\n",
      "Epoch [17/30], Batch [390/1045], Loss: 0.7153\n",
      "Epoch [17/30], Batch [400/1045], Loss: 0.5281\n",
      "Epoch [17/30], Batch [410/1045], Loss: 0.4709\n",
      "Epoch [17/30], Batch [420/1045], Loss: 0.4503\n",
      "Epoch [17/30], Batch [430/1045], Loss: 0.6086\n",
      "Epoch [17/30], Batch [440/1045], Loss: 0.5806\n",
      "Epoch [17/30], Batch [450/1045], Loss: 0.6600\n",
      "Epoch [17/30], Batch [460/1045], Loss: 0.3932\n",
      "Epoch [17/30], Batch [470/1045], Loss: 0.3796\n",
      "Epoch [17/30], Batch [480/1045], Loss: 0.6563\n",
      "Epoch [17/30], Batch [490/1045], Loss: 0.7609\n",
      "Epoch [17/30], Batch [500/1045], Loss: 0.6471\n",
      "Epoch [17/30], Batch [510/1045], Loss: 0.5038\n",
      "Epoch [17/30], Batch [520/1045], Loss: 0.5920\n",
      "Epoch [17/30], Batch [530/1045], Loss: 0.7402\n",
      "Epoch [17/30], Batch [540/1045], Loss: 0.5824\n",
      "Epoch [17/30], Batch [550/1045], Loss: 0.5931\n",
      "Epoch [17/30], Batch [560/1045], Loss: 0.4415\n",
      "Epoch [17/30], Batch [570/1045], Loss: 0.6176\n",
      "Epoch [17/30], Batch [580/1045], Loss: 0.5603\n",
      "Epoch [17/30], Batch [590/1045], Loss: 0.9245\n",
      "Epoch [17/30], Batch [600/1045], Loss: 0.5277\n",
      "Epoch [17/30], Batch [610/1045], Loss: 0.4664\n",
      "Epoch [17/30], Batch [620/1045], Loss: 0.9237\n",
      "Epoch [17/30], Batch [630/1045], Loss: 0.6346\n",
      "Epoch [17/30], Batch [640/1045], Loss: 0.3656\n",
      "Epoch [17/30], Batch [650/1045], Loss: 0.3679\n",
      "Epoch [17/30], Batch [660/1045], Loss: 0.6071\n",
      "Epoch [17/30], Batch [670/1045], Loss: 0.8283\n",
      "Epoch [17/30], Batch [680/1045], Loss: 0.5285\n",
      "Epoch [17/30], Batch [690/1045], Loss: 0.8079\n",
      "Epoch [17/30], Batch [700/1045], Loss: 0.6952\n",
      "Epoch [17/30], Batch [710/1045], Loss: 0.7032\n",
      "Epoch [17/30], Batch [720/1045], Loss: 0.4872\n",
      "Epoch [17/30], Batch [730/1045], Loss: 0.3821\n",
      "Epoch [17/30], Batch [740/1045], Loss: 0.6174\n",
      "Epoch [17/30], Batch [750/1045], Loss: 0.6934\n",
      "Epoch [17/30], Batch [760/1045], Loss: 0.6773\n",
      "Epoch [17/30], Batch [770/1045], Loss: 0.4483\n",
      "Epoch [17/30], Batch [780/1045], Loss: 0.3392\n",
      "Epoch [17/30], Batch [790/1045], Loss: 0.6679\n",
      "Epoch [17/30], Batch [800/1045], Loss: 0.4780\n",
      "Epoch [17/30], Batch [810/1045], Loss: 0.4520\n",
      "Epoch [17/30], Batch [820/1045], Loss: 0.5939\n",
      "Epoch [17/30], Batch [830/1045], Loss: 0.9146\n",
      "Epoch [17/30], Batch [840/1045], Loss: 0.6199\n",
      "Epoch [17/30], Batch [850/1045], Loss: 0.6558\n",
      "Epoch [17/30], Batch [860/1045], Loss: 0.4910\n",
      "Epoch [17/30], Batch [870/1045], Loss: 0.5690\n",
      "Epoch [17/30], Batch [880/1045], Loss: 0.7440\n",
      "Epoch [17/30], Batch [890/1045], Loss: 0.6924\n",
      "Epoch [17/30], Batch [900/1045], Loss: 0.5554\n",
      "Epoch [17/30], Batch [910/1045], Loss: 0.3223\n",
      "Epoch [17/30], Batch [920/1045], Loss: 0.7060\n",
      "Epoch [17/30], Batch [930/1045], Loss: 0.4969\n",
      "Epoch [17/30], Batch [940/1045], Loss: 0.6903\n",
      "Epoch [17/30], Batch [950/1045], Loss: 0.7444\n",
      "Epoch [17/30], Batch [960/1045], Loss: 0.4900\n",
      "Epoch [17/30], Batch [970/1045], Loss: 0.4397\n",
      "Epoch [17/30], Batch [980/1045], Loss: 0.5548\n",
      "Epoch [17/30], Batch [990/1045], Loss: 0.9032\n",
      "Epoch [17/30], Batch [1000/1045], Loss: 0.3742\n",
      "Epoch [17/30], Batch [1010/1045], Loss: 0.8616\n",
      "Epoch [17/30], Batch [1020/1045], Loss: 0.8517\n",
      "Epoch [17/30], Batch [1030/1045], Loss: 0.4831\n",
      "Epoch [17/30], Batch [1040/1045], Loss: 0.5397\n",
      "Epoch [17/30] - Average Loss: 0.5713, Accuracy: 0.7593\n",
      "Epoch [18/30], Batch [10/1045], Loss: 0.5272\n",
      "Epoch [18/30], Batch [20/1045], Loss: 0.4295\n",
      "Epoch [18/30], Batch [30/1045], Loss: 0.6407\n",
      "Epoch [18/30], Batch [40/1045], Loss: 0.4850\n",
      "Epoch [18/30], Batch [50/1045], Loss: 0.7001\n",
      "Epoch [18/30], Batch [60/1045], Loss: 0.5989\n",
      "Epoch [18/30], Batch [70/1045], Loss: 0.7633\n",
      "Epoch [18/30], Batch [80/1045], Loss: 0.5899\n",
      "Epoch [18/30], Batch [90/1045], Loss: 0.3643\n",
      "Epoch [18/30], Batch [100/1045], Loss: 0.4731\n",
      "Epoch [18/30], Batch [110/1045], Loss: 0.5469\n",
      "Epoch [18/30], Batch [120/1045], Loss: 0.6079\n",
      "Epoch [18/30], Batch [130/1045], Loss: 0.4377\n",
      "Epoch [18/30], Batch [140/1045], Loss: 0.6083\n",
      "Epoch [18/30], Batch [150/1045], Loss: 0.8050\n",
      "Epoch [18/30], Batch [160/1045], Loss: 0.5993\n",
      "Epoch [18/30], Batch [170/1045], Loss: 0.5582\n",
      "Epoch [18/30], Batch [180/1045], Loss: 0.7160\n",
      "Epoch [18/30], Batch [190/1045], Loss: 0.6353\n",
      "Epoch [18/30], Batch [200/1045], Loss: 0.6449\n",
      "Epoch [18/30], Batch [210/1045], Loss: 0.4969\n",
      "Epoch [18/30], Batch [220/1045], Loss: 0.5100\n",
      "Epoch [18/30], Batch [230/1045], Loss: 0.5600\n",
      "Epoch [18/30], Batch [240/1045], Loss: 0.6286\n",
      "Epoch [18/30], Batch [250/1045], Loss: 0.5174\n",
      "Epoch [18/30], Batch [260/1045], Loss: 0.4423\n",
      "Epoch [18/30], Batch [270/1045], Loss: 0.5510\n",
      "Epoch [18/30], Batch [280/1045], Loss: 0.6833\n",
      "Epoch [18/30], Batch [290/1045], Loss: 0.2184\n",
      "Epoch [18/30], Batch [300/1045], Loss: 0.4550\n",
      "Epoch [18/30], Batch [310/1045], Loss: 0.7097\n",
      "Epoch [18/30], Batch [320/1045], Loss: 0.4311\n",
      "Epoch [18/30], Batch [330/1045], Loss: 0.7600\n",
      "Epoch [18/30], Batch [340/1045], Loss: 0.5887\n",
      "Epoch [18/30], Batch [350/1045], Loss: 0.6789\n",
      "Epoch [18/30], Batch [360/1045], Loss: 0.5563\n",
      "Epoch [18/30], Batch [370/1045], Loss: 0.4402\n",
      "Epoch [18/30], Batch [380/1045], Loss: 0.7147\n",
      "Epoch [18/30], Batch [390/1045], Loss: 0.6577\n",
      "Epoch [18/30], Batch [400/1045], Loss: 0.4356\n",
      "Epoch [18/30], Batch [410/1045], Loss: 0.6134\n",
      "Epoch [18/30], Batch [420/1045], Loss: 0.5567\n",
      "Epoch [18/30], Batch [430/1045], Loss: 0.5662\n",
      "Epoch [18/30], Batch [440/1045], Loss: 0.9814\n",
      "Epoch [18/30], Batch [450/1045], Loss: 0.3783\n",
      "Epoch [18/30], Batch [460/1045], Loss: 0.4341\n",
      "Epoch [18/30], Batch [470/1045], Loss: 0.5383\n",
      "Epoch [18/30], Batch [480/1045], Loss: 0.6314\n",
      "Epoch [18/30], Batch [490/1045], Loss: 0.7619\n",
      "Epoch [18/30], Batch [500/1045], Loss: 0.4533\n",
      "Epoch [18/30], Batch [510/1045], Loss: 0.5901\n",
      "Epoch [18/30], Batch [520/1045], Loss: 0.4696\n",
      "Epoch [18/30], Batch [530/1045], Loss: 0.3699\n",
      "Epoch [18/30], Batch [540/1045], Loss: 0.5459\n",
      "Epoch [18/30], Batch [550/1045], Loss: 0.5421\n",
      "Epoch [18/30], Batch [560/1045], Loss: 0.6946\n",
      "Epoch [18/30], Batch [570/1045], Loss: 0.5749\n",
      "Epoch [18/30], Batch [580/1045], Loss: 0.6537\n",
      "Epoch [18/30], Batch [590/1045], Loss: 0.4837\n",
      "Epoch [18/30], Batch [600/1045], Loss: 0.4206\n",
      "Epoch [18/30], Batch [610/1045], Loss: 0.8206\n",
      "Epoch [18/30], Batch [620/1045], Loss: 0.4790\n",
      "Epoch [18/30], Batch [630/1045], Loss: 0.5781\n",
      "Epoch [18/30], Batch [640/1045], Loss: 0.4478\n",
      "Epoch [18/30], Batch [650/1045], Loss: 0.5472\n",
      "Epoch [18/30], Batch [660/1045], Loss: 0.4026\n",
      "Epoch [18/30], Batch [670/1045], Loss: 0.3982\n",
      "Epoch [18/30], Batch [680/1045], Loss: 0.8781\n",
      "Epoch [18/30], Batch [690/1045], Loss: 0.6728\n",
      "Epoch [18/30], Batch [700/1045], Loss: 0.4248\n",
      "Epoch [18/30], Batch [710/1045], Loss: 0.5905\n",
      "Epoch [18/30], Batch [720/1045], Loss: 0.5387\n",
      "Epoch [18/30], Batch [730/1045], Loss: 0.5059\n",
      "Epoch [18/30], Batch [740/1045], Loss: 0.6117\n",
      "Epoch [18/30], Batch [750/1045], Loss: 0.8623\n",
      "Epoch [18/30], Batch [760/1045], Loss: 0.3853\n",
      "Epoch [18/30], Batch [770/1045], Loss: 0.7818\n",
      "Epoch [18/30], Batch [780/1045], Loss: 0.4610\n",
      "Epoch [18/30], Batch [790/1045], Loss: 0.6995\n",
      "Epoch [18/30], Batch [800/1045], Loss: 0.5774\n",
      "Epoch [18/30], Batch [810/1045], Loss: 0.7655\n",
      "Epoch [18/30], Batch [820/1045], Loss: 0.6152\n",
      "Epoch [18/30], Batch [830/1045], Loss: 0.6290\n",
      "Epoch [18/30], Batch [840/1045], Loss: 0.4164\n",
      "Epoch [18/30], Batch [850/1045], Loss: 0.9307\n",
      "Epoch [18/30], Batch [860/1045], Loss: 0.4602\n",
      "Epoch [18/30], Batch [870/1045], Loss: 0.7014\n",
      "Epoch [18/30], Batch [880/1045], Loss: 0.4388\n",
      "Epoch [18/30], Batch [890/1045], Loss: 0.6885\n",
      "Epoch [18/30], Batch [900/1045], Loss: 0.6310\n",
      "Epoch [18/30], Batch [910/1045], Loss: 0.5880\n",
      "Epoch [18/30], Batch [920/1045], Loss: 0.3759\n",
      "Epoch [18/30], Batch [930/1045], Loss: 0.6146\n",
      "Epoch [18/30], Batch [940/1045], Loss: 0.7721\n",
      "Epoch [18/30], Batch [950/1045], Loss: 0.7480\n",
      "Epoch [18/30], Batch [960/1045], Loss: 0.3581\n",
      "Epoch [18/30], Batch [970/1045], Loss: 0.4841\n",
      "Epoch [18/30], Batch [980/1045], Loss: 0.5560\n",
      "Epoch [18/30], Batch [990/1045], Loss: 0.4499\n",
      "Epoch [18/30], Batch [1000/1045], Loss: 0.6554\n",
      "Epoch [18/30], Batch [1010/1045], Loss: 0.5695\n",
      "Epoch [18/30], Batch [1020/1045], Loss: 0.7229\n",
      "Epoch [18/30], Batch [1030/1045], Loss: 0.7186\n",
      "Epoch [18/30], Batch [1040/1045], Loss: 0.6514\n",
      "Epoch [18/30] - Average Loss: 0.5811, Accuracy: 0.7569\n",
      "Epoch [19/30], Batch [10/1045], Loss: 0.5272\n",
      "Epoch [19/30], Batch [20/1045], Loss: 0.4728\n",
      "Epoch [19/30], Batch [30/1045], Loss: 0.5293\n",
      "Epoch [19/30], Batch [40/1045], Loss: 0.5257\n",
      "Epoch [19/30], Batch [50/1045], Loss: 0.5783\n",
      "Epoch [19/30], Batch [60/1045], Loss: 0.4283\n",
      "Epoch [19/30], Batch [70/1045], Loss: 0.6838\n",
      "Epoch [19/30], Batch [80/1045], Loss: 0.5479\n",
      "Epoch [19/30], Batch [90/1045], Loss: 0.4385\n",
      "Epoch [19/30], Batch [100/1045], Loss: 0.3848\n",
      "Epoch [19/30], Batch [110/1045], Loss: 0.4061\n",
      "Epoch [19/30], Batch [120/1045], Loss: 0.4105\n",
      "Epoch [19/30], Batch [130/1045], Loss: 0.6591\n",
      "Epoch [19/30], Batch [140/1045], Loss: 0.4655\n",
      "Epoch [19/30], Batch [150/1045], Loss: 0.5186\n",
      "Epoch [19/30], Batch [160/1045], Loss: 0.3928\n",
      "Epoch [19/30], Batch [170/1045], Loss: 0.5165\n",
      "Epoch [19/30], Batch [180/1045], Loss: 0.4322\n",
      "Epoch [19/30], Batch [190/1045], Loss: 0.5550\n",
      "Epoch [19/30], Batch [200/1045], Loss: 0.4286\n",
      "Epoch [19/30], Batch [210/1045], Loss: 0.6138\n",
      "Epoch [19/30], Batch [220/1045], Loss: 1.0689\n",
      "Epoch [19/30], Batch [230/1045], Loss: 0.4639\n",
      "Epoch [19/30], Batch [240/1045], Loss: 0.5994\n",
      "Epoch [19/30], Batch [250/1045], Loss: 0.5428\n",
      "Epoch [19/30], Batch [260/1045], Loss: 0.4844\n",
      "Epoch [19/30], Batch [270/1045], Loss: 0.5134\n",
      "Epoch [19/30], Batch [280/1045], Loss: 0.4756\n",
      "Epoch [19/30], Batch [290/1045], Loss: 0.6843\n",
      "Epoch [19/30], Batch [300/1045], Loss: 0.7615\n",
      "Epoch [19/30], Batch [310/1045], Loss: 0.4712\n",
      "Epoch [19/30], Batch [320/1045], Loss: 0.4780\n",
      "Epoch [19/30], Batch [330/1045], Loss: 0.6858\n",
      "Epoch [19/30], Batch [340/1045], Loss: 0.3555\n",
      "Epoch [19/30], Batch [350/1045], Loss: 0.7680\n",
      "Epoch [19/30], Batch [360/1045], Loss: 0.5959\n",
      "Epoch [19/30], Batch [370/1045], Loss: 0.6059\n",
      "Epoch [19/30], Batch [380/1045], Loss: 0.5946\n",
      "Epoch [19/30], Batch [390/1045], Loss: 0.5841\n",
      "Epoch [19/30], Batch [400/1045], Loss: 0.3676\n",
      "Epoch [19/30], Batch [410/1045], Loss: 0.7174\n",
      "Epoch [19/30], Batch [420/1045], Loss: 0.4448\n",
      "Epoch [19/30], Batch [430/1045], Loss: 0.4526\n",
      "Epoch [19/30], Batch [440/1045], Loss: 0.4473\n",
      "Epoch [19/30], Batch [450/1045], Loss: 0.8680\n",
      "Epoch [19/30], Batch [460/1045], Loss: 0.4033\n",
      "Epoch [19/30], Batch [470/1045], Loss: 0.3870\n",
      "Epoch [19/30], Batch [480/1045], Loss: 0.5454\n",
      "Epoch [19/30], Batch [490/1045], Loss: 0.7217\n",
      "Epoch [19/30], Batch [500/1045], Loss: 0.5018\n",
      "Epoch [19/30], Batch [510/1045], Loss: 0.6240\n",
      "Epoch [19/30], Batch [520/1045], Loss: 0.6897\n",
      "Epoch [19/30], Batch [530/1045], Loss: 0.7288\n",
      "Epoch [19/30], Batch [540/1045], Loss: 0.8314\n",
      "Epoch [19/30], Batch [550/1045], Loss: 0.5498\n",
      "Epoch [19/30], Batch [560/1045], Loss: 0.7996\n",
      "Epoch [19/30], Batch [570/1045], Loss: 0.6416\n",
      "Epoch [19/30], Batch [580/1045], Loss: 0.3990\n",
      "Epoch [19/30], Batch [590/1045], Loss: 0.4766\n",
      "Epoch [19/30], Batch [600/1045], Loss: 0.7626\n",
      "Epoch [19/30], Batch [610/1045], Loss: 0.9034\n",
      "Epoch [19/30], Batch [620/1045], Loss: 0.5493\n",
      "Epoch [19/30], Batch [630/1045], Loss: 0.6272\n",
      "Epoch [19/30], Batch [640/1045], Loss: 0.4623\n",
      "Epoch [19/30], Batch [650/1045], Loss: 0.4780\n",
      "Epoch [19/30], Batch [660/1045], Loss: 0.6597\n",
      "Epoch [19/30], Batch [670/1045], Loss: 0.7220\n",
      "Epoch [19/30], Batch [680/1045], Loss: 0.7391\n",
      "Epoch [19/30], Batch [690/1045], Loss: 0.5417\n",
      "Epoch [19/30], Batch [700/1045], Loss: 0.5536\n",
      "Epoch [19/30], Batch [710/1045], Loss: 0.5855\n",
      "Epoch [19/30], Batch [720/1045], Loss: 0.4738\n",
      "Epoch [19/30], Batch [730/1045], Loss: 0.5826\n",
      "Epoch [19/30], Batch [740/1045], Loss: 0.3063\n",
      "Epoch [19/30], Batch [750/1045], Loss: 0.4174\n",
      "Epoch [19/30], Batch [760/1045], Loss: 0.5390\n",
      "Epoch [19/30], Batch [770/1045], Loss: 0.5275\n",
      "Epoch [19/30], Batch [780/1045], Loss: 0.5383\n",
      "Epoch [19/30], Batch [790/1045], Loss: 0.4853\n",
      "Epoch [19/30], Batch [800/1045], Loss: 0.7688\n",
      "Epoch [19/30], Batch [810/1045], Loss: 0.6163\n",
      "Epoch [19/30], Batch [820/1045], Loss: 0.6553\n",
      "Epoch [19/30], Batch [830/1045], Loss: 0.5461\n",
      "Epoch [19/30], Batch [840/1045], Loss: 0.7191\n",
      "Epoch [19/30], Batch [850/1045], Loss: 0.4191\n",
      "Epoch [19/30], Batch [860/1045], Loss: 0.5531\n",
      "Epoch [19/30], Batch [870/1045], Loss: 0.5144\n",
      "Epoch [19/30], Batch [880/1045], Loss: 0.3561\n",
      "Epoch [19/30], Batch [890/1045], Loss: 0.5576\n",
      "Epoch [19/30], Batch [900/1045], Loss: 0.6876\n",
      "Epoch [19/30], Batch [910/1045], Loss: 0.2964\n",
      "Epoch [19/30], Batch [920/1045], Loss: 0.6475\n",
      "Epoch [19/30], Batch [930/1045], Loss: 0.5662\n",
      "Epoch [19/30], Batch [940/1045], Loss: 0.7531\n",
      "Epoch [19/30], Batch [950/1045], Loss: 0.7020\n",
      "Epoch [19/30], Batch [960/1045], Loss: 0.5923\n",
      "Epoch [19/30], Batch [970/1045], Loss: 0.6399\n",
      "Epoch [19/30], Batch [980/1045], Loss: 0.5317\n",
      "Epoch [19/30], Batch [990/1045], Loss: 0.4079\n",
      "Epoch [19/30], Batch [1000/1045], Loss: 0.8098\n",
      "Epoch [19/30], Batch [1010/1045], Loss: 0.6322\n",
      "Epoch [19/30], Batch [1020/1045], Loss: 0.5221\n",
      "Epoch [19/30], Batch [1030/1045], Loss: 0.2988\n",
      "Epoch [19/30], Batch [1040/1045], Loss: 0.4638\n",
      "Epoch [19/30] - Average Loss: 0.5700, Accuracy: 0.7593\n",
      "Epoch [20/30], Batch [10/1045], Loss: 0.7633\n",
      "Epoch [20/30], Batch [20/1045], Loss: 0.7227\n",
      "Epoch [20/30], Batch [30/1045], Loss: 0.4635\n",
      "Epoch [20/30], Batch [40/1045], Loss: 0.6601\n",
      "Epoch [20/30], Batch [50/1045], Loss: 0.5525\n",
      "Epoch [20/30], Batch [60/1045], Loss: 0.4673\n",
      "Epoch [20/30], Batch [70/1045], Loss: 0.5017\n",
      "Epoch [20/30], Batch [80/1045], Loss: 0.4839\n",
      "Epoch [20/30], Batch [90/1045], Loss: 0.4903\n",
      "Epoch [20/30], Batch [100/1045], Loss: 0.4202\n",
      "Epoch [20/30], Batch [110/1045], Loss: 0.4220\n",
      "Epoch [20/30], Batch [120/1045], Loss: 0.5183\n",
      "Epoch [20/30], Batch [130/1045], Loss: 0.5891\n",
      "Epoch [20/30], Batch [140/1045], Loss: 0.3949\n",
      "Epoch [20/30], Batch [150/1045], Loss: 0.5996\n",
      "Epoch [20/30], Batch [160/1045], Loss: 0.6939\n",
      "Epoch [20/30], Batch [170/1045], Loss: 0.5231\n",
      "Epoch [20/30], Batch [180/1045], Loss: 0.2764\n",
      "Epoch [20/30], Batch [190/1045], Loss: 0.4421\n",
      "Epoch [20/30], Batch [200/1045], Loss: 0.5428\n",
      "Epoch [20/30], Batch [210/1045], Loss: 0.4756\n",
      "Epoch [20/30], Batch [220/1045], Loss: 0.6934\n",
      "Epoch [20/30], Batch [230/1045], Loss: 0.4600\n",
      "Epoch [20/30], Batch [240/1045], Loss: 0.6121\n",
      "Epoch [20/30], Batch [250/1045], Loss: 0.5804\n",
      "Epoch [20/30], Batch [260/1045], Loss: 0.5090\n",
      "Epoch [20/30], Batch [270/1045], Loss: 0.7227\n",
      "Epoch [20/30], Batch [280/1045], Loss: 0.4903\n",
      "Epoch [20/30], Batch [290/1045], Loss: 0.5889\n",
      "Epoch [20/30], Batch [300/1045], Loss: 0.5839\n",
      "Epoch [20/30], Batch [310/1045], Loss: 0.5134\n",
      "Epoch [20/30], Batch [320/1045], Loss: 0.4798\n",
      "Epoch [20/30], Batch [330/1045], Loss: 0.6103\n",
      "Epoch [20/30], Batch [340/1045], Loss: 0.6147\n",
      "Epoch [20/30], Batch [350/1045], Loss: 0.6010\n",
      "Epoch [20/30], Batch [360/1045], Loss: 0.5616\n",
      "Epoch [20/30], Batch [370/1045], Loss: 0.7552\n",
      "Epoch [20/30], Batch [380/1045], Loss: 0.6992\n",
      "Epoch [20/30], Batch [390/1045], Loss: 0.4249\n",
      "Epoch [20/30], Batch [400/1045], Loss: 0.3180\n",
      "Epoch [20/30], Batch [410/1045], Loss: 0.5539\n",
      "Epoch [20/30], Batch [420/1045], Loss: 0.3922\n",
      "Epoch [20/30], Batch [430/1045], Loss: 0.4288\n",
      "Epoch [20/30], Batch [440/1045], Loss: 0.5177\n",
      "Epoch [20/30], Batch [450/1045], Loss: 0.6440\n",
      "Epoch [20/30], Batch [460/1045], Loss: 0.7025\n",
      "Epoch [20/30], Batch [470/1045], Loss: 0.5286\n",
      "Epoch [20/30], Batch [480/1045], Loss: 0.4451\n",
      "Epoch [20/30], Batch [490/1045], Loss: 0.9657\n",
      "Epoch [20/30], Batch [500/1045], Loss: 0.9043\n",
      "Epoch [20/30], Batch [510/1045], Loss: 0.5138\n",
      "Epoch [20/30], Batch [520/1045], Loss: 0.7392\n",
      "Epoch [20/30], Batch [530/1045], Loss: 0.3974\n",
      "Epoch [20/30], Batch [540/1045], Loss: 0.5400\n",
      "Epoch [20/30], Batch [550/1045], Loss: 0.6697\n",
      "Epoch [20/30], Batch [560/1045], Loss: 0.5101\n",
      "Epoch [20/30], Batch [570/1045], Loss: 0.5755\n",
      "Epoch [20/30], Batch [580/1045], Loss: 0.6502\n",
      "Epoch [20/30], Batch [590/1045], Loss: 0.4693\n",
      "Epoch [20/30], Batch [600/1045], Loss: 0.8628\n",
      "Epoch [20/30], Batch [610/1045], Loss: 0.9912\n",
      "Epoch [20/30], Batch [620/1045], Loss: 0.4886\n",
      "Epoch [20/30], Batch [630/1045], Loss: 0.4371\n",
      "Epoch [20/30], Batch [640/1045], Loss: 0.5855\n",
      "Epoch [20/30], Batch [650/1045], Loss: 0.8747\n",
      "Epoch [20/30], Batch [660/1045], Loss: 0.8236\n",
      "Epoch [20/30], Batch [670/1045], Loss: 0.5380\n",
      "Epoch [20/30], Batch [680/1045], Loss: 0.4764\n",
      "Epoch [20/30], Batch [690/1045], Loss: 0.6720\n",
      "Epoch [20/30], Batch [700/1045], Loss: 0.5495\n",
      "Epoch [20/30], Batch [710/1045], Loss: 0.4257\n",
      "Epoch [20/30], Batch [720/1045], Loss: 0.5089\n",
      "Epoch [20/30], Batch [730/1045], Loss: 0.4440\n",
      "Epoch [20/30], Batch [740/1045], Loss: 0.7580\n",
      "Epoch [20/30], Batch [750/1045], Loss: 0.7006\n",
      "Epoch [20/30], Batch [760/1045], Loss: 0.5569\n",
      "Epoch [20/30], Batch [770/1045], Loss: 0.6159\n",
      "Epoch [20/30], Batch [780/1045], Loss: 0.7309\n",
      "Epoch [20/30], Batch [790/1045], Loss: 0.6882\n",
      "Epoch [20/30], Batch [800/1045], Loss: 0.5023\n",
      "Epoch [20/30], Batch [810/1045], Loss: 0.6455\n",
      "Epoch [20/30], Batch [820/1045], Loss: 0.4874\n",
      "Epoch [20/30], Batch [830/1045], Loss: 0.3598\n",
      "Epoch [20/30], Batch [840/1045], Loss: 0.4749\n",
      "Epoch [20/30], Batch [850/1045], Loss: 0.5045\n",
      "Epoch [20/30], Batch [860/1045], Loss: 0.5046\n",
      "Epoch [20/30], Batch [870/1045], Loss: 0.4563\n",
      "Epoch [20/30], Batch [880/1045], Loss: 0.6564\n",
      "Epoch [20/30], Batch [890/1045], Loss: 0.6360\n",
      "Epoch [20/30], Batch [900/1045], Loss: 0.7237\n",
      "Epoch [20/30], Batch [910/1045], Loss: 0.9426\n",
      "Epoch [20/30], Batch [920/1045], Loss: 0.5755\n",
      "Epoch [20/30], Batch [930/1045], Loss: 0.5596\n",
      "Epoch [20/30], Batch [940/1045], Loss: 0.5611\n",
      "Epoch [20/30], Batch [950/1045], Loss: 0.4768\n",
      "Epoch [20/30], Batch [960/1045], Loss: 0.6981\n",
      "Epoch [20/30], Batch [970/1045], Loss: 0.7141\n",
      "Epoch [20/30], Batch [980/1045], Loss: 0.5028\n",
      "Epoch [20/30], Batch [990/1045], Loss: 0.5401\n",
      "Epoch [20/30], Batch [1000/1045], Loss: 0.5898\n",
      "Epoch [20/30], Batch [1010/1045], Loss: 0.7541\n",
      "Epoch [20/30], Batch [1020/1045], Loss: 0.3951\n",
      "Epoch [20/30], Batch [1030/1045], Loss: 0.4718\n",
      "Epoch [20/30], Batch [1040/1045], Loss: 0.7092\n",
      "Epoch [20/30] - Average Loss: 0.5727, Accuracy: 0.7610\n",
      "Epoch [21/30], Batch [10/1045], Loss: 0.4552\n",
      "Epoch [21/30], Batch [20/1045], Loss: 0.3983\n",
      "Epoch [21/30], Batch [30/1045], Loss: 0.5449\n",
      "Epoch [21/30], Batch [40/1045], Loss: 0.3362\n",
      "Epoch [21/30], Batch [50/1045], Loss: 0.6426\n",
      "Epoch [21/30], Batch [60/1045], Loss: 0.6624\n",
      "Epoch [21/30], Batch [70/1045], Loss: 0.6104\n",
      "Epoch [21/30], Batch [80/1045], Loss: 0.5765\n",
      "Epoch [21/30], Batch [90/1045], Loss: 0.6393\n",
      "Epoch [21/30], Batch [100/1045], Loss: 0.5368\n",
      "Epoch [21/30], Batch [110/1045], Loss: 0.5933\n",
      "Epoch [21/30], Batch [120/1045], Loss: 0.3663\n",
      "Epoch [21/30], Batch [130/1045], Loss: 0.8167\n",
      "Epoch [21/30], Batch [140/1045], Loss: 0.3881\n",
      "Epoch [21/30], Batch [150/1045], Loss: 0.7459\n",
      "Epoch [21/30], Batch [160/1045], Loss: 0.4170\n",
      "Epoch [21/30], Batch [170/1045], Loss: 0.7449\n",
      "Epoch [21/30], Batch [180/1045], Loss: 0.6844\n",
      "Epoch [21/30], Batch [190/1045], Loss: 0.6224\n",
      "Epoch [21/30], Batch [200/1045], Loss: 0.3956\n",
      "Epoch [21/30], Batch [210/1045], Loss: 0.4102\n",
      "Epoch [21/30], Batch [220/1045], Loss: 0.5821\n",
      "Epoch [21/30], Batch [230/1045], Loss: 0.5941\n",
      "Epoch [21/30], Batch [240/1045], Loss: 0.6192\n",
      "Epoch [21/30], Batch [250/1045], Loss: 0.4305\n",
      "Epoch [21/30], Batch [260/1045], Loss: 0.2872\n",
      "Epoch [21/30], Batch [270/1045], Loss: 0.4585\n",
      "Epoch [21/30], Batch [280/1045], Loss: 0.5524\n",
      "Epoch [21/30], Batch [290/1045], Loss: 0.5140\n",
      "Epoch [21/30], Batch [300/1045], Loss: 0.8549\n",
      "Epoch [21/30], Batch [310/1045], Loss: 0.5902\n",
      "Epoch [21/30], Batch [320/1045], Loss: 0.7406\n",
      "Epoch [21/30], Batch [330/1045], Loss: 0.4178\n",
      "Epoch [21/30], Batch [340/1045], Loss: 0.2753\n",
      "Epoch [21/30], Batch [350/1045], Loss: 0.7936\n",
      "Epoch [21/30], Batch [360/1045], Loss: 0.5949\n",
      "Epoch [21/30], Batch [370/1045], Loss: 0.5908\n",
      "Epoch [21/30], Batch [380/1045], Loss: 0.4900\n",
      "Epoch [21/30], Batch [390/1045], Loss: 0.7909\n",
      "Epoch [21/30], Batch [400/1045], Loss: 0.4898\n",
      "Epoch [21/30], Batch [410/1045], Loss: 0.6502\n",
      "Epoch [21/30], Batch [420/1045], Loss: 0.5877\n",
      "Epoch [21/30], Batch [430/1045], Loss: 0.6912\n",
      "Epoch [21/30], Batch [440/1045], Loss: 0.8138\n",
      "Epoch [21/30], Batch [450/1045], Loss: 0.9143\n",
      "Epoch [21/30], Batch [460/1045], Loss: 0.4504\n",
      "Epoch [21/30], Batch [470/1045], Loss: 0.3004\n",
      "Epoch [21/30], Batch [480/1045], Loss: 0.5047\n",
      "Epoch [21/30], Batch [490/1045], Loss: 0.4586\n",
      "Epoch [21/30], Batch [500/1045], Loss: 0.7197\n",
      "Epoch [21/30], Batch [510/1045], Loss: 0.7100\n",
      "Epoch [21/30], Batch [520/1045], Loss: 0.3857\n",
      "Epoch [21/30], Batch [530/1045], Loss: 0.5948\n",
      "Epoch [21/30], Batch [540/1045], Loss: 0.4042\n",
      "Epoch [21/30], Batch [550/1045], Loss: 0.5338\n",
      "Epoch [21/30], Batch [560/1045], Loss: 0.5056\n",
      "Epoch [21/30], Batch [570/1045], Loss: 0.4669\n",
      "Epoch [21/30], Batch [580/1045], Loss: 0.5520\n",
      "Epoch [21/30], Batch [590/1045], Loss: 0.6599\n",
      "Epoch [21/30], Batch [600/1045], Loss: 0.5604\n",
      "Epoch [21/30], Batch [610/1045], Loss: 0.5137\n",
      "Epoch [21/30], Batch [620/1045], Loss: 0.6928\n",
      "Epoch [21/30], Batch [630/1045], Loss: 0.6077\n",
      "Epoch [21/30], Batch [640/1045], Loss: 0.5696\n",
      "Epoch [21/30], Batch [650/1045], Loss: 0.6055\n",
      "Epoch [21/30], Batch [660/1045], Loss: 0.7550\n",
      "Epoch [21/30], Batch [670/1045], Loss: 0.5151\n",
      "Epoch [21/30], Batch [680/1045], Loss: 0.5929\n",
      "Epoch [21/30], Batch [690/1045], Loss: 0.4791\n",
      "Epoch [21/30], Batch [700/1045], Loss: 0.5307\n",
      "Epoch [21/30], Batch [710/1045], Loss: 0.5803\n",
      "Epoch [21/30], Batch [720/1045], Loss: 0.5698\n",
      "Epoch [21/30], Batch [730/1045], Loss: 0.5843\n",
      "Epoch [21/30], Batch [740/1045], Loss: 0.5041\n",
      "Epoch [21/30], Batch [750/1045], Loss: 0.4340\n",
      "Epoch [21/30], Batch [760/1045], Loss: 0.5817\n",
      "Epoch [21/30], Batch [770/1045], Loss: 0.6457\n",
      "Epoch [21/30], Batch [780/1045], Loss: 0.4932\n",
      "Epoch [21/30], Batch [790/1045], Loss: 0.9295\n",
      "Epoch [21/30], Batch [800/1045], Loss: 0.6321\n",
      "Epoch [21/30], Batch [810/1045], Loss: 0.7439\n",
      "Epoch [21/30], Batch [820/1045], Loss: 1.0352\n",
      "Epoch [21/30], Batch [830/1045], Loss: 0.5116\n",
      "Epoch [21/30], Batch [840/1045], Loss: 0.5897\n",
      "Epoch [21/30], Batch [850/1045], Loss: 0.5356\n",
      "Epoch [21/30], Batch [860/1045], Loss: 0.5709\n",
      "Epoch [21/30], Batch [870/1045], Loss: 0.7181\n",
      "Epoch [21/30], Batch [880/1045], Loss: 0.5806\n",
      "Epoch [21/30], Batch [890/1045], Loss: 0.6071\n",
      "Epoch [21/30], Batch [900/1045], Loss: 0.7783\n",
      "Epoch [21/30], Batch [910/1045], Loss: 0.4023\n",
      "Epoch [21/30], Batch [920/1045], Loss: 0.4768\n",
      "Epoch [21/30], Batch [930/1045], Loss: 0.4186\n",
      "Epoch [21/30], Batch [940/1045], Loss: 0.4719\n",
      "Epoch [21/30], Batch [950/1045], Loss: 0.3915\n",
      "Epoch [21/30], Batch [960/1045], Loss: 0.2933\n",
      "Epoch [21/30], Batch [970/1045], Loss: 0.6216\n",
      "Epoch [21/30], Batch [980/1045], Loss: 0.6328\n",
      "Epoch [21/30], Batch [990/1045], Loss: 0.5605\n",
      "Epoch [21/30], Batch [1000/1045], Loss: 0.5752\n",
      "Epoch [21/30], Batch [1010/1045], Loss: 0.4253\n",
      "Epoch [21/30], Batch [1020/1045], Loss: 0.4791\n",
      "Epoch [21/30], Batch [1030/1045], Loss: 0.5371\n",
      "Epoch [21/30], Batch [1040/1045], Loss: 0.6575\n",
      "Epoch [21/30] - Average Loss: 0.5613, Accuracy: 0.7637\n",
      "Epoch [22/30], Batch [10/1045], Loss: 0.3691\n",
      "Epoch [22/30], Batch [20/1045], Loss: 0.4530\n",
      "Epoch [22/30], Batch [30/1045], Loss: 0.3622\n",
      "Epoch [22/30], Batch [40/1045], Loss: 0.5410\n",
      "Epoch [22/30], Batch [50/1045], Loss: 0.4351\n",
      "Epoch [22/30], Batch [60/1045], Loss: 0.6674\n",
      "Epoch [22/30], Batch [70/1045], Loss: 0.5102\n",
      "Epoch [22/30], Batch [80/1045], Loss: 0.9881\n",
      "Epoch [22/30], Batch [90/1045], Loss: 0.5328\n",
      "Epoch [22/30], Batch [100/1045], Loss: 0.3327\n",
      "Epoch [22/30], Batch [110/1045], Loss: 0.8517\n",
      "Epoch [22/30], Batch [120/1045], Loss: 0.5739\n",
      "Epoch [22/30], Batch [130/1045], Loss: 0.4548\n",
      "Epoch [22/30], Batch [140/1045], Loss: 0.5810\n",
      "Epoch [22/30], Batch [150/1045], Loss: 0.5908\n",
      "Epoch [22/30], Batch [160/1045], Loss: 0.3580\n",
      "Epoch [22/30], Batch [170/1045], Loss: 0.4403\n",
      "Epoch [22/30], Batch [180/1045], Loss: 0.5219\n",
      "Epoch [22/30], Batch [190/1045], Loss: 0.6523\n",
      "Epoch [22/30], Batch [200/1045], Loss: 0.7068\n",
      "Epoch [22/30], Batch [210/1045], Loss: 0.6905\n",
      "Epoch [22/30], Batch [220/1045], Loss: 0.6136\n",
      "Epoch [22/30], Batch [230/1045], Loss: 0.6851\n",
      "Epoch [22/30], Batch [240/1045], Loss: 0.7829\n",
      "Epoch [22/30], Batch [250/1045], Loss: 0.5592\n",
      "Epoch [22/30], Batch [260/1045], Loss: 0.5313\n",
      "Epoch [22/30], Batch [270/1045], Loss: 0.4429\n",
      "Epoch [22/30], Batch [280/1045], Loss: 0.4505\n",
      "Epoch [22/30], Batch [290/1045], Loss: 0.6821\n",
      "Epoch [22/30], Batch [300/1045], Loss: 0.3587\n",
      "Epoch [22/30], Batch [310/1045], Loss: 0.4492\n",
      "Epoch [22/30], Batch [320/1045], Loss: 0.4474\n",
      "Epoch [22/30], Batch [330/1045], Loss: 0.4811\n",
      "Epoch [22/30], Batch [340/1045], Loss: 0.6196\n",
      "Epoch [22/30], Batch [350/1045], Loss: 0.3779\n",
      "Epoch [22/30], Batch [360/1045], Loss: 0.7012\n",
      "Epoch [22/30], Batch [370/1045], Loss: 0.7263\n",
      "Epoch [22/30], Batch [380/1045], Loss: 0.5383\n",
      "Epoch [22/30], Batch [390/1045], Loss: 0.4957\n",
      "Epoch [22/30], Batch [400/1045], Loss: 0.6403\n",
      "Epoch [22/30], Batch [410/1045], Loss: 0.7340\n",
      "Epoch [22/30], Batch [420/1045], Loss: 0.4131\n",
      "Epoch [22/30], Batch [430/1045], Loss: 0.5273\n",
      "Epoch [22/30], Batch [440/1045], Loss: 0.5299\n",
      "Epoch [22/30], Batch [450/1045], Loss: 0.4376\n",
      "Epoch [22/30], Batch [460/1045], Loss: 0.5380\n",
      "Epoch [22/30], Batch [470/1045], Loss: 0.5419\n",
      "Epoch [22/30], Batch [480/1045], Loss: 0.6995\n",
      "Epoch [22/30], Batch [490/1045], Loss: 0.4704\n",
      "Epoch [22/30], Batch [500/1045], Loss: 0.7147\n",
      "Epoch [22/30], Batch [510/1045], Loss: 0.5472\n",
      "Epoch [22/30], Batch [520/1045], Loss: 0.3748\n",
      "Epoch [22/30], Batch [530/1045], Loss: 0.5652\n",
      "Epoch [22/30], Batch [540/1045], Loss: 0.5929\n",
      "Epoch [22/30], Batch [550/1045], Loss: 0.4240\n",
      "Epoch [22/30], Batch [560/1045], Loss: 0.5067\n",
      "Epoch [22/30], Batch [570/1045], Loss: 0.5878\n",
      "Epoch [22/30], Batch [580/1045], Loss: 0.8802\n",
      "Epoch [22/30], Batch [590/1045], Loss: 0.6786\n",
      "Epoch [22/30], Batch [600/1045], Loss: 0.3960\n",
      "Epoch [22/30], Batch [610/1045], Loss: 0.4051\n",
      "Epoch [22/30], Batch [620/1045], Loss: 0.6531\n",
      "Epoch [22/30], Batch [630/1045], Loss: 0.5463\n",
      "Epoch [22/30], Batch [640/1045], Loss: 0.7290\n",
      "Epoch [22/30], Batch [650/1045], Loss: 0.5762\n",
      "Epoch [22/30], Batch [660/1045], Loss: 0.4876\n",
      "Epoch [22/30], Batch [670/1045], Loss: 0.7594\n",
      "Epoch [22/30], Batch [680/1045], Loss: 0.6867\n",
      "Epoch [22/30], Batch [690/1045], Loss: 0.5726\n",
      "Epoch [22/30], Batch [700/1045], Loss: 0.6300\n",
      "Epoch [22/30], Batch [710/1045], Loss: 0.4104\n",
      "Epoch [22/30], Batch [720/1045], Loss: 0.5638\n",
      "Epoch [22/30], Batch [730/1045], Loss: 0.4384\n",
      "Epoch [22/30], Batch [740/1045], Loss: 0.5522\n",
      "Epoch [22/30], Batch [750/1045], Loss: 0.5316\n",
      "Epoch [22/30], Batch [760/1045], Loss: 0.9021\n",
      "Epoch [22/30], Batch [770/1045], Loss: 0.5737\n",
      "Epoch [22/30], Batch [780/1045], Loss: 0.6952\n",
      "Epoch [22/30], Batch [790/1045], Loss: 0.8961\n",
      "Epoch [22/30], Batch [800/1045], Loss: 0.6481\n",
      "Epoch [22/30], Batch [810/1045], Loss: 0.5727\n",
      "Epoch [22/30], Batch [820/1045], Loss: 0.6864\n",
      "Epoch [22/30], Batch [830/1045], Loss: 0.4149\n",
      "Epoch [22/30], Batch [840/1045], Loss: 0.7000\n",
      "Epoch [22/30], Batch [850/1045], Loss: 0.4212\n",
      "Epoch [22/30], Batch [860/1045], Loss: 0.3025\n",
      "Epoch [22/30], Batch [870/1045], Loss: 0.3942\n",
      "Epoch [22/30], Batch [880/1045], Loss: 0.4034\n",
      "Epoch [22/30], Batch [890/1045], Loss: 0.6584\n",
      "Epoch [22/30], Batch [900/1045], Loss: 0.4702\n",
      "Epoch [22/30], Batch [910/1045], Loss: 0.4098\n",
      "Epoch [22/30], Batch [920/1045], Loss: 0.4720\n",
      "Epoch [22/30], Batch [930/1045], Loss: 0.4920\n",
      "Epoch [22/30], Batch [940/1045], Loss: 0.8493\n",
      "Epoch [22/30], Batch [950/1045], Loss: 0.6542\n",
      "Epoch [22/30], Batch [960/1045], Loss: 0.4109\n",
      "Epoch [22/30], Batch [970/1045], Loss: 0.3236\n",
      "Epoch [22/30], Batch [980/1045], Loss: 0.7446\n",
      "Epoch [22/30], Batch [990/1045], Loss: 0.5466\n",
      "Epoch [22/30], Batch [1000/1045], Loss: 0.6662\n",
      "Epoch [22/30], Batch [1010/1045], Loss: 0.4388\n",
      "Epoch [22/30], Batch [1020/1045], Loss: 0.7841\n",
      "Epoch [22/30], Batch [1030/1045], Loss: 0.6455\n",
      "Epoch [22/30], Batch [1040/1045], Loss: 0.6295\n",
      "Epoch [22/30] - Average Loss: 0.5591, Accuracy: 0.7635\n",
      "Epoch [23/30], Batch [10/1045], Loss: 0.8240\n",
      "Epoch [23/30], Batch [20/1045], Loss: 0.2825\n",
      "Epoch [23/30], Batch [30/1045], Loss: 0.5770\n",
      "Epoch [23/30], Batch [40/1045], Loss: 0.4534\n",
      "Epoch [23/30], Batch [50/1045], Loss: 0.3762\n",
      "Epoch [23/30], Batch [60/1045], Loss: 0.7140\n",
      "Epoch [23/30], Batch [70/1045], Loss: 0.5328\n",
      "Epoch [23/30], Batch [80/1045], Loss: 0.3274\n",
      "Epoch [23/30], Batch [90/1045], Loss: 0.3974\n",
      "Epoch [23/30], Batch [100/1045], Loss: 0.3024\n",
      "Epoch [23/30], Batch [110/1045], Loss: 0.5872\n",
      "Epoch [23/30], Batch [120/1045], Loss: 0.4254\n",
      "Epoch [23/30], Batch [130/1045], Loss: 0.7246\n",
      "Epoch [23/30], Batch [140/1045], Loss: 0.5825\n",
      "Epoch [23/30], Batch [150/1045], Loss: 0.4161\n",
      "Epoch [23/30], Batch [160/1045], Loss: 0.3989\n",
      "Epoch [23/30], Batch [170/1045], Loss: 0.7542\n",
      "Epoch [23/30], Batch [180/1045], Loss: 0.4856\n",
      "Epoch [23/30], Batch [190/1045], Loss: 0.5256\n",
      "Epoch [23/30], Batch [200/1045], Loss: 0.4073\n",
      "Epoch [23/30], Batch [210/1045], Loss: 0.3957\n",
      "Epoch [23/30], Batch [220/1045], Loss: 0.5432\n",
      "Epoch [23/30], Batch [230/1045], Loss: 0.7372\n",
      "Epoch [23/30], Batch [240/1045], Loss: 0.5797\n",
      "Epoch [23/30], Batch [250/1045], Loss: 0.5237\n",
      "Epoch [23/30], Batch [260/1045], Loss: 0.5542\n",
      "Epoch [23/30], Batch [270/1045], Loss: 0.4928\n",
      "Epoch [23/30], Batch [280/1045], Loss: 0.2417\n",
      "Epoch [23/30], Batch [290/1045], Loss: 0.5160\n",
      "Epoch [23/30], Batch [300/1045], Loss: 0.4604\n",
      "Epoch [23/30], Batch [310/1045], Loss: 0.5283\n",
      "Epoch [23/30], Batch [320/1045], Loss: 0.5848\n",
      "Epoch [23/30], Batch [330/1045], Loss: 0.5227\n",
      "Epoch [23/30], Batch [340/1045], Loss: 0.5101\n",
      "Epoch [23/30], Batch [350/1045], Loss: 0.5426\n",
      "Epoch [23/30], Batch [360/1045], Loss: 0.4890\n",
      "Epoch [23/30], Batch [370/1045], Loss: 0.4261\n",
      "Epoch [23/30], Batch [380/1045], Loss: 0.5465\n",
      "Epoch [23/30], Batch [390/1045], Loss: 0.5438\n",
      "Epoch [23/30], Batch [400/1045], Loss: 0.4685\n",
      "Epoch [23/30], Batch [410/1045], Loss: 0.5266\n",
      "Epoch [23/30], Batch [420/1045], Loss: 0.5739\n",
      "Epoch [23/30], Batch [430/1045], Loss: 0.5338\n",
      "Epoch [23/30], Batch [440/1045], Loss: 0.5981\n",
      "Epoch [23/30], Batch [450/1045], Loss: 0.4115\n",
      "Epoch [23/30], Batch [460/1045], Loss: 0.6030\n",
      "Epoch [23/30], Batch [470/1045], Loss: 0.5587\n",
      "Epoch [23/30], Batch [480/1045], Loss: 0.5482\n",
      "Epoch [23/30], Batch [490/1045], Loss: 0.4612\n",
      "Epoch [23/30], Batch [500/1045], Loss: 0.5611\n",
      "Epoch [23/30], Batch [510/1045], Loss: 0.5185\n",
      "Epoch [23/30], Batch [520/1045], Loss: 0.5926\n",
      "Epoch [23/30], Batch [530/1045], Loss: 0.5252\n",
      "Epoch [23/30], Batch [540/1045], Loss: 0.4569\n",
      "Epoch [23/30], Batch [550/1045], Loss: 0.5053\n",
      "Epoch [23/30], Batch [560/1045], Loss: 0.2954\n",
      "Epoch [23/30], Batch [570/1045], Loss: 0.3596\n",
      "Epoch [23/30], Batch [580/1045], Loss: 1.0122\n",
      "Epoch [23/30], Batch [590/1045], Loss: 0.4734\n",
      "Epoch [23/30], Batch [600/1045], Loss: 0.6443\n",
      "Epoch [23/30], Batch [610/1045], Loss: 0.5368\n",
      "Epoch [23/30], Batch [620/1045], Loss: 0.4189\n",
      "Epoch [23/30], Batch [630/1045], Loss: 0.4782\n",
      "Epoch [23/30], Batch [640/1045], Loss: 0.5374\n",
      "Epoch [23/30], Batch [650/1045], Loss: 0.6987\n",
      "Epoch [23/30], Batch [660/1045], Loss: 0.4212\n",
      "Epoch [23/30], Batch [670/1045], Loss: 0.5537\n",
      "Epoch [23/30], Batch [680/1045], Loss: 0.4716\n",
      "Epoch [23/30], Batch [690/1045], Loss: 0.5206\n",
      "Epoch [23/30], Batch [700/1045], Loss: 0.6135\n",
      "Epoch [23/30], Batch [710/1045], Loss: 0.6234\n",
      "Epoch [23/30], Batch [720/1045], Loss: 0.6101\n",
      "Epoch [23/30], Batch [730/1045], Loss: 0.5694\n",
      "Epoch [23/30], Batch [740/1045], Loss: 0.6451\n",
      "Epoch [23/30], Batch [750/1045], Loss: 0.6696\n",
      "Epoch [23/30], Batch [760/1045], Loss: 0.8573\n",
      "Epoch [23/30], Batch [770/1045], Loss: 0.5767\n",
      "Epoch [23/30], Batch [780/1045], Loss: 0.6072\n",
      "Epoch [23/30], Batch [790/1045], Loss: 0.4611\n",
      "Epoch [23/30], Batch [800/1045], Loss: 0.3422\n",
      "Epoch [23/30], Batch [810/1045], Loss: 0.7710\n",
      "Epoch [23/30], Batch [820/1045], Loss: 0.5796\n",
      "Epoch [23/30], Batch [830/1045], Loss: 0.3865\n",
      "Epoch [23/30], Batch [840/1045], Loss: 0.6878\n",
      "Epoch [23/30], Batch [850/1045], Loss: 0.5450\n",
      "Epoch [23/30], Batch [860/1045], Loss: 0.4862\n",
      "Epoch [23/30], Batch [870/1045], Loss: 0.7335\n",
      "Epoch [23/30], Batch [880/1045], Loss: 0.5579\n",
      "Epoch [23/30], Batch [890/1045], Loss: 0.5409\n",
      "Epoch [23/30], Batch [900/1045], Loss: 0.6464\n",
      "Epoch [23/30], Batch [910/1045], Loss: 0.3394\n",
      "Epoch [23/30], Batch [920/1045], Loss: 0.5817\n",
      "Epoch [23/30], Batch [930/1045], Loss: 0.5775\n",
      "Epoch [23/30], Batch [940/1045], Loss: 0.5555\n",
      "Epoch [23/30], Batch [950/1045], Loss: 0.6069\n",
      "Epoch [23/30], Batch [960/1045], Loss: 0.7068\n",
      "Epoch [23/30], Batch [970/1045], Loss: 0.5571\n",
      "Epoch [23/30], Batch [980/1045], Loss: 0.5832\n",
      "Epoch [23/30], Batch [990/1045], Loss: 0.4468\n",
      "Epoch [23/30], Batch [1000/1045], Loss: 0.6001\n",
      "Epoch [23/30], Batch [1010/1045], Loss: 0.6091\n",
      "Epoch [23/30], Batch [1020/1045], Loss: 0.4428\n",
      "Epoch [23/30], Batch [1030/1045], Loss: 0.3645\n",
      "Epoch [23/30], Batch [1040/1045], Loss: 0.6480\n",
      "Epoch [23/30] - Average Loss: 0.5546, Accuracy: 0.7646\n",
      "Epoch [24/30], Batch [10/1045], Loss: 0.3399\n",
      "Epoch [24/30], Batch [20/1045], Loss: 0.4306\n",
      "Epoch [24/30], Batch [30/1045], Loss: 0.3860\n",
      "Epoch [24/30], Batch [40/1045], Loss: 0.5303\n",
      "Epoch [24/30], Batch [50/1045], Loss: 0.4556\n",
      "Epoch [24/30], Batch [60/1045], Loss: 0.5428\n",
      "Epoch [24/30], Batch [70/1045], Loss: 0.7705\n",
      "Epoch [24/30], Batch [80/1045], Loss: 0.6466\n",
      "Epoch [24/30], Batch [90/1045], Loss: 0.4710\n",
      "Epoch [24/30], Batch [100/1045], Loss: 0.4685\n",
      "Epoch [24/30], Batch [110/1045], Loss: 0.6527\n",
      "Epoch [24/30], Batch [120/1045], Loss: 0.7217\n",
      "Epoch [24/30], Batch [130/1045], Loss: 0.5669\n",
      "Epoch [24/30], Batch [140/1045], Loss: 0.5044\n",
      "Epoch [24/30], Batch [150/1045], Loss: 0.5122\n",
      "Epoch [24/30], Batch [160/1045], Loss: 0.6373\n",
      "Epoch [24/30], Batch [170/1045], Loss: 0.5779\n",
      "Epoch [24/30], Batch [180/1045], Loss: 0.6035\n",
      "Epoch [24/30], Batch [190/1045], Loss: 0.4915\n",
      "Epoch [24/30], Batch [200/1045], Loss: 0.4095\n",
      "Epoch [24/30], Batch [210/1045], Loss: 0.2736\n",
      "Epoch [24/30], Batch [220/1045], Loss: 0.3854\n",
      "Epoch [24/30], Batch [230/1045], Loss: 0.5511\n",
      "Epoch [24/30], Batch [240/1045], Loss: 0.5517\n",
      "Epoch [24/30], Batch [250/1045], Loss: 0.6896\n",
      "Epoch [24/30], Batch [260/1045], Loss: 0.6974\n",
      "Epoch [24/30], Batch [270/1045], Loss: 0.5474\n",
      "Epoch [24/30], Batch [280/1045], Loss: 0.3528\n",
      "Epoch [24/30], Batch [290/1045], Loss: 0.4155\n",
      "Epoch [24/30], Batch [300/1045], Loss: 0.6077\n",
      "Epoch [24/30], Batch [310/1045], Loss: 0.5712\n",
      "Epoch [24/30], Batch [320/1045], Loss: 0.8115\n",
      "Epoch [24/30], Batch [330/1045], Loss: 0.5638\n",
      "Epoch [24/30], Batch [340/1045], Loss: 0.6790\n",
      "Epoch [24/30], Batch [350/1045], Loss: 0.6243\n",
      "Epoch [24/30], Batch [360/1045], Loss: 0.4871\n",
      "Epoch [24/30], Batch [370/1045], Loss: 0.4037\n",
      "Epoch [24/30], Batch [380/1045], Loss: 0.6580\n",
      "Epoch [24/30], Batch [390/1045], Loss: 0.7429\n",
      "Epoch [24/30], Batch [400/1045], Loss: 0.5656\n",
      "Epoch [24/30], Batch [410/1045], Loss: 0.5076\n",
      "Epoch [24/30], Batch [420/1045], Loss: 0.7284\n",
      "Epoch [24/30], Batch [430/1045], Loss: 0.5330\n",
      "Epoch [24/30], Batch [440/1045], Loss: 0.3764\n",
      "Epoch [24/30], Batch [450/1045], Loss: 0.4372\n",
      "Epoch [24/30], Batch [460/1045], Loss: 0.6098\n",
      "Epoch [24/30], Batch [470/1045], Loss: 0.5930\n",
      "Epoch [24/30], Batch [480/1045], Loss: 0.6482\n",
      "Epoch [24/30], Batch [490/1045], Loss: 0.6335\n",
      "Epoch [24/30], Batch [500/1045], Loss: 0.8490\n",
      "Epoch [24/30], Batch [510/1045], Loss: 0.5079\n",
      "Epoch [24/30], Batch [520/1045], Loss: 0.8026\n",
      "Epoch [24/30], Batch [530/1045], Loss: 0.7048\n",
      "Epoch [24/30], Batch [540/1045], Loss: 0.4255\n",
      "Epoch [24/30], Batch [550/1045], Loss: 0.4308\n",
      "Epoch [24/30], Batch [560/1045], Loss: 0.5469\n",
      "Epoch [24/30], Batch [570/1045], Loss: 0.6158\n",
      "Epoch [24/30], Batch [580/1045], Loss: 0.4788\n",
      "Epoch [24/30], Batch [590/1045], Loss: 0.7726\n",
      "Epoch [24/30], Batch [600/1045], Loss: 1.1941\n",
      "Epoch [24/30], Batch [610/1045], Loss: 0.6293\n",
      "Epoch [24/30], Batch [620/1045], Loss: 0.6327\n",
      "Epoch [24/30], Batch [630/1045], Loss: 0.5871\n",
      "Epoch [24/30], Batch [640/1045], Loss: 0.8439\n",
      "Epoch [24/30], Batch [650/1045], Loss: 0.6172\n",
      "Epoch [24/30], Batch [660/1045], Loss: 0.7015\n",
      "Epoch [24/30], Batch [670/1045], Loss: 0.5626\n",
      "Epoch [24/30], Batch [680/1045], Loss: 0.5674\n",
      "Epoch [24/30], Batch [690/1045], Loss: 0.4583\n",
      "Epoch [24/30], Batch [700/1045], Loss: 0.5006\n",
      "Epoch [24/30], Batch [710/1045], Loss: 0.4886\n",
      "Epoch [24/30], Batch [720/1045], Loss: 0.5391\n",
      "Epoch [24/30], Batch [730/1045], Loss: 0.6107\n",
      "Epoch [24/30], Batch [740/1045], Loss: 0.6154\n",
      "Epoch [24/30], Batch [750/1045], Loss: 0.4704\n",
      "Epoch [24/30], Batch [760/1045], Loss: 0.4344\n",
      "Epoch [24/30], Batch [770/1045], Loss: 0.7841\n",
      "Epoch [24/30], Batch [780/1045], Loss: 0.6964\n",
      "Epoch [24/30], Batch [790/1045], Loss: 0.4672\n",
      "Epoch [24/30], Batch [800/1045], Loss: 0.7277\n",
      "Epoch [24/30], Batch [810/1045], Loss: 0.5136\n",
      "Epoch [24/30], Batch [820/1045], Loss: 0.3039\n",
      "Epoch [24/30], Batch [830/1045], Loss: 0.4323\n",
      "Epoch [24/30], Batch [840/1045], Loss: 0.5030\n",
      "Epoch [24/30], Batch [850/1045], Loss: 0.5703\n",
      "Epoch [24/30], Batch [860/1045], Loss: 0.6040\n",
      "Epoch [24/30], Batch [870/1045], Loss: 0.6488\n",
      "Epoch [24/30], Batch [880/1045], Loss: 0.5199\n",
      "Epoch [24/30], Batch [890/1045], Loss: 0.4493\n",
      "Epoch [24/30], Batch [900/1045], Loss: 0.4070\n",
      "Epoch [24/30], Batch [910/1045], Loss: 0.6335\n",
      "Epoch [24/30], Batch [920/1045], Loss: 0.6391\n",
      "Epoch [24/30], Batch [930/1045], Loss: 0.4741\n",
      "Epoch [24/30], Batch [940/1045], Loss: 0.9054\n",
      "Epoch [24/30], Batch [950/1045], Loss: 0.6629\n",
      "Epoch [24/30], Batch [960/1045], Loss: 0.3770\n",
      "Epoch [24/30], Batch [970/1045], Loss: 0.6353\n",
      "Epoch [24/30], Batch [980/1045], Loss: 0.3839\n",
      "Epoch [24/30], Batch [990/1045], Loss: 0.7705\n",
      "Epoch [24/30], Batch [1000/1045], Loss: 0.4437\n",
      "Epoch [24/30], Batch [1010/1045], Loss: 0.7682\n",
      "Epoch [24/30], Batch [1020/1045], Loss: 0.7076\n",
      "Epoch [24/30], Batch [1030/1045], Loss: 0.4962\n",
      "Epoch [24/30], Batch [1040/1045], Loss: 0.5788\n",
      "Epoch [24/30] - Average Loss: 0.5556, Accuracy: 0.7624\n",
      "Epoch [25/30], Batch [10/1045], Loss: 0.4607\n",
      "Epoch [25/30], Batch [20/1045], Loss: 0.4209\n",
      "Epoch [25/30], Batch [30/1045], Loss: 0.6856\n",
      "Epoch [25/30], Batch [40/1045], Loss: 0.4606\n",
      "Epoch [25/30], Batch [50/1045], Loss: 0.3263\n",
      "Epoch [25/30], Batch [60/1045], Loss: 0.5337\n",
      "Epoch [25/30], Batch [70/1045], Loss: 0.6496\n",
      "Epoch [25/30], Batch [80/1045], Loss: 0.5474\n",
      "Epoch [25/30], Batch [90/1045], Loss: 0.4852\n",
      "Epoch [25/30], Batch [100/1045], Loss: 0.4154\n",
      "Epoch [25/30], Batch [110/1045], Loss: 0.4400\n",
      "Epoch [25/30], Batch [120/1045], Loss: 0.5537\n",
      "Epoch [25/30], Batch [130/1045], Loss: 0.6777\n",
      "Epoch [25/30], Batch [140/1045], Loss: 0.6864\n",
      "Epoch [25/30], Batch [150/1045], Loss: 0.4602\n",
      "Epoch [25/30], Batch [160/1045], Loss: 0.6905\n",
      "Epoch [25/30], Batch [170/1045], Loss: 0.5380\n",
      "Epoch [25/30], Batch [180/1045], Loss: 0.4809\n",
      "Epoch [25/30], Batch [190/1045], Loss: 0.3541\n",
      "Epoch [25/30], Batch [200/1045], Loss: 0.5805\n",
      "Epoch [25/30], Batch [210/1045], Loss: 0.6395\n",
      "Epoch [25/30], Batch [220/1045], Loss: 0.4540\n",
      "Epoch [25/30], Batch [230/1045], Loss: 0.4722\n",
      "Epoch [25/30], Batch [240/1045], Loss: 0.6126\n",
      "Epoch [25/30], Batch [250/1045], Loss: 0.6756\n",
      "Epoch [25/30], Batch [260/1045], Loss: 0.6267\n",
      "Epoch [25/30], Batch [270/1045], Loss: 0.4868\n",
      "Epoch [25/30], Batch [280/1045], Loss: 0.4606\n",
      "Epoch [25/30], Batch [290/1045], Loss: 0.6202\n",
      "Epoch [25/30], Batch [300/1045], Loss: 0.4237\n",
      "Epoch [25/30], Batch [310/1045], Loss: 0.5181\n",
      "Epoch [25/30], Batch [320/1045], Loss: 0.4804\n",
      "Epoch [25/30], Batch [330/1045], Loss: 0.5546\n",
      "Epoch [25/30], Batch [340/1045], Loss: 0.9137\n",
      "Epoch [25/30], Batch [350/1045], Loss: 0.5563\n",
      "Epoch [25/30], Batch [360/1045], Loss: 0.6638\n",
      "Epoch [25/30], Batch [370/1045], Loss: 0.5265\n",
      "Epoch [25/30], Batch [380/1045], Loss: 0.6950\n",
      "Epoch [25/30], Batch [390/1045], Loss: 0.7767\n",
      "Epoch [25/30], Batch [400/1045], Loss: 0.5183\n",
      "Epoch [25/30], Batch [410/1045], Loss: 0.5308\n",
      "Epoch [25/30], Batch [420/1045], Loss: 0.4727\n",
      "Epoch [25/30], Batch [430/1045], Loss: 0.4319\n",
      "Epoch [25/30], Batch [440/1045], Loss: 0.6400\n",
      "Epoch [25/30], Batch [450/1045], Loss: 0.4413\n",
      "Epoch [25/30], Batch [460/1045], Loss: 0.3884\n",
      "Epoch [25/30], Batch [470/1045], Loss: 0.4438\n",
      "Epoch [25/30], Batch [480/1045], Loss: 0.5278\n",
      "Epoch [25/30], Batch [490/1045], Loss: 0.5865\n",
      "Epoch [25/30], Batch [500/1045], Loss: 0.4340\n",
      "Epoch [25/30], Batch [510/1045], Loss: 0.5737\n",
      "Epoch [25/30], Batch [520/1045], Loss: 0.5063\n",
      "Epoch [25/30], Batch [530/1045], Loss: 0.3414\n",
      "Epoch [25/30], Batch [540/1045], Loss: 0.5804\n",
      "Epoch [25/30], Batch [550/1045], Loss: 0.4642\n",
      "Epoch [25/30], Batch [560/1045], Loss: 0.6056\n",
      "Epoch [25/30], Batch [570/1045], Loss: 0.4552\n",
      "Epoch [25/30], Batch [580/1045], Loss: 0.4207\n",
      "Epoch [25/30], Batch [590/1045], Loss: 0.6243\n",
      "Epoch [25/30], Batch [600/1045], Loss: 0.6356\n",
      "Epoch [25/30], Batch [610/1045], Loss: 0.4495\n",
      "Epoch [25/30], Batch [620/1045], Loss: 0.4795\n",
      "Epoch [25/30], Batch [630/1045], Loss: 0.6862\n",
      "Epoch [25/30], Batch [640/1045], Loss: 0.7001\n",
      "Epoch [25/30], Batch [650/1045], Loss: 0.4513\n",
      "Epoch [25/30], Batch [660/1045], Loss: 0.6710\n",
      "Epoch [25/30], Batch [670/1045], Loss: 0.6641\n",
      "Epoch [25/30], Batch [680/1045], Loss: 0.6051\n",
      "Epoch [25/30], Batch [690/1045], Loss: 0.5227\n",
      "Epoch [25/30], Batch [700/1045], Loss: 0.6606\n",
      "Epoch [25/30], Batch [710/1045], Loss: 0.6463\n",
      "Epoch [25/30], Batch [720/1045], Loss: 0.5021\n",
      "Epoch [25/30], Batch [730/1045], Loss: 0.5182\n",
      "Epoch [25/30], Batch [740/1045], Loss: 0.5992\n",
      "Epoch [25/30], Batch [750/1045], Loss: 0.8847\n",
      "Epoch [25/30], Batch [760/1045], Loss: 0.4960\n",
      "Epoch [25/30], Batch [770/1045], Loss: 0.4571\n",
      "Epoch [25/30], Batch [780/1045], Loss: 0.4881\n",
      "Epoch [25/30], Batch [790/1045], Loss: 0.5898\n",
      "Epoch [25/30], Batch [800/1045], Loss: 0.3813\n",
      "Epoch [25/30], Batch [810/1045], Loss: 0.4776\n",
      "Epoch [25/30], Batch [820/1045], Loss: 0.6939\n",
      "Epoch [25/30], Batch [830/1045], Loss: 0.6630\n",
      "Epoch [25/30], Batch [840/1045], Loss: 0.6216\n",
      "Epoch [25/30], Batch [850/1045], Loss: 0.4672\n",
      "Epoch [25/30], Batch [860/1045], Loss: 0.5770\n",
      "Epoch [25/30], Batch [870/1045], Loss: 0.4551\n",
      "Epoch [25/30], Batch [880/1045], Loss: 0.6418\n",
      "Epoch [25/30], Batch [890/1045], Loss: 0.6798\n",
      "Epoch [25/30], Batch [900/1045], Loss: 0.4369\n",
      "Epoch [25/30], Batch [910/1045], Loss: 0.5169\n",
      "Epoch [25/30], Batch [920/1045], Loss: 0.5180\n",
      "Epoch [25/30], Batch [930/1045], Loss: 0.4138\n",
      "Epoch [25/30], Batch [940/1045], Loss: 0.7865\n",
      "Epoch [25/30], Batch [950/1045], Loss: 0.7237\n",
      "Epoch [25/30], Batch [960/1045], Loss: 0.5589\n",
      "Epoch [25/30], Batch [970/1045], Loss: 0.4807\n",
      "Epoch [25/30], Batch [980/1045], Loss: 0.5229\n",
      "Epoch [25/30], Batch [990/1045], Loss: 0.4261\n",
      "Epoch [25/30], Batch [1000/1045], Loss: 0.4011\n",
      "Epoch [25/30], Batch [1010/1045], Loss: 0.6610\n",
      "Epoch [25/30], Batch [1020/1045], Loss: 0.5925\n",
      "Epoch [25/30], Batch [1030/1045], Loss: 0.3268\n",
      "Epoch [25/30], Batch [1040/1045], Loss: 0.6724\n",
      "Epoch [25/30] - Average Loss: 0.5480, Accuracy: 0.7647\n",
      "Epoch [26/30], Batch [10/1045], Loss: 0.5355\n",
      "Epoch [26/30], Batch [20/1045], Loss: 0.5604\n",
      "Epoch [26/30], Batch [30/1045], Loss: 0.7424\n",
      "Epoch [26/30], Batch [40/1045], Loss: 0.6786\n",
      "Epoch [26/30], Batch [50/1045], Loss: 0.4206\n",
      "Epoch [26/30], Batch [60/1045], Loss: 0.8097\n",
      "Epoch [26/30], Batch [70/1045], Loss: 0.5674\n",
      "Epoch [26/30], Batch [80/1045], Loss: 0.4865\n",
      "Epoch [26/30], Batch [90/1045], Loss: 0.6005\n",
      "Epoch [26/30], Batch [100/1045], Loss: 0.6245\n",
      "Epoch [26/30], Batch [110/1045], Loss: 0.8443\n",
      "Epoch [26/30], Batch [120/1045], Loss: 0.4625\n",
      "Epoch [26/30], Batch [130/1045], Loss: 0.6341\n",
      "Epoch [26/30], Batch [140/1045], Loss: 0.5708\n",
      "Epoch [26/30], Batch [150/1045], Loss: 0.5306\n",
      "Epoch [26/30], Batch [160/1045], Loss: 0.4523\n",
      "Epoch [26/30], Batch [170/1045], Loss: 0.5122\n",
      "Epoch [26/30], Batch [180/1045], Loss: 0.5323\n",
      "Epoch [26/30], Batch [190/1045], Loss: 0.3265\n",
      "Epoch [26/30], Batch [200/1045], Loss: 0.5312\n",
      "Epoch [26/30], Batch [210/1045], Loss: 0.6135\n",
      "Epoch [26/30], Batch [220/1045], Loss: 0.5354\n",
      "Epoch [26/30], Batch [230/1045], Loss: 0.5892\n",
      "Epoch [26/30], Batch [240/1045], Loss: 0.5116\n",
      "Epoch [26/30], Batch [250/1045], Loss: 0.5142\n",
      "Epoch [26/30], Batch [260/1045], Loss: 0.5531\n",
      "Epoch [26/30], Batch [270/1045], Loss: 0.5634\n",
      "Epoch [26/30], Batch [280/1045], Loss: 0.3610\n",
      "Epoch [26/30], Batch [290/1045], Loss: 0.5532\n",
      "Epoch [26/30], Batch [300/1045], Loss: 0.5359\n",
      "Epoch [26/30], Batch [310/1045], Loss: 0.4634\n",
      "Epoch [26/30], Batch [320/1045], Loss: 0.6152\n",
      "Epoch [26/30], Batch [330/1045], Loss: 0.6253\n",
      "Epoch [26/30], Batch [340/1045], Loss: 0.5840\n",
      "Epoch [26/30], Batch [350/1045], Loss: 0.4686\n",
      "Epoch [26/30], Batch [360/1045], Loss: 0.6321\n",
      "Epoch [26/30], Batch [370/1045], Loss: 0.3491\n",
      "Epoch [26/30], Batch [380/1045], Loss: 0.7754\n",
      "Epoch [26/30], Batch [390/1045], Loss: 0.6024\n",
      "Epoch [26/30], Batch [400/1045], Loss: 0.6173\n",
      "Epoch [26/30], Batch [410/1045], Loss: 0.4022\n",
      "Epoch [26/30], Batch [420/1045], Loss: 0.5506\n",
      "Epoch [26/30], Batch [430/1045], Loss: 0.4995\n",
      "Epoch [26/30], Batch [440/1045], Loss: 0.4140\n",
      "Epoch [26/30], Batch [450/1045], Loss: 0.8305\n",
      "Epoch [26/30], Batch [460/1045], Loss: 0.4095\n",
      "Epoch [26/30], Batch [470/1045], Loss: 0.6556\n",
      "Epoch [26/30], Batch [480/1045], Loss: 0.5144\n",
      "Epoch [26/30], Batch [490/1045], Loss: 0.7521\n",
      "Epoch [26/30], Batch [500/1045], Loss: 0.6583\n",
      "Epoch [26/30], Batch [510/1045], Loss: 0.6575\n",
      "Epoch [26/30], Batch [520/1045], Loss: 0.4435\n",
      "Epoch [26/30], Batch [530/1045], Loss: 0.7756\n",
      "Epoch [26/30], Batch [540/1045], Loss: 0.6748\n",
      "Epoch [26/30], Batch [550/1045], Loss: 0.6070\n",
      "Epoch [26/30], Batch [560/1045], Loss: 0.7125\n",
      "Epoch [26/30], Batch [570/1045], Loss: 0.4851\n",
      "Epoch [26/30], Batch [580/1045], Loss: 0.3924\n",
      "Epoch [26/30], Batch [590/1045], Loss: 0.5176\n",
      "Epoch [26/30], Batch [600/1045], Loss: 0.4904\n",
      "Epoch [26/30], Batch [610/1045], Loss: 0.3443\n",
      "Epoch [26/30], Batch [620/1045], Loss: 0.6492\n",
      "Epoch [26/30], Batch [630/1045], Loss: 0.3622\n",
      "Epoch [26/30], Batch [640/1045], Loss: 0.5236\n",
      "Epoch [26/30], Batch [650/1045], Loss: 0.7217\n",
      "Epoch [26/30], Batch [660/1045], Loss: 0.4168\n",
      "Epoch [26/30], Batch [670/1045], Loss: 0.3769\n",
      "Epoch [26/30], Batch [680/1045], Loss: 0.7715\n",
      "Epoch [26/30], Batch [690/1045], Loss: 0.6919\n",
      "Epoch [26/30], Batch [700/1045], Loss: 0.6492\n",
      "Epoch [26/30], Batch [710/1045], Loss: 0.6714\n",
      "Epoch [26/30], Batch [720/1045], Loss: 0.4602\n",
      "Epoch [26/30], Batch [730/1045], Loss: 0.6457\n",
      "Epoch [26/30], Batch [740/1045], Loss: 0.6806\n",
      "Epoch [26/30], Batch [750/1045], Loss: 0.4311\n",
      "Epoch [26/30], Batch [760/1045], Loss: 0.6830\n",
      "Epoch [26/30], Batch [770/1045], Loss: 0.4560\n",
      "Epoch [26/30], Batch [780/1045], Loss: 0.5622\n",
      "Epoch [26/30], Batch [790/1045], Loss: 0.4052\n",
      "Epoch [26/30], Batch [800/1045], Loss: 0.4337\n",
      "Epoch [26/30], Batch [810/1045], Loss: 0.7934\n",
      "Epoch [26/30], Batch [820/1045], Loss: 0.6510\n",
      "Epoch [26/30], Batch [830/1045], Loss: 0.7656\n",
      "Epoch [26/30], Batch [840/1045], Loss: 0.6752\n",
      "Epoch [26/30], Batch [850/1045], Loss: 0.5048\n",
      "Epoch [26/30], Batch [860/1045], Loss: 0.5665\n",
      "Epoch [26/30], Batch [870/1045], Loss: 0.5501\n",
      "Epoch [26/30], Batch [880/1045], Loss: 0.3715\n",
      "Epoch [26/30], Batch [890/1045], Loss: 0.7192\n",
      "Epoch [26/30], Batch [900/1045], Loss: 0.6411\n",
      "Epoch [26/30], Batch [910/1045], Loss: 0.4322\n",
      "Epoch [26/30], Batch [920/1045], Loss: 0.8671\n",
      "Epoch [26/30], Batch [930/1045], Loss: 0.7732\n",
      "Epoch [26/30], Batch [940/1045], Loss: 0.4836\n",
      "Epoch [26/30], Batch [950/1045], Loss: 0.4713\n",
      "Epoch [26/30], Batch [960/1045], Loss: 0.6758\n",
      "Epoch [26/30], Batch [970/1045], Loss: 0.5397\n",
      "Epoch [26/30], Batch [980/1045], Loss: 0.3619\n",
      "Epoch [26/30], Batch [990/1045], Loss: 0.3767\n",
      "Epoch [26/30], Batch [1000/1045], Loss: 0.4380\n",
      "Epoch [26/30], Batch [1010/1045], Loss: 0.6702\n",
      "Epoch [26/30], Batch [1020/1045], Loss: 0.4870\n",
      "Epoch [26/30], Batch [1030/1045], Loss: 0.5595\n",
      "Epoch [26/30], Batch [1040/1045], Loss: 0.5089\n",
      "Epoch [26/30] - Average Loss: 0.5486, Accuracy: 0.7663\n",
      "Epoch [27/30], Batch [10/1045], Loss: 0.4592\n",
      "Epoch [27/30], Batch [20/1045], Loss: 0.3641\n",
      "Epoch [27/30], Batch [30/1045], Loss: 0.4631\n",
      "Epoch [27/30], Batch [40/1045], Loss: 0.4242\n",
      "Epoch [27/30], Batch [50/1045], Loss: 0.6954\n",
      "Epoch [27/30], Batch [60/1045], Loss: 0.3357\n",
      "Epoch [27/30], Batch [70/1045], Loss: 0.5474\n",
      "Epoch [27/30], Batch [80/1045], Loss: 0.2728\n",
      "Epoch [27/30], Batch [90/1045], Loss: 0.7162\n",
      "Epoch [27/30], Batch [100/1045], Loss: 0.8235\n",
      "Epoch [27/30], Batch [110/1045], Loss: 0.4451\n",
      "Epoch [27/30], Batch [120/1045], Loss: 0.3777\n",
      "Epoch [27/30], Batch [130/1045], Loss: 0.4942\n",
      "Epoch [27/30], Batch [140/1045], Loss: 0.4222\n",
      "Epoch [27/30], Batch [150/1045], Loss: 0.7353\n",
      "Epoch [27/30], Batch [160/1045], Loss: 0.6059\n",
      "Epoch [27/30], Batch [170/1045], Loss: 0.4806\n",
      "Epoch [27/30], Batch [180/1045], Loss: 0.4130\n",
      "Epoch [27/30], Batch [190/1045], Loss: 0.6967\n",
      "Epoch [27/30], Batch [200/1045], Loss: 0.6440\n",
      "Epoch [27/30], Batch [210/1045], Loss: 0.4155\n",
      "Epoch [27/30], Batch [220/1045], Loss: 0.5361\n",
      "Epoch [27/30], Batch [230/1045], Loss: 0.6685\n",
      "Epoch [27/30], Batch [240/1045], Loss: 0.3980\n",
      "Epoch [27/30], Batch [250/1045], Loss: 0.4631\n",
      "Epoch [27/30], Batch [260/1045], Loss: 0.6860\n",
      "Epoch [27/30], Batch [270/1045], Loss: 0.4245\n",
      "Epoch [27/30], Batch [280/1045], Loss: 0.4638\n",
      "Epoch [27/30], Batch [290/1045], Loss: 0.6303\n",
      "Epoch [27/30], Batch [300/1045], Loss: 0.5123\n",
      "Epoch [27/30], Batch [310/1045], Loss: 0.4822\n",
      "Epoch [27/30], Batch [320/1045], Loss: 0.4598\n",
      "Epoch [27/30], Batch [330/1045], Loss: 0.6768\n",
      "Epoch [27/30], Batch [340/1045], Loss: 0.3784\n",
      "Epoch [27/30], Batch [350/1045], Loss: 0.3885\n",
      "Epoch [27/30], Batch [360/1045], Loss: 0.7925\n",
      "Epoch [27/30], Batch [370/1045], Loss: 0.7968\n",
      "Epoch [27/30], Batch [380/1045], Loss: 0.3982\n",
      "Epoch [27/30], Batch [390/1045], Loss: 0.5549\n",
      "Epoch [27/30], Batch [400/1045], Loss: 0.5688\n",
      "Epoch [27/30], Batch [410/1045], Loss: 0.7879\n",
      "Epoch [27/30], Batch [420/1045], Loss: 0.7849\n",
      "Epoch [27/30], Batch [430/1045], Loss: 1.0427\n",
      "Epoch [27/30], Batch [440/1045], Loss: 0.5736\n",
      "Epoch [27/30], Batch [450/1045], Loss: 0.6042\n",
      "Epoch [27/30], Batch [460/1045], Loss: 0.7760\n",
      "Epoch [27/30], Batch [470/1045], Loss: 0.5140\n",
      "Epoch [27/30], Batch [480/1045], Loss: 0.7174\n",
      "Epoch [27/30], Batch [490/1045], Loss: 0.4806\n",
      "Epoch [27/30], Batch [500/1045], Loss: 0.5949\n",
      "Epoch [27/30], Batch [510/1045], Loss: 0.6667\n",
      "Epoch [27/30], Batch [520/1045], Loss: 0.5701\n",
      "Epoch [27/30], Batch [530/1045], Loss: 0.5899\n",
      "Epoch [27/30], Batch [540/1045], Loss: 0.7207\n",
      "Epoch [27/30], Batch [550/1045], Loss: 0.8218\n",
      "Epoch [27/30], Batch [560/1045], Loss: 0.4381\n",
      "Epoch [27/30], Batch [570/1045], Loss: 0.6832\n",
      "Epoch [27/30], Batch [580/1045], Loss: 0.4808\n",
      "Epoch [27/30], Batch [590/1045], Loss: 0.6624\n",
      "Epoch [27/30], Batch [600/1045], Loss: 0.5297\n",
      "Epoch [27/30], Batch [610/1045], Loss: 0.4991\n",
      "Epoch [27/30], Batch [620/1045], Loss: 0.4865\n",
      "Epoch [27/30], Batch [630/1045], Loss: 0.5693\n",
      "Epoch [27/30], Batch [640/1045], Loss: 0.5909\n",
      "Epoch [27/30], Batch [650/1045], Loss: 0.3810\n",
      "Epoch [27/30], Batch [660/1045], Loss: 0.7694\n",
      "Epoch [27/30], Batch [670/1045], Loss: 0.7462\n",
      "Epoch [27/30], Batch [680/1045], Loss: 0.6230\n",
      "Epoch [27/30], Batch [690/1045], Loss: 0.4843\n",
      "Epoch [27/30], Batch [700/1045], Loss: 0.4659\n",
      "Epoch [27/30], Batch [710/1045], Loss: 0.4839\n",
      "Epoch [27/30], Batch [720/1045], Loss: 0.4957\n",
      "Epoch [27/30], Batch [730/1045], Loss: 0.5479\n",
      "Epoch [27/30], Batch [740/1045], Loss: 0.6927\n",
      "Epoch [27/30], Batch [750/1045], Loss: 0.4616\n",
      "Epoch [27/30], Batch [760/1045], Loss: 0.2801\n",
      "Epoch [27/30], Batch [770/1045], Loss: 0.7614\n",
      "Epoch [27/30], Batch [780/1045], Loss: 0.5911\n",
      "Epoch [27/30], Batch [790/1045], Loss: 0.7144\n",
      "Epoch [27/30], Batch [800/1045], Loss: 0.7045\n",
      "Epoch [27/30], Batch [810/1045], Loss: 0.3743\n",
      "Epoch [27/30], Batch [820/1045], Loss: 0.5801\n",
      "Epoch [27/30], Batch [830/1045], Loss: 0.5674\n",
      "Epoch [27/30], Batch [840/1045], Loss: 0.6339\n",
      "Epoch [27/30], Batch [850/1045], Loss: 0.5946\n",
      "Epoch [27/30], Batch [860/1045], Loss: 0.4140\n",
      "Epoch [27/30], Batch [870/1045], Loss: 0.7555\n",
      "Epoch [27/30], Batch [880/1045], Loss: 0.6901\n",
      "Epoch [27/30], Batch [890/1045], Loss: 0.8614\n",
      "Epoch [27/30], Batch [900/1045], Loss: 0.3043\n",
      "Epoch [27/30], Batch [910/1045], Loss: 0.6100\n",
      "Epoch [27/30], Batch [920/1045], Loss: 0.4866\n",
      "Epoch [27/30], Batch [930/1045], Loss: 0.6424\n",
      "Epoch [27/30], Batch [940/1045], Loss: 0.4456\n",
      "Epoch [27/30], Batch [950/1045], Loss: 0.6073\n",
      "Epoch [27/30], Batch [960/1045], Loss: 0.6634\n",
      "Epoch [27/30], Batch [970/1045], Loss: 0.6439\n",
      "Epoch [27/30], Batch [980/1045], Loss: 0.5567\n",
      "Epoch [27/30], Batch [990/1045], Loss: 0.4056\n",
      "Epoch [27/30], Batch [1000/1045], Loss: 0.5199\n",
      "Epoch [27/30], Batch [1010/1045], Loss: 0.5157\n",
      "Epoch [27/30], Batch [1020/1045], Loss: 0.6557\n",
      "Epoch [27/30], Batch [1030/1045], Loss: 0.4921\n",
      "Epoch [27/30], Batch [1040/1045], Loss: 0.4563\n",
      "Epoch [27/30] - Average Loss: 0.5520, Accuracy: 0.7653\n",
      "Epoch [28/30], Batch [10/1045], Loss: 0.3685\n",
      "Epoch [28/30], Batch [20/1045], Loss: 0.5057\n",
      "Epoch [28/30], Batch [30/1045], Loss: 0.4895\n",
      "Epoch [28/30], Batch [40/1045], Loss: 0.6010\n",
      "Epoch [28/30], Batch [50/1045], Loss: 0.4847\n",
      "Epoch [28/30], Batch [60/1045], Loss: 0.6468\n",
      "Epoch [28/30], Batch [70/1045], Loss: 0.5342\n",
      "Epoch [28/30], Batch [80/1045], Loss: 0.6608\n",
      "Epoch [28/30], Batch [90/1045], Loss: 0.4263\n",
      "Epoch [28/30], Batch [100/1045], Loss: 0.4072\n",
      "Epoch [28/30], Batch [110/1045], Loss: 0.3671\n",
      "Epoch [28/30], Batch [120/1045], Loss: 0.5311\n",
      "Epoch [28/30], Batch [130/1045], Loss: 0.3346\n",
      "Epoch [28/30], Batch [140/1045], Loss: 0.6469\n",
      "Epoch [28/30], Batch [150/1045], Loss: 0.5786\n",
      "Epoch [28/30], Batch [160/1045], Loss: 0.3957\n",
      "Epoch [28/30], Batch [170/1045], Loss: 0.5324\n",
      "Epoch [28/30], Batch [180/1045], Loss: 0.8675\n",
      "Epoch [28/30], Batch [190/1045], Loss: 0.5785\n",
      "Epoch [28/30], Batch [200/1045], Loss: 0.5482\n",
      "Epoch [28/30], Batch [210/1045], Loss: 0.6134\n",
      "Epoch [28/30], Batch [220/1045], Loss: 0.6172\n",
      "Epoch [28/30], Batch [230/1045], Loss: 0.3976\n",
      "Epoch [28/30], Batch [240/1045], Loss: 0.6595\n",
      "Epoch [28/30], Batch [250/1045], Loss: 0.4223\n",
      "Epoch [28/30], Batch [260/1045], Loss: 0.4684\n",
      "Epoch [28/30], Batch [270/1045], Loss: 0.5192\n",
      "Epoch [28/30], Batch [280/1045], Loss: 0.8043\n",
      "Epoch [28/30], Batch [290/1045], Loss: 0.6203\n",
      "Epoch [28/30], Batch [300/1045], Loss: 0.6055\n",
      "Epoch [28/30], Batch [310/1045], Loss: 0.5419\n",
      "Epoch [28/30], Batch [320/1045], Loss: 0.6871\n",
      "Epoch [28/30], Batch [330/1045], Loss: 0.4911\n",
      "Epoch [28/30], Batch [340/1045], Loss: 0.3773\n",
      "Epoch [28/30], Batch [350/1045], Loss: 0.6163\n",
      "Epoch [28/30], Batch [360/1045], Loss: 0.3770\n",
      "Epoch [28/30], Batch [370/1045], Loss: 0.5111\n",
      "Epoch [28/30], Batch [380/1045], Loss: 0.5764\n",
      "Epoch [28/30], Batch [390/1045], Loss: 0.4650\n",
      "Epoch [28/30], Batch [400/1045], Loss: 0.3350\n",
      "Epoch [28/30], Batch [410/1045], Loss: 0.5319\n",
      "Epoch [28/30], Batch [420/1045], Loss: 0.6551\n",
      "Epoch [28/30], Batch [430/1045], Loss: 0.5222\n",
      "Epoch [28/30], Batch [440/1045], Loss: 0.5768\n",
      "Epoch [28/30], Batch [450/1045], Loss: 0.3744\n",
      "Epoch [28/30], Batch [460/1045], Loss: 0.6704\n",
      "Epoch [28/30], Batch [470/1045], Loss: 0.7124\n",
      "Epoch [28/30], Batch [480/1045], Loss: 0.4274\n",
      "Epoch [28/30], Batch [490/1045], Loss: 0.6037\n",
      "Epoch [28/30], Batch [500/1045], Loss: 0.5256\n",
      "Epoch [28/30], Batch [510/1045], Loss: 0.7268\n",
      "Epoch [28/30], Batch [520/1045], Loss: 0.6178\n",
      "Epoch [28/30], Batch [530/1045], Loss: 0.4473\n",
      "Epoch [28/30], Batch [540/1045], Loss: 0.4765\n",
      "Epoch [28/30], Batch [550/1045], Loss: 0.4098\n",
      "Epoch [28/30], Batch [560/1045], Loss: 0.4787\n",
      "Epoch [28/30], Batch [570/1045], Loss: 0.5654\n",
      "Epoch [28/30], Batch [580/1045], Loss: 0.5188\n",
      "Epoch [28/30], Batch [590/1045], Loss: 0.4537\n",
      "Epoch [28/30], Batch [600/1045], Loss: 0.4868\n",
      "Epoch [28/30], Batch [610/1045], Loss: 0.5384\n",
      "Epoch [28/30], Batch [620/1045], Loss: 0.6501\n",
      "Epoch [28/30], Batch [630/1045], Loss: 0.5615\n",
      "Epoch [28/30], Batch [640/1045], Loss: 0.6376\n",
      "Epoch [28/30], Batch [650/1045], Loss: 0.4856\n",
      "Epoch [28/30], Batch [660/1045], Loss: 0.5047\n",
      "Epoch [28/30], Batch [670/1045], Loss: 0.4896\n",
      "Epoch [28/30], Batch [680/1045], Loss: 0.4946\n",
      "Epoch [28/30], Batch [690/1045], Loss: 0.4651\n",
      "Epoch [28/30], Batch [700/1045], Loss: 0.5727\n",
      "Epoch [28/30], Batch [710/1045], Loss: 0.5360\n",
      "Epoch [28/30], Batch [720/1045], Loss: 0.5420\n",
      "Epoch [28/30], Batch [730/1045], Loss: 0.5276\n",
      "Epoch [28/30], Batch [740/1045], Loss: 0.6720\n",
      "Epoch [28/30], Batch [750/1045], Loss: 0.4703\n",
      "Epoch [28/30], Batch [760/1045], Loss: 0.4938\n",
      "Epoch [28/30], Batch [770/1045], Loss: 0.5479\n",
      "Epoch [28/30], Batch [780/1045], Loss: 0.5579\n",
      "Epoch [28/30], Batch [790/1045], Loss: 0.3794\n",
      "Epoch [28/30], Batch [800/1045], Loss: 0.5946\n",
      "Epoch [28/30], Batch [810/1045], Loss: 0.3848\n",
      "Epoch [28/30], Batch [820/1045], Loss: 0.3798\n",
      "Epoch [28/30], Batch [830/1045], Loss: 0.4399\n",
      "Epoch [28/30], Batch [840/1045], Loss: 0.5834\n",
      "Epoch [28/30], Batch [850/1045], Loss: 0.8185\n",
      "Epoch [28/30], Batch [860/1045], Loss: 0.8885\n",
      "Epoch [28/30], Batch [870/1045], Loss: 0.5602\n",
      "Epoch [28/30], Batch [880/1045], Loss: 0.4908\n",
      "Epoch [28/30], Batch [890/1045], Loss: 0.4873\n",
      "Epoch [28/30], Batch [900/1045], Loss: 0.5631\n",
      "Epoch [28/30], Batch [910/1045], Loss: 0.5523\n",
      "Epoch [28/30], Batch [920/1045], Loss: 0.3336\n",
      "Epoch [28/30], Batch [930/1045], Loss: 0.4019\n",
      "Epoch [28/30], Batch [940/1045], Loss: 0.7774\n",
      "Epoch [28/30], Batch [950/1045], Loss: 0.6253\n",
      "Epoch [28/30], Batch [960/1045], Loss: 0.3238\n",
      "Epoch [28/30], Batch [970/1045], Loss: 0.4294\n",
      "Epoch [28/30], Batch [980/1045], Loss: 0.5218\n",
      "Epoch [28/30], Batch [990/1045], Loss: 0.6080\n",
      "Epoch [28/30], Batch [1000/1045], Loss: 0.5071\n",
      "Epoch [28/30], Batch [1010/1045], Loss: 0.4231\n",
      "Epoch [28/30], Batch [1020/1045], Loss: 0.7281\n",
      "Epoch [28/30], Batch [1030/1045], Loss: 0.4934\n",
      "Epoch [28/30], Batch [1040/1045], Loss: 0.6393\n",
      "Epoch [28/30] - Average Loss: 0.5400, Accuracy: 0.7695\n",
      "Epoch [29/30], Batch [10/1045], Loss: 0.6212\n",
      "Epoch [29/30], Batch [20/1045], Loss: 0.3288\n",
      "Epoch [29/30], Batch [30/1045], Loss: 0.9412\n",
      "Epoch [29/30], Batch [40/1045], Loss: 0.3376\n",
      "Epoch [29/30], Batch [50/1045], Loss: 0.4410\n",
      "Epoch [29/30], Batch [60/1045], Loss: 0.5640\n",
      "Epoch [29/30], Batch [70/1045], Loss: 0.5347\n",
      "Epoch [29/30], Batch [80/1045], Loss: 0.4461\n",
      "Epoch [29/30], Batch [90/1045], Loss: 0.6163\n",
      "Epoch [29/30], Batch [100/1045], Loss: 0.3091\n",
      "Epoch [29/30], Batch [110/1045], Loss: 0.5658\n",
      "Epoch [29/30], Batch [120/1045], Loss: 0.5158\n",
      "Epoch [29/30], Batch [130/1045], Loss: 0.6907\n",
      "Epoch [29/30], Batch [140/1045], Loss: 0.2849\n",
      "Epoch [29/30], Batch [150/1045], Loss: 0.5741\n",
      "Epoch [29/30], Batch [160/1045], Loss: 0.6608\n",
      "Epoch [29/30], Batch [170/1045], Loss: 0.3129\n",
      "Epoch [29/30], Batch [180/1045], Loss: 0.4613\n",
      "Epoch [29/30], Batch [190/1045], Loss: 0.7056\n",
      "Epoch [29/30], Batch [200/1045], Loss: 0.5775\n",
      "Epoch [29/30], Batch [210/1045], Loss: 0.4641\n",
      "Epoch [29/30], Batch [220/1045], Loss: 0.5609\n",
      "Epoch [29/30], Batch [230/1045], Loss: 0.6609\n",
      "Epoch [29/30], Batch [240/1045], Loss: 0.4812\n",
      "Epoch [29/30], Batch [250/1045], Loss: 0.5570\n",
      "Epoch [29/30], Batch [260/1045], Loss: 0.4291\n",
      "Epoch [29/30], Batch [270/1045], Loss: 0.5198\n",
      "Epoch [29/30], Batch [280/1045], Loss: 0.2904\n",
      "Epoch [29/30], Batch [290/1045], Loss: 0.5682\n",
      "Epoch [29/30], Batch [300/1045], Loss: 0.6104\n",
      "Epoch [29/30], Batch [310/1045], Loss: 0.3842\n",
      "Epoch [29/30], Batch [320/1045], Loss: 0.6484\n",
      "Epoch [29/30], Batch [330/1045], Loss: 0.6699\n",
      "Epoch [29/30], Batch [340/1045], Loss: 0.4717\n",
      "Epoch [29/30], Batch [350/1045], Loss: 0.4601\n",
      "Epoch [29/30], Batch [360/1045], Loss: 0.6208\n",
      "Epoch [29/30], Batch [370/1045], Loss: 0.5581\n",
      "Epoch [29/30], Batch [380/1045], Loss: 0.4386\n",
      "Epoch [29/30], Batch [390/1045], Loss: 1.0067\n",
      "Epoch [29/30], Batch [400/1045], Loss: 0.5279\n",
      "Epoch [29/30], Batch [410/1045], Loss: 0.7427\n",
      "Epoch [29/30], Batch [420/1045], Loss: 0.6340\n",
      "Epoch [29/30], Batch [430/1045], Loss: 0.5698\n",
      "Epoch [29/30], Batch [440/1045], Loss: 0.5338\n",
      "Epoch [29/30], Batch [450/1045], Loss: 0.6629\n",
      "Epoch [29/30], Batch [460/1045], Loss: 0.4784\n",
      "Epoch [29/30], Batch [470/1045], Loss: 0.5741\n",
      "Epoch [29/30], Batch [480/1045], Loss: 0.4325\n",
      "Epoch [29/30], Batch [490/1045], Loss: 0.6415\n",
      "Epoch [29/30], Batch [500/1045], Loss: 0.4083\n",
      "Epoch [29/30], Batch [510/1045], Loss: 0.6059\n",
      "Epoch [29/30], Batch [520/1045], Loss: 0.4152\n",
      "Epoch [29/30], Batch [530/1045], Loss: 0.4541\n",
      "Epoch [29/30], Batch [540/1045], Loss: 0.6989\n",
      "Epoch [29/30], Batch [550/1045], Loss: 0.4742\n",
      "Epoch [29/30], Batch [560/1045], Loss: 0.5894\n",
      "Epoch [29/30], Batch [570/1045], Loss: 0.4633\n",
      "Epoch [29/30], Batch [580/1045], Loss: 0.5685\n",
      "Epoch [29/30], Batch [590/1045], Loss: 0.7171\n",
      "Epoch [29/30], Batch [600/1045], Loss: 0.4290\n",
      "Epoch [29/30], Batch [610/1045], Loss: 0.6244\n",
      "Epoch [29/30], Batch [620/1045], Loss: 0.2884\n",
      "Epoch [29/30], Batch [630/1045], Loss: 0.4850\n",
      "Epoch [29/30], Batch [640/1045], Loss: 0.5980\n",
      "Epoch [29/30], Batch [650/1045], Loss: 0.5625\n",
      "Epoch [29/30], Batch [660/1045], Loss: 0.4040\n",
      "Epoch [29/30], Batch [670/1045], Loss: 0.5115\n",
      "Epoch [29/30], Batch [680/1045], Loss: 0.7495\n",
      "Epoch [29/30], Batch [690/1045], Loss: 0.7712\n",
      "Epoch [29/30], Batch [700/1045], Loss: 0.4679\n",
      "Epoch [29/30], Batch [710/1045], Loss: 0.5008\n",
      "Epoch [29/30], Batch [720/1045], Loss: 0.4784\n",
      "Epoch [29/30], Batch [730/1045], Loss: 0.3948\n",
      "Epoch [29/30], Batch [740/1045], Loss: 0.4979\n",
      "Epoch [29/30], Batch [750/1045], Loss: 0.5175\n",
      "Epoch [29/30], Batch [760/1045], Loss: 0.5267\n",
      "Epoch [29/30], Batch [770/1045], Loss: 0.4506\n",
      "Epoch [29/30], Batch [780/1045], Loss: 0.5565\n",
      "Epoch [29/30], Batch [790/1045], Loss: 0.4371\n",
      "Epoch [29/30], Batch [800/1045], Loss: 0.3590\n",
      "Epoch [29/30], Batch [810/1045], Loss: 0.5206\n",
      "Epoch [29/30], Batch [820/1045], Loss: 0.4539\n",
      "Epoch [29/30], Batch [830/1045], Loss: 0.6194\n",
      "Epoch [29/30], Batch [840/1045], Loss: 0.5933\n",
      "Epoch [29/30], Batch [850/1045], Loss: 0.4761\n",
      "Epoch [29/30], Batch [860/1045], Loss: 0.5393\n",
      "Epoch [29/30], Batch [870/1045], Loss: 0.5908\n",
      "Epoch [29/30], Batch [880/1045], Loss: 0.5739\n",
      "Epoch [29/30], Batch [890/1045], Loss: 0.5307\n",
      "Epoch [29/30], Batch [900/1045], Loss: 0.4294\n",
      "Epoch [29/30], Batch [910/1045], Loss: 0.5783\n",
      "Epoch [29/30], Batch [920/1045], Loss: 0.8706\n",
      "Epoch [29/30], Batch [930/1045], Loss: 0.6364\n",
      "Epoch [29/30], Batch [940/1045], Loss: 0.5904\n",
      "Epoch [29/30], Batch [950/1045], Loss: 0.7361\n",
      "Epoch [29/30], Batch [960/1045], Loss: 0.6992\n",
      "Epoch [29/30], Batch [970/1045], Loss: 0.4714\n",
      "Epoch [29/30], Batch [980/1045], Loss: 0.5726\n",
      "Epoch [29/30], Batch [990/1045], Loss: 0.4394\n",
      "Epoch [29/30], Batch [1000/1045], Loss: 0.4454\n",
      "Epoch [29/30], Batch [1010/1045], Loss: 0.4463\n",
      "Epoch [29/30], Batch [1020/1045], Loss: 0.4262\n",
      "Epoch [29/30], Batch [1030/1045], Loss: 0.4359\n",
      "Epoch [29/30], Batch [1040/1045], Loss: 0.5207\n",
      "Epoch [29/30] - Average Loss: 0.5424, Accuracy: 0.7658\n",
      "Epoch [30/30], Batch [10/1045], Loss: 0.6147\n",
      "Epoch [30/30], Batch [20/1045], Loss: 0.3807\n",
      "Epoch [30/30], Batch [30/1045], Loss: 0.3570\n",
      "Epoch [30/30], Batch [40/1045], Loss: 0.6685\n",
      "Epoch [30/30], Batch [50/1045], Loss: 0.4800\n",
      "Epoch [30/30], Batch [60/1045], Loss: 0.3608\n",
      "Epoch [30/30], Batch [70/1045], Loss: 0.4291\n",
      "Epoch [30/30], Batch [80/1045], Loss: 0.7344\n",
      "Epoch [30/30], Batch [90/1045], Loss: 0.5498\n",
      "Epoch [30/30], Batch [100/1045], Loss: 0.5616\n",
      "Epoch [30/30], Batch [110/1045], Loss: 0.5406\n",
      "Epoch [30/30], Batch [120/1045], Loss: 0.4213\n",
      "Epoch [30/30], Batch [130/1045], Loss: 0.6281\n",
      "Epoch [30/30], Batch [140/1045], Loss: 0.6639\n",
      "Epoch [30/30], Batch [150/1045], Loss: 0.4795\n",
      "Epoch [30/30], Batch [160/1045], Loss: 0.6239\n",
      "Epoch [30/30], Batch [170/1045], Loss: 0.5998\n",
      "Epoch [30/30], Batch [180/1045], Loss: 0.6078\n",
      "Epoch [30/30], Batch [190/1045], Loss: 0.7988\n",
      "Epoch [30/30], Batch [200/1045], Loss: 0.4778\n",
      "Epoch [30/30], Batch [210/1045], Loss: 0.3168\n",
      "Epoch [30/30], Batch [220/1045], Loss: 0.5454\n",
      "Epoch [30/30], Batch [230/1045], Loss: 0.5664\n",
      "Epoch [30/30], Batch [240/1045], Loss: 0.3033\n",
      "Epoch [30/30], Batch [250/1045], Loss: 0.7182\n",
      "Epoch [30/30], Batch [260/1045], Loss: 0.5160\n",
      "Epoch [30/30], Batch [270/1045], Loss: 0.5315\n",
      "Epoch [30/30], Batch [280/1045], Loss: 0.4641\n",
      "Epoch [30/30], Batch [290/1045], Loss: 0.4131\n",
      "Epoch [30/30], Batch [300/1045], Loss: 0.8123\n",
      "Epoch [30/30], Batch [310/1045], Loss: 0.4691\n",
      "Epoch [30/30], Batch [320/1045], Loss: 0.5556\n",
      "Epoch [30/30], Batch [330/1045], Loss: 0.5007\n",
      "Epoch [30/30], Batch [340/1045], Loss: 0.5670\n",
      "Epoch [30/30], Batch [350/1045], Loss: 0.4891\n",
      "Epoch [30/30], Batch [360/1045], Loss: 0.8763\n",
      "Epoch [30/30], Batch [370/1045], Loss: 0.5136\n",
      "Epoch [30/30], Batch [380/1045], Loss: 0.8492\n",
      "Epoch [30/30], Batch [390/1045], Loss: 0.7569\n",
      "Epoch [30/30], Batch [400/1045], Loss: 0.5113\n",
      "Epoch [30/30], Batch [410/1045], Loss: 0.6082\n",
      "Epoch [30/30], Batch [420/1045], Loss: 0.4824\n",
      "Epoch [30/30], Batch [430/1045], Loss: 0.5132\n",
      "Epoch [30/30], Batch [440/1045], Loss: 0.5901\n",
      "Epoch [30/30], Batch [450/1045], Loss: 0.8013\n",
      "Epoch [30/30], Batch [460/1045], Loss: 0.5952\n",
      "Epoch [30/30], Batch [470/1045], Loss: 0.5165\n",
      "Epoch [30/30], Batch [480/1045], Loss: 0.6056\n",
      "Epoch [30/30], Batch [490/1045], Loss: 0.4462\n",
      "Epoch [30/30], Batch [500/1045], Loss: 0.5750\n",
      "Epoch [30/30], Batch [510/1045], Loss: 0.5741\n",
      "Epoch [30/30], Batch [520/1045], Loss: 0.3939\n",
      "Epoch [30/30], Batch [530/1045], Loss: 0.4466\n",
      "Epoch [30/30], Batch [540/1045], Loss: 0.8809\n",
      "Epoch [30/30], Batch [550/1045], Loss: 0.5659\n",
      "Epoch [30/30], Batch [560/1045], Loss: 0.5486\n",
      "Epoch [30/30], Batch [570/1045], Loss: 0.5355\n",
      "Epoch [30/30], Batch [580/1045], Loss: 0.5409\n",
      "Epoch [30/30], Batch [590/1045], Loss: 0.4758\n",
      "Epoch [30/30], Batch [600/1045], Loss: 0.6881\n",
      "Epoch [30/30], Batch [610/1045], Loss: 0.5184\n",
      "Epoch [30/30], Batch [620/1045], Loss: 0.7165\n",
      "Epoch [30/30], Batch [630/1045], Loss: 0.4145\n",
      "Epoch [30/30], Batch [640/1045], Loss: 0.5648\n",
      "Epoch [30/30], Batch [650/1045], Loss: 0.4133\n",
      "Epoch [30/30], Batch [660/1045], Loss: 0.4655\n",
      "Epoch [30/30], Batch [670/1045], Loss: 0.5648\n",
      "Epoch [30/30], Batch [680/1045], Loss: 0.4079\n",
      "Epoch [30/30], Batch [690/1045], Loss: 0.3898\n",
      "Epoch [30/30], Batch [700/1045], Loss: 0.6708\n",
      "Epoch [30/30], Batch [710/1045], Loss: 0.5870\n",
      "Epoch [30/30], Batch [720/1045], Loss: 0.7058\n",
      "Epoch [30/30], Batch [730/1045], Loss: 0.5061\n",
      "Epoch [30/30], Batch [740/1045], Loss: 0.4007\n",
      "Epoch [30/30], Batch [750/1045], Loss: 0.5593\n",
      "Epoch [30/30], Batch [760/1045], Loss: 0.4418\n",
      "Epoch [30/30], Batch [770/1045], Loss: 0.6718\n",
      "Epoch [30/30], Batch [780/1045], Loss: 0.4975\n",
      "Epoch [30/30], Batch [790/1045], Loss: 0.3534\n",
      "Epoch [30/30], Batch [800/1045], Loss: 0.5312\n",
      "Epoch [30/30], Batch [810/1045], Loss: 0.5743\n",
      "Epoch [30/30], Batch [820/1045], Loss: 0.4944\n",
      "Epoch [30/30], Batch [830/1045], Loss: 0.4972\n",
      "Epoch [30/30], Batch [840/1045], Loss: 0.4616\n",
      "Epoch [30/30], Batch [850/1045], Loss: 0.7582\n",
      "Epoch [30/30], Batch [860/1045], Loss: 0.5289\n",
      "Epoch [30/30], Batch [870/1045], Loss: 0.6388\n",
      "Epoch [30/30], Batch [880/1045], Loss: 0.4770\n",
      "Epoch [30/30], Batch [890/1045], Loss: 0.6636\n",
      "Epoch [30/30], Batch [900/1045], Loss: 0.3559\n",
      "Epoch [30/30], Batch [910/1045], Loss: 0.4713\n",
      "Epoch [30/30], Batch [920/1045], Loss: 0.6567\n",
      "Epoch [30/30], Batch [930/1045], Loss: 0.3472\n",
      "Epoch [30/30], Batch [940/1045], Loss: 0.4113\n",
      "Epoch [30/30], Batch [950/1045], Loss: 0.5139\n",
      "Epoch [30/30], Batch [960/1045], Loss: 0.6333\n",
      "Epoch [30/30], Batch [970/1045], Loss: 0.4286\n",
      "Epoch [30/30], Batch [980/1045], Loss: 0.6423\n",
      "Epoch [30/30], Batch [990/1045], Loss: 0.3888\n",
      "Epoch [30/30], Batch [1000/1045], Loss: 0.4309\n",
      "Epoch [30/30], Batch [1010/1045], Loss: 0.5263\n",
      "Epoch [30/30], Batch [1020/1045], Loss: 0.5908\n",
      "Epoch [30/30], Batch [1030/1045], Loss: 0.4018\n",
      "Epoch [30/30], Batch [1040/1045], Loss: 0.5465\n",
      "Epoch [30/30] - Average Loss: 0.5435, Accuracy: 0.7637\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating the Model...\n",
      "\n",
      "Test Accuracy: 0.9527\n",
      "Precision (Weighted): 0.9561\n",
      "Recall (Weighted): 0.9527\n",
      "F1-Score (Weighted): 0.9534\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Use GPU if available, otherwise fallback to CPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Load pretrained EfficientNet model\n",
    "    efficientnet_model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "    efficientnet_classifier = EfficientNetClassifier(efficientnet_model)\n",
    "    efficientnet_classifier = efficientnet_classifier.to(device)\n",
    "\n",
    "    # Loss and optimizer\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(efficientnet_classifier.parameters(), lr=0.001)\n",
    "\n",
    "    # Data loaders\n",
    "    train_loader = get_data_loader('train/_annotations.csv', 'train', transform=transform)\n",
    "    test_loader = get_data_loader('test/_annotations.csv', 'test', transform=transform, shuffle=False)\n",
    "\n",
    "    # Train the model\n",
    "    print(\"\\nStarting Training...\\n\")\n",
    "    train_model(efficientnet_classifier, train_loader, criterion, optimizer, device, epochs=30)\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(\"\\nEvaluating the Model...\\n\")\n",
    "    evaluate_model(efficientnet_classifier, test_loader, device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
